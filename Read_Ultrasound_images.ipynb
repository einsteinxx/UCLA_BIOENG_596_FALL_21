{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/einsteinxx/UCLA_BIOENG_596_FALL_21/blob/main/Read_Ultrasound_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdli9yCjQSzP"
      },
      "source": [
        "#CODE SETUP\n",
        "\n",
        "\n",
        "1.   Library Imports\n",
        "2.   Set data specific Google Drive folders\n",
        "\n",
        "\n",
        "\n",
        "'keep_Highscore' function original design from Anil Yadav:\n",
        " https://github.com/akre96/BUS_tumor_classification/tree/master/segmentation_model/experiments_FasterR-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NkBEnltCrpg",
        "outputId": "e7b4beee-c5e9-4e37-8ff2-683cb5b6e37c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 793 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 54.5 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 256 kB 5.3 MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n",
            "GPU NOT FOUND!!! USING CPU INSTEAD!!!!!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import gc  #debug memory leaks in matplotlib\n",
        "import csv #read in description files\n",
        "import random #used to select random slice for patches\n",
        "import cv2\n",
        "import re #regexp for BUSI files\n",
        "from skimage import exposure  #image equalization\n",
        "\n",
        "!pip3 install -q torchinfo\n",
        "!pip3 install -Uqq ipdb\n",
        "################################################################################\n",
        "#ULTRASOUND NEEDS\n",
        "import PIL\n",
        "#from PIL import Image\n",
        "# Open the image form working directory\n",
        "#image = Image.open(full_file)\n",
        "from matplotlib import image\n",
        "from ast import literal_eval #used to break out bounding boxes from strings\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from numpy import clip\n",
        "\n",
        "import torchinfo\n",
        "\n",
        "\n",
        "#import ipdb  #debugger tool \n",
        "################################################################################\n",
        "\n",
        "eps = 1e-16 #keep div by 0 away\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "#\n",
        "# Read Data from google drive\n",
        "#\n",
        "from google.colab import drive #for loading gdrive data\n",
        "from google.colab import files\n",
        "\n",
        "# install dependencies not included by Colab\n",
        "# use pip3 to ensure compatibility w/ Google Deep Learning Images \n",
        "!pip3 install -q pydicom \n",
        "!pip3 install -q tqdm \n",
        "!pip3 install -q imgaug\n",
        "!pip3 install -q pickle5\n",
        "\n",
        "import pydicom #to read dicom files\n",
        "from pydicom import dcmread\n",
        "import pickle5 as pickle; #generic storage of image array\n",
        "\n",
        "################################################################################\n",
        "# Load data from google drive\n",
        "################################################################################\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#\n",
        "# Setup of input and output drives\n",
        "#\n",
        "\n",
        "#\n",
        "# Choose training sets to use\n",
        "#\n",
        "training_set = 0 #0=UCLA US, 1 = UCLA + BUSI, 2 = BUSI\n",
        "\n",
        "#storage areas \n",
        "data_dir = '/content/gdrive/Shareddrives/BreastUS'\n",
        "local_dir = '/content/gdrive/My Drive/BreastUS' #for local storage\n",
        "model_dir = '/content/gdrive/My Drive/BreastUS/MODEL_SAVE'\n",
        "tensorboard_dir =  '/content/gdrive/My Drive/BreastUS/TENSORBOARD_SUMMARIES'\n",
        "\n",
        "\n",
        "#\n",
        "# UCLA specific data folders\n",
        "#\n",
        "csv_dir = os.path.join(data_dir,'Annotated data')\n",
        "\n",
        "annotated_dir = os.path.join(data_dir,'Annotated data')\n",
        "\n",
        "data_files = os.listdir(annotated_dir)\n",
        "label_data_dir = os.path.join(annotated_dir,'LabelMe_3.0_format_updated')\n",
        "label_files = os.listdir(label_data_dir)\n",
        "\n",
        "#\n",
        "# Alternative set of Ultrasound data\n",
        "#\n",
        "use_USnorm = 1\n",
        "if (use_USnorm == 1): #use norm based on US data, not imagenet\n",
        "\n",
        "    #busi_main_dir = '/content/gdrive/My Drive/BreastUS/BUSI_DATA' #downloaded BUSI\n",
        "    busi_main_dir = '/content/gdrive/My Drive/BreastUS/0TO1NORM/BUSI_DATA_CONTRAST_EQUALIZED'\n",
        "    #output converted BUSI images go in here:\n",
        "    ucla_converted_main_dir = '/content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED'\n",
        "else:\n",
        "    #busi_main_dir = '/content/gdrive/My Drive/BreastUS/BUSI_DATA' #downloaded BUSI\n",
        "    busi_main_dir = '/content/gdrive/My Drive/BreastUS/N2TO2_NORM/BUSI_DATA_CONTRAST_EQUALIZED'\n",
        "    #output converted BUSI images go in here:\n",
        "    ucla_converted_main_dir = '/content/gdrive/My Drive/BreastUS/N2TO2_NORM/UCLA_DATA_CONTRAST_EQUALIZED'    \n",
        "\n",
        "#\n",
        "# Stored output images\n",
        "#\n",
        "ucla_output_image_dir = '/content/gdrive/My Drive/BreastUS/UCLA_OUTPUT_IMAGES'\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#      GPU OPTIONS\n",
        "### Enable GPU, if present\n",
        "################################################################################\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if (train_on_gpu):\n",
        "    !nvidia-smi -L\n",
        "    !nvidia-smi \n",
        "    dev=torch.device(\"cuda\")\n",
        "else:\n",
        "    print('GPU NOT FOUND!!! USING CPU INSTEAD!!!!!')\n",
        "    dev=torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ahGyS9xgArE",
        "outputId": "2810f7bd-60c5-450d-b327-defb12c96b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "Using Training option  0\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print('Using Training option ', training_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcUM9Hgy69Pg"
      },
      "source": [
        "#CREATE UCLA LISTING OF CONTRAST ADJUSTED FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3C4ye3otp8zW"
      },
      "outputs": [],
      "source": [
        "if (training_set ==0):\n",
        "    #get the full listing of all pickle files that have been converted\n",
        "    subdirs = os.listdir(ucla_converted_main_dir)\n",
        "\n",
        "    ucla_pickle_list = []\n",
        "    #go into each subdirectory and pull the files from default/\n",
        "    for sdir in subdirs:\n",
        "        bottom_dir = os.path.join(ucla_converted_main_dir,sdir,'default')\n",
        "        plist = os.listdir(bottom_dir)\n",
        "\n",
        "        for pfile in plist:\n",
        "            fname = os.path.join(bottom_dir,pfile)\n",
        "            ucla_pickle_list.append(fname)\n",
        "\n",
        "\n",
        "else:\n",
        "    print('UCLA Data not selected')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ucla_pickle_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrcVpU_6W-Rz",
        "outputId": "3bf913f6-4df9-4e29-c5f7-3e2e46cd99b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18273"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCO2XId18C_k"
      },
      "source": [
        "#GET BUSI INFORMATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XEmubWxe8CV_"
      },
      "outputs": [],
      "source": [
        "if (training_set > 0):\n",
        "    print('--- Loading BUSI Data Files and Categorizing')\n",
        "    busi_dirs = os.listdir(busi_main_dir)\n",
        "    print('busi directories: ', busi_dirs)\n",
        "\n",
        "    #busi_m_files = os.listdir(os.path.join(busi_main_dir, 'malignant')) #bus_dirs['malignant']))\n",
        "\n",
        "    m_mask_list = []\n",
        "    image_m_dict={}\n",
        "    image_n_dict ={}\n",
        "    image_b_dict={}\n",
        "\n",
        "    mask_m_dict = {}\n",
        "    mask_n_dict ={}\n",
        "    mask_b_dict = {}\n",
        "\n",
        "    busi_filename =[]\n",
        "    busi_category = []\n",
        "    busi_bbox=[]\n",
        "\n",
        "    for category in busi_dirs:\n",
        "        busi_files = os.listdir(os.path.join(busi_main_dir, category))\n",
        "        \n",
        "        for filename in busi_files:\n",
        "            busi_filename.append(filename)\n",
        "            if ('mask' in filename):\n",
        "                m_mask_list.append(filename)\n",
        "                temp= filename.split(' ')\n",
        "                number = re.findall('\\d+',temp[1])\n",
        "                number = int(number[0])\n",
        "\n",
        "                full_file = os.path.join(busi_main_dir,category, filename)\n",
        "                img_data = image.imread(full_file)\n",
        "\n",
        "                if ('normal' not in category):\n",
        "                    result =np.where(img_data > 0)\n",
        "                    rows = min(result[0]),max(result[0])\n",
        "                    cols = min(result[1]), max(result[1])\n",
        "                else:\n",
        "                    #normal cases have a solid 0 mask\n",
        "                    rows = 0,0\n",
        "                    cols = 0,0\n",
        "\n",
        "\n",
        "\n",
        "                #\n",
        "                # Create Mask coordinates\n",
        "                #\n",
        "                #    pos = np.int32(pos)\n",
        "                #    xmin = pos[0][0]\n",
        "                #    xmax = pos[1][0]\n",
        "                #    ymin = pos[0][1]\n",
        "                #    ymax = pos[2][1]        \n",
        "                #busi_bbox.append([(rows[0],cols[0]), (rows[0], cols[1]), (rows[1], cols[0]), (rows[1], cols[1])])\n",
        "                if ('malignant' in temp[0]):\n",
        "                    mask_m_dict[number]  = [(cols[0],rows[0]), (cols[1],rows[0]), \n",
        "                                            (cols[0], rows[1]), (cols[1], rows[1])]\n",
        "                    #[(rows[0],cols[0]), (rows[0], cols[1]), (rows[1], cols[0]), (rows[1], cols[1])]\n",
        "                elif ('normal' in temp[0]):\n",
        "                    mask_n_dict[number] = [] \n",
        "                    #[(cols[0],rows[0]), (cols[1],rows[0]), \n",
        "                    #                        (cols[0], rows[1]), (cols[1], rows[1])]\n",
        "                    \n",
        "                # [(rows[0],cols[0]), (rows[0], cols[1]), (rows[1], cols[0]), (rows[1], cols[1])]\n",
        "                elif ('benign' in temp[0]):\n",
        "                    mask_b_dict[number] = [(cols[0],rows[0]), (cols[1],rows[0]), \n",
        "                                            (cols[0], rows[1]), (cols[1], rows[1])]\n",
        "                # [(rows[0],cols[0]), (rows[0], cols[1]), (rows[1], cols[0]), (rows[1], cols[1])]\n",
        "                else:\n",
        "                    print('Found an incorrect data category')\n",
        "                    exit()\n",
        "\n",
        "                \n",
        "                '''\n",
        "                plt.figure()\n",
        "                plt.imshow(img_data,cmap = 'jet')\n",
        "                plt.colorbar()\n",
        "                plt.show()\n",
        "                '''\n",
        "            else:\n",
        "                temp= filename.split(' ')\n",
        "                number = re.findall('\\d+',temp[1])\n",
        "                number = int(number[0])\n",
        "                full_file = os.path.join(busi_main_dir,category, filename)\n",
        "\n",
        "                if ('malignant' in temp[0]):\n",
        "                    image_m_dict[number] = full_file\n",
        "                elif ('normal' in temp[0]):\n",
        "                    image_n_dict[number] = full_file\n",
        "                elif ('benign' in temp[0]):\n",
        "                    image_b_dict[number] = full_file\n",
        "                else:\n",
        "                    print('Found an incorrect data image category')\n",
        "                    exit()\n",
        "        print('Done with category: ', category)\n",
        "                \n",
        "    print('Done parsing BUSI data')\n",
        "            \n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdVnU-1rU__i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S-cryelSAPV"
      },
      "source": [
        "#Get Example DICOM header info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jui81Q6f872p",
        "outputId": "8aa9ec04-06ae-496d-b9be-19619b2c8c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/BreastUS/1.dcm\n",
            "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
            "(0008, 0008) Image Type                          CS: ['DERIVED', 'PRIMARY', 'SMALL PARTS']\n",
            "(0008, 0012) Instance Creation Date              DA: '20211111'\n",
            "(0008, 0013) Instance Creation Time              TM: '132938'\n",
            "(0008, 0016) SOP Class UID                       UI: Ultrasound Multi-frame Image Storage\n",
            "(0008, 0018) SOP Instance UID                    UI: 1.2.840.113663.1500.1.365952523.3.2.20210204.132938.671\n",
            "(0008, 0020) Study Date                          DA: '20211111'\n",
            "(0008, 0021) Series Date                         DA: '20211111'\n",
            "(0008, 0023) Content Date                        DA: '20211111'\n",
            "(0008, 002a) Acquisition DateTime                DT: '20211111'\n",
            "(0008, 0030) Study Time                          TM: '130201'\n",
            "(0008, 0031) Series Time                         TM: '130201'\n",
            "(0008, 0033) Content Time                        TM: '132938'\n",
            "(0008, 0050) Accession Number                    SH: 'A_TR6Z2X0X'\n",
            "(0008, 0060) Modality                            CS: 'US'\n",
            "(0008, 0068) Presentation Intent Type            CS: 'FOR PRESENTATION'\n",
            "(0008, 0070) Manufacturer                        LO: 'Philips Medical Systems'\n",
            "(0008, 0080) Institution Name                    LO: 'BKWIC,SM,CA 90404 RM2'\n",
            "(0008, 0090) Referring Physician's Name          PN: 'LEE^MINNA'\n",
            "(0008, 1010) Station Name                        SH: 'USSM'\n",
            "(0008, 1030) Study Description                   LO: 'RIGHT BREAST BIOPSY ULTRASOUND GUIDED'\n",
            "(0008, 1032) Procedure Code Sequence             SQ: <Sequence, length 1>\n",
            "(0008, 103e) Series Description                  LO: 'MM US RT BREAST BIOPSY'\n",
            "(0008, 1070) Operators' Name                     PN: ''\n",
            "(0008, 1090) Manufacturer's Model Name           LO: 'iU22'\n",
            "(0008, 1111) Referenced Performed Procedure Step SQ: <Sequence, length 1>\n",
            "(0008, 2111) Derivation Description              ST: ''\n",
            "(0009, 0000) Private Creator                     UL: 14\n",
            "(0009, 0010) Private tag data                    LO: 'GEIIS'\n",
            "(0010, 0010) Patient's Name                      PN: '10088_1_0K0L7T04'\n",
            "(0010, 0020) Patient ID                          LO: '10088_1_0K0L7T04'\n",
            "(0010, 0021) Issuer of Patient ID                LO: '001R41:20090813:023040546:015090'\n",
            "(0010, 0030) Patient's Birth Date                DA: '19000101'\n",
            "(0010, 0040) Patient's Sex                       CS: ''\n",
            "(0010, 1020) Patient's Size                      DS: None\n",
            "(0010, 1030) Patient's Weight                    DS: None\n",
            "(0010, 1040) Patient's Address                   LO: 'MQ DE-IDENTIFIED'\n",
            "(0010, 2160) Ethnic Group                        SH: 'MQ DE-IDENTIFIED'\n",
            "(0018, 1000) Device Serial Number                LO: '365952523'\n",
            "(0018, 1020) Software Versions                   LO: 'PMS5.1 Ultrasound iU22_6.0.2.144'\n",
            "(0018, 1030) Protocol Name                       LO: 'Free Form'\n",
            "(0018, 1063) Frame Time                          DS: '31.154'\n",
            "(0018, 1088) Heart Rate                          IS: '0'\n",
            "(0018, 5010) Transducer Data                     LO: ['L12_5', '', '']\n",
            "(0018, 5020) Processing Function                 LO: 'SM_PRTS_ADV_BREAST'\n",
            "(0018, 6011) Sequence of Ultrasound Regions      SQ: <Sequence, length 1>\n",
            "(0020, 000d) Study Instance UID                  UI: 1.2.840.114350.2.300.2.798268.2.463966434.1\n",
            "(0020, 000e) Series Instance UID                 UI: 1.2.840.113663.1500.1.365952523.2.1.20210204.130201.984\n",
            "(0020, 0010) Study ID                            SH: '465241817'\n",
            "(0020, 0011) Series Number                       IS: '1'\n",
            "(0020, 0013) Instance Number                     IS: '1'\n",
            "(0028, 0002) Samples per Pixel                   US: 3\n",
            "(0028, 0004) Photometric Interpretation          CS: 'RGB'\n",
            "(0028, 0006) Planar Configuration                US: 0\n",
            "(0028, 0008) Number of Frames                    IS: '1'\n",
            "(0028, 0009) Frame Increment Pointer             AT: (0018, 1063)\n",
            "(0028, 0010) Rows                                US: 600\n",
            "(0028, 0011) Columns                             US: 800\n",
            "(0028, 0014) Ultrasound Color Data Present       US: 0\n",
            "(0028, 0100) Bits Allocated                      US: 8\n",
            "(0028, 0101) Bits Stored                         US: 8\n",
            "(0028, 0102) High Bit                            US: 7\n",
            "(0028, 0103) Pixel Representation                US: 0\n",
            "(0028, 0301) Burned In Annotation                CS: 'YES'\n",
            "(0028, 2110) Lossy Image Compression             CS: '01'\n",
            "(0028, 2112) Lossy Image Compression Ratio       DS: '0.0'\n",
            "(0032, 1032) Requesting Physician                PN: 'LEE^MINNA^K.^^MD'\n",
            "(0032, 1033) Requesting Service                  LO: 'Unspecified'\n",
            "(0040, 0244) Performed Procedure Step Start Date DA: '20211111'\n",
            "(0040, 0245) Performed Procedure Step Start Time TM: '130201'\n",
            "(0040, 0253) Performed Procedure Step ID         SH: '20211111'\n",
            "(0040, 0254) Performed Procedure Step Descriptio LO: 'MM US RT BREAST BIOPSY'\n",
            "(0040, 0260) Performed Protocol Code Sequence    SQ: <Sequence, length 1>\n",
            "(0040, 0280) Comments on the Performed Procedure ST: 'Breast'\n",
            "(0903, 0010) Private Creator                     LO: 'GEIIS PACS'\n",
            "(0903, 1010) [Reject Image Flag]                 US: 0\n",
            "(0903, 1011) [Significant Flag]                  US: 0\n",
            "(0903, 1012) [Confidential Flag]                 US: 0\n",
            "(0905, 0010) Private Creator                     LO: 'GEIIS'\n",
            "(0905, 1030) [Assigning Authority For Patient ID LO: '001R41:20090813:023040546:015090'\n",
            "(2050, 0020) Presentation LUT Shape              CS: 'IDENTITY'\n",
            "(7fd1, 0000) Private Creator                     UL: 350\n",
            "(7fd1, 0010) Private tag data                    LO: 'GEIIS'\n",
            "(7fd1, 1010) [GE IIS Compression ID]             UL: 17\n",
            "(7fd1, 1020) [GE IIS Multiframe Offsets]         UL: Array of 79 elements\n",
            "(7fe0, 0000) Group Length                        UL: 113760012\n",
            "(7fe0, 0010) Pixel Data                          OB: Array of 1440000 elements\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/Copy of us_status_index.pickle\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/us_status_index2nd.pickle\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/us_status_index.pickle\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/counters_to_remove.pickle\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/remaining_bad_counters_to_remove.pickle\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/ucla_converted_files_pickle_list.pck\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/b2.csv\n",
            "Non-dicom file found  /content/gdrive/My Drive/BreastUS/out.csv\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Get DICOM info\n",
        "#\n",
        "local_files = os.listdir(local_dir)\n",
        "\n",
        "for dicom_file in local_files:\n",
        "    filename = os.path.join(local_dir,dicom_file)\n",
        "    if (os.path.isdir(filename) == 1):\n",
        "        #skip any directories found in list\n",
        "        continue\n",
        "    if ('dcm' in filename):\n",
        "        print(filename)\n",
        "        ds = dcmread(filename, force=True)\n",
        "        for element in ds:\n",
        "            print(element)\n",
        "\n",
        "    else:\n",
        "        print('Non-dicom file found ',filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GET CSV DATA FUNCTION"
      ],
      "metadata": {
        "id": "HKnX95TLpUCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "afyEeFFcVJCa"
      },
      "outputs": [],
      "source": [
        "def get_csv_data(filename):\n",
        "    fields = []\n",
        "    rows = []\n",
        "\n",
        "    # reading csv file\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        # creating a csv reader object\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        \n",
        "        # extracting field names through first row\n",
        "        fields = next(csvreader)\n",
        "\n",
        "        # extracting each data row one by one\n",
        "        for row in csvreader:\n",
        "            rows.append(row)\n",
        "\n",
        "\n",
        "        # lines present\n",
        "        print(\"found rows: %d\"%(len(rows)))\n",
        "        print(row)\n",
        "    return fields, rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzhCbP7tbCX8"
      },
      "source": [
        "# GET CSV INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrtsfNXHWsUX",
        "outputId": "b651d7f5-c3ae-4dd4-b6b5-d4bdcc28918d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-archive file found  /content/gdrive/Shareddrives/BreastUS/Annotated data/annotations_updated_final.csv\n",
            "Non-archive file found  /content/gdrive/Shareddrives/BreastUS/Annotated data/annotations_updated.csv\n",
            "Non-archive file found  /content/gdrive/Shareddrives/BreastUS/Annotated data/unzipfiles.py\n",
            "Non-archive file found  /content/gdrive/Shareddrives/BreastUS/Annotated data/UnzipFiles.ipynb\n",
            "found rows: 18688\n",
            "['18687', '1_PQ8NN45N', 'A_X4G5X404', '1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip', '112', '/content/gdrive/Shareddrives/BreastUS/Annotated data/unzipped_Batch2/1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip/default/frame_000112.PNG', '[]', 'Invasive ductal carcinoma, grade 2 (90% of biopsy, longest involved segment 7.5 mm). Modified Bloom and Richardson Score: 6 of 9.', 'Right Breast, 12:00, 6cm FTN', 'N/A', 'M']\n",
            "Using CSV FILE:  /content/gdrive/Shareddrives/BreastUS/Annotated data/annotations_updated_final_Batch1_Batch2.csv\n",
            "Done reading CSV data\n"
          ]
        }
      ],
      "source": [
        "#READ CSV FILES\n",
        "#pull out the box information and label info\n",
        "csv_list = os.listdir(csv_dir)\n",
        "\n",
        "for csv_file in csv_list:\n",
        "    filename = os.path.join(csv_dir,csv_file)\n",
        "    if (os.path.isdir(filename) == 1):\n",
        "        #skip any directories found in list\n",
        "        continue\n",
        "    if ('_final_Batch1_Batch2' in csv_file):\n",
        "        annotation_fields, annotation_rows = get_csv_data(filename)\n",
        "        print('Using CSV FILE: ',filename)\n",
        "        break\n",
        "    else:\n",
        "        print('Non-archive file found ',filename)\n",
        "print('Done reading CSV data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotation_rows[15590] #:15590]\n",
        "\n",
        "count = 0\n",
        "for ii in range(0,18000):\n",
        "    if ('1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip' in annotation_rows[ii][3]):\n",
        "        print(ii,count,annotation_rows[ii][3],annotation_rows[ii][6])\n",
        "        count +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkEsQ5E1i6vq",
        "outputId": "e848f6d1-ffb2-47ef-968f-3c8d02d0faee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15957 0 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15958 1 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15959 2 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15960 3 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15961 4 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15962 5 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15963 6 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15964 7 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15965 8 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15966 9 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15967 10 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15968 11 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15969 12 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15970 13 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15971 14 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15972 15 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15973 16 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15974 17 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15975 18 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15976 19 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15977 20 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15978 21 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15979 22 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15980 23 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15981 24 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15982 25 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15983 26 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15984 27 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15985 28 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15986 29 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15987 30 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15988 31 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15989 32 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15990 33 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15991 34 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15992 35 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15993 36 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15994 37 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15995 38 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15996 39 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15997 40 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15998 41 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15999 42 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16000 43 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16001 44 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16002 45 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(275, 355), (275, 471), (350, 471), (350, 355)]\n",
            "16003 46 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(275, 355), (275, 471), (350, 471), (350, 355)]\n",
            "16004 47 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(269, 352), (269, 468), (345, 468), (345, 352)]\n",
            "16005 48 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(269, 354), (269, 470), (345, 470), (345, 354)]\n",
            "16006 49 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16007 50 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16008 51 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16009 52 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16010 53 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16011 54 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16012 55 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16013 56 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16014 57 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16015 58 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16016 59 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16017 60 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16018 61 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16019 62 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16020 63 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16021 64 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16022 65 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16023 66 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16024 67 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16025 68 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16026 69 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16027 70 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16028 71 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16029 72 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16030 73 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16031 74 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16032 75 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16033 76 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16034 77 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16035 78 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16036 79 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16037 80 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16038 81 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16039 82 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16040 83 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16041 84 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16042 85 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16043 86 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16044 87 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16045 88 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 469), (350, 469), (350, 362)]\n",
            "16046 89 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16047 90 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16048 91 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16049 92 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16050 93 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16051 94 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16052 95 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16053 96 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16054 97 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16055 98 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16056 99 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16057 100 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16058 101 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16059 102 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16060 103 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16061 104 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16062 105 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16063 106 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16064 107 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16065 108 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16066 109 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16067 110 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16068 111 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16069 112 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16070 113 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16071 114 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16072 115 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16073 116 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16074 117 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16075 118 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16076 119 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16077 120 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16078 121 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16079 122 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16080 123 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16081 124 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16082 125 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16083 126 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16084 127 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16085 128 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16086 129 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16087 130 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16088 131 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16089 132 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16090 133 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16091 134 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16092 135 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16093 136 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16094 137 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16095 138 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16096 139 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16097 140 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16098 141 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16099 142 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16100 143 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16101 144 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16102 145 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16103 146 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16104 147 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16105 148 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16106 149 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16107 150 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16108 151 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16109 152 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16110 153 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16111 154 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16112 155 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16113 156 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16114 157 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16115 158 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16116 159 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16117 160 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16118 161 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16119 162 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16120 163 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16121 164 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16122 165 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16123 166 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16124 167 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16125 168 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16126 169 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16127 170 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16128 171 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16129 172 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16130 173 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16131 174 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16132 175 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16133 176 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16134 177 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16135 178 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16136 179 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16137 180 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16138 181 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16139 182 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16140 183 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16141 184 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16142 185 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16143 186 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16144 187 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16145 188 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16146 189 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16147 190 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16148 191 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16149 192 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16150 193 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16151 194 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16152 195 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16153 196 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16154 197 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16155 198 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16156 199 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16157 200 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16158 201 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16159 202 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16160 203 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16161 204 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16162 205 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16163 206 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16164 207 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16165 208 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16166 209 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16167 210 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16168 211 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16169 212 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16170 213 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16171 214 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16172 215 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16173 216 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16174 217 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16175 218 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16176 219 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16177 220 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16178 221 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16179 222 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16180 223 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16181 224 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16182 225 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16183 226 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16184 227 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16185 228 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16186 229 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16187 230 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16188 231 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16189 232 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16190 233 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16191 234 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16192 235 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16193 236 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16194 237 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16195 238 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16196 239 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16197 240 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16198 241 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16199 242 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16200 243 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16201 244 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16202 245 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16203 246 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16204 247 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16205 248 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16206 249 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16207 250 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16208 251 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16209 252 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16210 253 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16211 254 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnV_94fziBBe"
      },
      "source": [
        "#Assign UCLA CSV DATA INTO FIELDS\n",
        "\n",
        "\n",
        "*   String row is turned into a numpy array\n",
        "*   Copy slices into separate lists for use in labeling/annotations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3nGek1gaHBY",
        "outputId": "099d9e64-9fed-47e7-c083-a6c2a82f4336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18688, 11)\n",
            "['', 'coded_mrn', 'coded_accession', 'video_id', 'frame_id', 'image_path', 'bounding box', 'Final Diagnosis', 'Bx Site', 'Final Diagnosis.1', 'First 50']\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Pull the data from the csv array into their own field groups\n",
        "#\n",
        "\n",
        "print(np.shape(annotation_rows))\n",
        "\n",
        "print(annotation_fields)\n",
        "\n",
        "array_rows = np.array(annotation_rows.copy())\n",
        "csv_counter = array_rows[:,0].copy() #csv line number\n",
        "mrn = array_rows[:,1].copy()\n",
        "accession = array_rows[:,2].copy()\n",
        "video_id = array_rows[:,3].copy()\n",
        "frame_id = array_rows[:,4].copy()\n",
        "image_path = array_rows[:,5].copy()\n",
        "bounding_box =    array_rows[:,6].copy()\n",
        "diagnosis = array_rows[:,7].copy()\n",
        "biopsy_site = array_rows[:,8].copy()\n",
        "diagnosis2 = array_rows[:,9].copy()\n",
        "first50 = array_rows[:,10].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ii=16050\n",
        "print(annotation_rows[ii])\n",
        "#print(annotation_rows[ii][6])\n",
        "print(np.array(annotation_rows[ii])[6])\n",
        "print(bounding_box[ii])\n",
        "print(type(bounding_box[ii]))\n",
        "\n",
        "count = 0\n",
        "for ii in range(0,18000):\n",
        "    if ('1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip' in video_id[ii]):\n",
        "        print(ii,count,video_id[ii],bounding_box[ii])\n",
        "        count +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWUzs3SLlngN",
        "outputId": "dcf6a245-1f12-4303-e873-5d8085c738b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['16050', '1_4U573X42', 'A_3K55O0C8', '1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip', '93', '/content/gdrive/Shareddrives/BreastUS/Annotated data/unzipped_Batch2/1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip/default/frame_000093.PNG', '[(281, 358), (281, 445), (345, 445), (345, 358)]', 'Invasive lobular carcinoma\\xa0with pleomorphic features, grade\\xa02. Modified Bloom and Richardson Score: 7 of 9 ', 'Left Breast, 2:00, 6 cm FTN', 'N/A', 'M']\n",
            "[(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "[(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "<class 'numpy.str_'>\n",
            "15957 0 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15958 1 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15959 2 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15960 3 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15961 4 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15962 5 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15963 6 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15964 7 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15965 8 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15966 9 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15967 10 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15968 11 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15969 12 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15970 13 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15971 14 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15972 15 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15973 16 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15974 17 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15975 18 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15976 19 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15977 20 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15978 21 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15979 22 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15980 23 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15981 24 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15982 25 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15983 26 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15984 27 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15985 28 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15986 29 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15987 30 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15988 31 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15989 32 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15990 33 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15991 34 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15992 35 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15993 36 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15994 37 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15995 38 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15996 39 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15997 40 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15998 41 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15999 42 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16000 43 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16001 44 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16002 45 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(275, 355), (275, 471), (350, 471), (350, 355)]\n",
            "16003 46 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(275, 355), (275, 471), (350, 471), (350, 355)]\n",
            "16004 47 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(269, 352), (269, 468), (345, 468), (345, 352)]\n",
            "16005 48 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(269, 354), (269, 470), (345, 470), (345, 354)]\n",
            "16006 49 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16007 50 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16008 51 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16009 52 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16010 53 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16011 54 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16012 55 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16013 56 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16014 57 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16015 58 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16016 59 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16017 60 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16018 61 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16019 62 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16020 63 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16021 64 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16022 65 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16023 66 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16024 67 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16025 68 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16026 69 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16027 70 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16028 71 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16029 72 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16030 73 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16031 74 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16032 75 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16033 76 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16034 77 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16035 78 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16036 79 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16037 80 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16038 81 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16039 82 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16040 83 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16041 84 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16042 85 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16043 86 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16044 87 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 483), (350, 483), (350, 362)]\n",
            "16045 88 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(264, 362), (264, 469), (350, 469), (350, 362)]\n",
            "16046 89 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16047 90 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16048 91 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16049 92 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16050 93 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16051 94 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16052 95 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16053 96 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16054 97 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16055 98 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16056 99 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip [(281, 358), (281, 445), (345, 445), (345, 358)]\n",
            "16057 100 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16058 101 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16059 102 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16060 103 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16061 104 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16062 105 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16063 106 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16064 107 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16065 108 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16066 109 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16067 110 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16068 111 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16069 112 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16070 113 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16071 114 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16072 115 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16073 116 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16074 117 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16075 118 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16076 119 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16077 120 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16078 121 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16079 122 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16080 123 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16081 124 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16082 125 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16083 126 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16084 127 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16085 128 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16086 129 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16087 130 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16088 131 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16089 132 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16090 133 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16091 134 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16092 135 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16093 136 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16094 137 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16095 138 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16096 139 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16097 140 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16098 141 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16099 142 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16100 143 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16101 144 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16102 145 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16103 146 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16104 147 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16105 148 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16106 149 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16107 150 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16108 151 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16109 152 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16110 153 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16111 154 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16112 155 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16113 156 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16114 157 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16115 158 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16116 159 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16117 160 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16118 161 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16119 162 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16120 163 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16121 164 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16122 165 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16123 166 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16124 167 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16125 168 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16126 169 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16127 170 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16128 171 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16129 172 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16130 173 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16131 174 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16132 175 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16133 176 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16134 177 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16135 178 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16136 179 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16137 180 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16138 181 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16139 182 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16140 183 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16141 184 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16142 185 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16143 186 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16144 187 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16145 188 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16146 189 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16147 190 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16148 191 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16149 192 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16150 193 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16151 194 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16152 195 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16153 196 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16154 197 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16155 198 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16156 199 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16157 200 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16158 201 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16159 202 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16160 203 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16161 204 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16162 205 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16163 206 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16164 207 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16165 208 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16166 209 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16167 210 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16168 211 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16169 212 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16170 213 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16171 214 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16172 215 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16173 216 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16174 217 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16175 218 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16176 219 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16177 220 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16178 221 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16179 222 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16180 223 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16181 224 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16182 225 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16183 226 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16184 227 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16185 228 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16186 229 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16187 230 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16188 231 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16189 232 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16190 233 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16191 234 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16192 235 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16193 236 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16194 237 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16195 238 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16196 239 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16197 240 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16198 241 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16199 242 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16200 243 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16201 244 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16202 245 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16203 246 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16204 247 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16205 248 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16206 249 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16207 250 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16208 251 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16209 252 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16210 253 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "16211 254 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ii in range(0,10):\n",
        "    print(bounding_box[ii], annotation_rows[ii][6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmdzTQ7DIeUn",
        "outputId": "206a0400-dbeb-43e3-f5a0-61c6f1ba7b04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[] []\n",
            "[] []\n",
            "[] []\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ii in range(0,18000):\n",
        "    if (annotation_rows[ii][6] != np.array(annotation_rows[ii][6])):\n",
        "        print(annotation_rows[ii][6], np.array(annotation_rows[ii][6]))\n",
        "    #if ('1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip' in video_id[ii]):\n",
        "    #    print(ii,video_id[ii],bounding_box[ii],array_rows[ii,6])\n",
        "\n",
        "'''\n",
        "for ii in range(0,18000):\n",
        "    print(array_rows[ii,6])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d3qOGshjkaoP",
        "outputId": "74281911-3462-480c-8e9a-c5635a06ae5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor ii in range(0,18000):\\n    print(array_rows[ii,6])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lee4NWfc-c98"
      },
      "source": [
        "# PLOT ANNOTATIONS AND PREDICTED BOX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vTWqwW_0-aTz"
      },
      "outputs": [],
      "source": [
        "def annotation_plot(img,\n",
        "                    eval_label,\n",
        "                    iou, \n",
        "                    score, \n",
        "                    calc_label, \n",
        "                    pred_boxes, \n",
        "                    target_boxes,\n",
        "                    savedir ='',\n",
        "                    savename='',\n",
        "                    figsave=0):\n",
        "    ############################################\n",
        "    #MATPLOTLIB STUFF\n",
        "    ############################################\n",
        "    plt.figure(figsize=(8, 6), dpi=80)\n",
        "    plt.imshow(img[1,:,:],cmap='gray')\n",
        "\n",
        "\n",
        "    #iou_value = f'{iou:.2f}'\n",
        "\n",
        "    '''\n",
        "    if (len(eval_label) >0):\n",
        "        label_value = f'{eval_label[0]:.1f}'\n",
        "    else:\n",
        "        label_value = 'N/A'\n",
        "    '''\n",
        "\n",
        "    \n",
        "    if (score > 0):\n",
        "        score_value = score#f'{score[0]['scores']:.1f}'\n",
        "    else:\n",
        "        score_value = 0.0 #'N/A'\n",
        "    if (torch.is_tensor(iou)):\n",
        "        print('found a tensor iou')\n",
        "        iou = iou.numpy()\n",
        "    if (calc_label ):\n",
        "        plabel = calc_label\n",
        "    else:\n",
        "        plabel = 0 #'N/A' is the output, but it stands for background\n",
        "        \n",
        "    #number format for use in figure title\n",
        "    iou_value = '{:04.2f}'.format(iou)\n",
        "    score_value = '{:04.2f}'.format(score_value)\n",
        "    \n",
        "    ttext = 'iou=' + str(iou_value)+'_Plabel='+str(plabel)+'_Pscore_'+str(score_value)\n",
        "    plt.title(ttext)\n",
        "    #print('iou = ', iou)\n",
        "    #print('------------------------------------------')\n",
        "\n",
        "    ax = plt.gca()\n",
        "    if (len(pred_boxes['boxes']) == 0):\n",
        "        pass\n",
        "    else:\n",
        "        rect = patches.Rectangle((np.uint(pred_boxes['boxes'][0]),\n",
        "                                np.uint(pred_boxes['boxes'][1] )), #np.uint(bdata[1].cpu() )),\n",
        "                                np.uint(pred_boxes['boxes'][2])-(np.uint(pred_boxes['boxes'][0])),\n",
        "                                np.uint(pred_boxes['boxes'][3])-(np.uint(pred_boxes['boxes'][1])),\n",
        "                                linewidth=1.5,edgecolor='r',facecolor='none')\n",
        "\n",
        "    if (len(target_boxes)==0):\n",
        "        #skip this, no rectangular annotation to plot\n",
        "        pass\n",
        "    else:\n",
        "        rect2 = patches.Rectangle((np.uint(target_boxes[0][0].cpu()),\n",
        "                                np.uint(target_boxes[0][1].cpu() )),\n",
        "                                np.uint(target_boxes[0][2].cpu())-(np.uint(target_boxes[0][0].cpu())),\n",
        "                                np.uint(target_boxes[0][3].cpu())-(np.uint(target_boxes[0][1].cpu())),\n",
        "                                linewidth=1.2,edgecolor='k',facecolor='none')\n",
        "\n",
        "\n",
        "        # Add the patch to the Axes\n",
        "    if (len(pred_boxes['boxes']) >0):\n",
        "        ax.add_patch(rect)\n",
        "    if (len(target_boxes)==0):\n",
        "        legend_text = ['Prediction']\n",
        "    else:\n",
        "        ax.add_patch(rect2)\n",
        "        legend_text = ['Prediction', 'Annotation']\n",
        "    plt.legend(legend_text)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if(figsave == 1):\n",
        "        #close this figure after writing image to drive\n",
        "        save_file = os.path.join(savedir,savename)\n",
        "        plt.savefig(save_file)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xClpqcOB55BT"
      },
      "source": [
        "### SAVE IMAGES TO DISK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "039DO_cZorqH"
      },
      "outputs": [],
      "source": [
        "if(0):\n",
        "    #['', 'coded_mrn', 'coded_accession', 'video_id', 'frame_id', 'image_path', 'bounding box', 'Final Diagnosis', 'Bx Site', 'Final Diagnosis.1', 'First 50']\n",
        "    '''\n",
        "    mrn = array_rows[:,1]\n",
        "    accession = array_rows[:,2]\n",
        "    video_id = array_rows[:,3]\n",
        "    frame_id = array_rows[:,4]\n",
        "    image_path = array_rows[:,5]\n",
        "    bounding_box = array_rows[:,6]\n",
        "    diagnosis = array_rows[:,7]\n",
        "    biopsy_site = array_rows[:,8]\n",
        "    diagnosis2 = array_rows[:,9]\n",
        "    first50 = array_rows[:,10]\n",
        "    '''\n",
        "\n",
        "    mrn_list = set(mrn)\n",
        "\n",
        "    acc =set()\n",
        "    vid = set()\n",
        "\n",
        "    #try first US video in first mrn\n",
        "\n",
        "\n",
        "    for count,mm in enumerate(mrn):\n",
        "        \n",
        "        if mm in mrn[0]:\n",
        "            acc.add(accession[count])\n",
        "            vid.add(video_id[count])\n",
        "\n",
        "    screen_dir = '/content/gdrive/My Drive/BreastUS/SCREEN_CAPS/'\n",
        "    #video_save = os.path.join()\n",
        "\n",
        "\n",
        "    file_name =[]\n",
        "    vname=[]\n",
        "    boundary_box = []\n",
        "    for cc,video_temp in enumerate(video_id):\n",
        "        [_,fpath] =image_path[cc].split('drive/MyDrive/Annotated data/')\n",
        "        full_file = os.path.join(annotated_dir,fpath)\n",
        "        file_name.append(full_file)\n",
        "        vname.append(video_temp)\n",
        "        boundary_box.append(bounding_box[cc])\n",
        "\n",
        "    print(file_name[0])\n",
        "    print(vname[0])\n",
        "    print(len(file_name))\n",
        "\n",
        "\n",
        "    case_holder = []\n",
        "    failed_list = [] #record of images that failed cropping\n",
        "\n",
        "    skip_to = 8002 #-1\n",
        "    for count,ii in enumerate(file_name):\n",
        "\n",
        "        if (count < skip_to):\n",
        "            continue #skip these until we get back to the proper file\n",
        "\n",
        "        #\n",
        "        # Save folder information. Get the video name and make a folder with that \n",
        "        # long name in the screen caps folder\n",
        "        #\n",
        "        video_save = os.path.join(screen_dir,vname[count])\n",
        "        if(os.path.exists(video_save)):\n",
        "            print('folder found')\n",
        "        else:\n",
        "            os.mkdir(video_save)\n",
        "\n",
        "        img_data = image.imread(ii)\n",
        "        #print(np.shape(img_data))\n",
        "        #print('Processing: ', ii)\n",
        "        print(count)\n",
        "\n",
        "\n",
        "        corners=literal_eval(boundary_box[count]) #bounding_box[count])\n",
        "        #bounding box values are in (x,y) formats from xml\n",
        "        #print('corners, len = ',corners, len(corners))\n",
        "        #print('bounding box = ',boundary_box[count]) #bounding_box[count])\n",
        "\n",
        "        '''\n",
        "        Bounding box ordering is \n",
        "        point 1        point 2\n",
        "        ----------------------\n",
        "        point 4        point 3\n",
        "        '''\n",
        "        if (len(corners)>0):\n",
        "            #print('corners ',pos)\n",
        "            pos = np.uint(corners)\n",
        "            xmin = pos[0][0]\n",
        "            xmax = pos[1][0]\n",
        "            ymin = pos[0][1]\n",
        "            ymax = pos[2][1]\n",
        "            #boxes.append([xmin, ymin, xmax, ymax])\n",
        "            h=ymax-ymin\n",
        "            w=xmax-xmin\n",
        "        else:\n",
        "            #print('EMPTY bounding box')\n",
        "            xmin=np.uint(1)\n",
        "            xmax=np.uint(2)\n",
        "            ymin=np.uint(1)\n",
        "            ymax=np.uint(2)\n",
        "            h=0\n",
        "            w=0\n",
        "            #boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "\n",
        "\n",
        "        #skip points =[low_row, high_row,start_column, final_column]\n",
        "        ## Convert the RGB input into grayscale\n",
        "        R, G, B = img_data[:,:,0], img_data[:,:,1], img_data[:,:,2]\n",
        "        imgGray = 0.2989 * R + 0.5870 * G + 0.1140 * B\n",
        "\n",
        "\n",
        "        #\n",
        "        # Crop the image to the Ultrasound borders. If it fails during this \n",
        "        # process, mark it and continue to next image. That failed index will be\n",
        "        # stored to remove any failed images later\n",
        "        #\n",
        "        cropped_image, skip_points,fail_flag = crop_us_image(imgGray,0)\n",
        "\n",
        "\n",
        "        show_plots = 0\n",
        "        if (fail_flag == 1): #if cropping worked, process annotations\n",
        "\n",
        "            #print('skip points = ',skip_points)\n",
        "            #print('h = ymax-ymin',ymax,ymin,h)\n",
        "            offset_row = ymin-skip_points[0]\n",
        "            offset_col = xmin-skip_points[2]\n",
        "\n",
        "            if (len(corners)>0):\n",
        "                width = xmax-xmin\n",
        "                height = ymax-ymin\n",
        "                rect = patches.Rectangle((offset_col,offset_row),width,height,linewidth=1,edgecolor='r',facecolor='none')\n",
        "                #print('adding rectangle ',offset_row, offset_col, height, width)\n",
        "                #print(ymin, ymax, xmin, xmax)\n",
        "            else:\n",
        "                rect = patches.Rectangle((0,0),0,0,linewidth=1,edgecolor='r',facecolor='none')\n",
        "\n",
        "            if (show_plots == 1):\n",
        "                show_crop = 0\n",
        "                if (show_crop == 0):\n",
        "\n",
        "                    fig = plt.figure(figsize=(8, 6), dpi=80)\n",
        "                    #plt.figure(figsize=(8, 6), dpi=80)\n",
        "                    #plt.imshow(cropped_image, cmap='gray')\n",
        "                    plt.imshow(cropped_image,cmap='gray')\n",
        "                    # Get the current reference\n",
        "                    ax = plt.gca()\n",
        "                    # Add the patch to the Axes\n",
        "                    ax.add_patch(rect)\n",
        "\n",
        "                    fname = os.path.join(video_save,os.path.basename(ii))\n",
        "                    #fname = os.path.basename(ii)\n",
        "                    title_text = 'Frame ' + str(fname)\n",
        "                    plt.title(title_text)\n",
        "                    \n",
        "                    plt.savefig(os.path.join(screen_dir,str(fname)))\n",
        "                    #time.sleep(1)\n",
        "                    #plt.show()\n",
        "                    plt.close()\n",
        "\n",
        "\n",
        "                if (show_crop == 1):  \n",
        "                    if (len(corners)>0):\n",
        "                        plt.figure(figsize=(8, 6), dpi=80)\n",
        "                        plt.imshow(img_data,cmap='gray')\n",
        "                \n",
        "                    # Get the current reference\n",
        "                        \n",
        "                        rect = patches.Rectangle((corners[0][0],corners[0][1]),w,h,linewidth=1,edgecolor='r',facecolor='none')\n",
        "                        bx = plt.gca()\n",
        "                        # Add the patch to the Axes\n",
        "                        bx.add_patch(rect)\n",
        "                        plt.show()\n",
        "                        plt.close()\n",
        "\n",
        "        else:\n",
        "            print('Failed crop for : ',file_name)\n",
        "            failed_list.append(count)\n",
        "        #save the fail list and file name list to remove fails later\n",
        "        if (count%1000 == 0):\n",
        "            status_file = os.path.join(local_dir,'us_status_index2nd.pickle')\n",
        "\n",
        "            pickle.dump([failed_list],open( status_file, \"wb\" ),protocol=5 )\n",
        "\n",
        "\n",
        "    print('finished plotting all images')\n",
        "\n",
        "\n",
        "    status_file = os.path.join(local_dir,'us_status_index2nd.pickle')\n",
        "    pickle.dump([failed_list],open( status_file, \"wb\" ),protocol=5 )\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    #print('filename exists: ',os.path.exists(full_file))\n",
        "\n",
        "    #image = image.imread(full_file)\n",
        "    #print(np.shape(image))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JNbFf0FAskGM"
      },
      "outputs": [],
      "source": [
        "def get_bb_stats(bounding_box):\n",
        "    total_area=[]\n",
        "    num_box=0\n",
        "    num_h=[]\n",
        "    num_w=[]\n",
        "    for index in range(0,len(bounding_box)):\n",
        "\n",
        "        #corners=literal_eval(bounding_box[index])\n",
        "\n",
        "        boxes = []\n",
        "        area = 0\n",
        "        #print(type(bounding_box[index]))\n",
        "        pos=literal_eval(bounding_box[index])\n",
        "\n",
        "        #print(index,pos)\n",
        "        #pos = np.double(pos)\n",
        "        if (len(pos) !=0): #(pos):\n",
        "            #print('corners ',pos)\n",
        "            pos = np.int32(pos)\n",
        "            xmin = pos[0][1]\n",
        "            xmax = pos[2][1]\n",
        "            ymin = pos[0][0]\n",
        "            ymax = pos[1][0]\n",
        "            w=xmax-xmin\n",
        "            h = ymax-ymin\n",
        "            num_h.append(h)\n",
        "            num_w.append(w)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            area += (xmax-xmin)*(ymax-ymin)\n",
        "            total_area.append(area)\n",
        "            num_box+=1\n",
        "    return total_area, num_box,num_h, num_w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxsXie0YGRUg"
      },
      "source": [
        "#GET COORDINATES FROM CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5c-aUiEvo7RW"
      },
      "outputs": [],
      "source": [
        "def get_coordinates(video_id,video_series):\n",
        "#video_series is the video_id for a series of PNG images taken from a movie.\n",
        "#Anything with this id will be a frame set that should be kept together\n",
        "\n",
        "#uvids = set(video_id)\n",
        "\n",
        "    bbox = []\n",
        "    for count,v in enumerate(video_id): #video_series:\n",
        "        if (v in video_series):\n",
        "            box_info = bounding_box[count]\n",
        "            #box_info = box_info.strip('][') #.split(', ')\n",
        "\n",
        "            if (not (box_info =='[]')):\n",
        "                \n",
        "                corners=literal_eval(box_info)\n",
        "                bbox.append(torch.FloatTensor(corners))\n",
        "                print(corners)\n",
        "            else:\n",
        "                bbox.append(torch.FloatTensor(0))\n",
        "\n",
        "    return bbox\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWp6S054HoNv"
      },
      "source": [
        "#                         **** Data Loaders ****\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lxErahOxJmLb"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self,\n",
        "                 img_dir,\n",
        "                 bounding_boxes,\n",
        "                 label_data,\n",
        "                 category=[],\n",
        "                 file_count=1,\n",
        "                 file_list =[],\n",
        "                 data_type = 0, #0=UCLA, 1 = BUSI\n",
        "                 transform=None,\n",
        "                 target_transform=None):\n",
        "        #self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.label_data = label_data\n",
        "        self.bounding_boxes = bounding_boxes\n",
        "        self.category = category\n",
        "        self.file_count = file_count\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.category_name =''\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "        self.imgs = file_list\n",
        "        self.data_type = data_type\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        eps = 1e-16 #keep div by 0 away\n",
        "\n",
        "        dbprint = 0\n",
        "        image_dir = self.img_dir\n",
        "        bounding_boxes_data = self.bounding_boxes[index]\n",
        "        file_name = self.file_list[index]\n",
        "        file_label = self.label_data[index] #for this index, the label stored\n",
        "\n",
        "        #print('--------------------------------------------------')\n",
        "        #print(file_name)\n",
        "        #print('image id ', index)\n",
        "\n",
        "        ########################################################################\n",
        "        #\n",
        "        # BUSI Data loading\n",
        "        #\n",
        "        ########################################################################\n",
        "        if (self.data_type == 2): #BUSI Images\n",
        "            #all of the cropping, normalization, equalization done in \n",
        "            #the pre-processing stage. We just load in the 3d volume \n",
        "            img = pickle.load( open( file_name, \"rb\" ) )\n",
        "            #img=cropped_image.astype(np.double)\n",
        "\n",
        "            #get original image sizes, which are part of the \n",
        "            #filenames. An example will be:\n",
        "            #  'malignant (208).png_664_617.pck'\n",
        "            fnumber = re.findall(r\"\\d+\",file_name)\n",
        "            #0TO1_NORM is the first set of 2 integers in the name\n",
        "            #filenum = int(fnumber[2])\n",
        "            oldr = int(fnumber[3])\n",
        "            oldc = int(fnumber[4])\n",
        "            #get nr, nc from image filename np.shape(cropped_image) #image shape before resize\n",
        "            skip_points = [0,0,0,0] #image was pre-cropped, nothing to skip\n",
        "            fail_crop=0 #cropping done externally, so set to 0\n",
        "        \n",
        "        ########################################################################\n",
        "        #\n",
        "        # UCLA Data loading\n",
        "        #\n",
        "        ########################################################################\n",
        "        elif (self.data_type == 0): #UCLA Data\n",
        "            #all of the cropping, normalization, equalization done in \n",
        "            #the pre-processing stage. We just load in the 3d volume \n",
        "\n",
        "            if os.path.getsize(file_name) < 0:\n",
        "                print('empty file --- ', file_name)\n",
        "                dbprint =1\n",
        "            else:\n",
        "                try:\n",
        "                    img = pickle.load( open( file_name, \"rb\" ) )\n",
        "                except:\n",
        "                    print('ERROR IN: ', file_name)\n",
        "\n",
        "            #ucla_path = '/content/gdrive/My Drive/BreastUS/0TO1_NORM/UCLA_DATA_CONTRAST_EQUALIZED'\n",
        "            cut_index = file_name.index(ucla_converted_main_dir) + len(ucla_converted_main_dir)+1\n",
        "\n",
        "        \n",
        "            short_name = file_name[cut_index:]  #removed the starting directory\n",
        "            parts = short_name.split('/')\n",
        "            if (dbprint == 1):\n",
        "                print('file_name[] ',file_name[cut_index:])\n",
        "                print(parts)\n",
        "            video_part = parts[0] #get the video idea from the parsed string\n",
        "            fileonly = os.path.basename(file_name) #filename without full pathing\n",
        "            #converted_name = fname.replace(old_string, new_string)\n",
        "\n",
        "            #get the original image sizes from the filename\n",
        "            fnumber = re.findall(r\"\\d+\",fileonly)\n",
        "            temp_frameid = fnumber[0]  #frame id\n",
        "\n",
        "\n",
        "            fnumber = re.findall(r\"\\d+\",fileonly) #_name)\n",
        "            oldr = int(fnumber[1])\n",
        "            oldc = int(fnumber[2])\n",
        "            skip_points =[]\n",
        "            for xx in fnumber[3:]:\n",
        "                skip_points.append(int(xx))\n",
        "            if (dbprint == 1):\n",
        "                print('oldr, oldc = ', oldr, oldc)\n",
        "                print('skip points ', skip_points)\n",
        "                print(bounding_boxes_data)\n",
        "            #get nr, nc from image filename np.shape(cropped_image) #image shape before resize\n",
        "            \n",
        "            fail_crop=0 #cropping done externally, so set to 0\n",
        "            \n",
        "\n",
        "        else:\n",
        "            stop\n",
        "\n",
        "            \n",
        "        ########################################################################\n",
        "        # Processing to run over every type of data\n",
        "        #\n",
        "        ########################################################################\n",
        "\n",
        "                #\n",
        "        # Scaling values for adjusting annotation box coordinates\n",
        "        # - since the images are likely upsized, the annotations need to be scaled\n",
        "        # by an amount to correspond to the new image size\n",
        "        #\n",
        "        nr,nc = np.shape(img[0,:,:]) #this is the new resized image\n",
        "        box_scalex = nc/oldc\n",
        "        box_scaley = nr/oldr\n",
        "        #\n",
        "                #bbox = torch.FloatTensor(corners)\n",
        "\n",
        "        # get bounding box coordinates for each mask\n",
        "        num_objs = len(self.file_list) #bounding_box)\n",
        "        boxes = []\n",
        "        #area = 0\n",
        "        pos=literal_eval(bounding_boxes_data)#[index])\n",
        "\n",
        "\n",
        "        #if (len(corners)>0):\n",
        "        #    width = xmax-xmin\n",
        "        #    height = ymax-ymin\n",
        "        #    rect = patches.Rectangle((offset_col,offset_row),width,height,linewidth=1,edgecolor='r',facecolor='none')\n",
        "        #skip_points = [low_row, high_row,start_column, final_column]\n",
        "\n",
        "        if (dbprint == 1):\n",
        "            corners=literal_eval(bounding_boxes_data)#[index])\n",
        "            print('corners ',pos)\n",
        "\n",
        "        #pos = np.double(pos)\n",
        "        if (len(pos) !=0): #(pos):\n",
        "\n",
        "            pos = np.int32(pos)\n",
        "            xmin = pos[0][0]\n",
        "            xmax = pos[1][0]\n",
        "            ymin = pos[0][1]\n",
        "            ymax = pos[2][1]\n",
        "            ### Correct for the cropped image as annotation points are for the \n",
        "            ### main image with subset\n",
        "            offset_row = ymin-skip_points[0]\n",
        "            offset_col = xmin-skip_points[2]\n",
        "            max_row = ymax - skip_points[0]\n",
        "            max_col = xmax - skip_points[2]\n",
        "\n",
        "            #boxes.append([offset_col, offset_row, \n",
        "            #              xmax-skip_points[2], \n",
        "            #              ymax-skip_points[0]])\n",
        "            x0 = offset_col * box_scalex\n",
        "            y0 = offset_row * box_scaley\n",
        "            x1 = max_col * box_scalex\n",
        "            y1 = max_row * box_scaley\n",
        "\n",
        "            if (dbprint ==1):\n",
        "                print('----------------------------------')\n",
        "                print('xo,yo,x1,y1 = ',x0,y0,x1,y1)\n",
        "                print('box scale x,y ',box_scalex, box_scaley)\n",
        "                print('offset col, row =',offset_col, offset_row)\n",
        "                print('skip points ',skip_points)\n",
        "                print('nr,nc = ', nr,nc)\n",
        "                print('oldc, oldr = ', oldc, oldr)\n",
        "                print('-----------------------------------')\n",
        "\n",
        "            w = x1-x0\n",
        "            h = y1-y0\n",
        "            if ((w <10) or (h <10)):\n",
        "                print('!!!!!! Unusable h/w found: ',h,w)\n",
        "                print(x0,y0,w,h)\n",
        "                print('box scale x,y ',box_scalex, box_scaley)\n",
        "                print('xmin,ymin,xmax,ymax ',xmin,ymin,xmax,ymax)\n",
        "                print('index is ',index)\n",
        "                print('skip points ',skip_points)\n",
        "                print('offset col, row =',offset_col, offset_row)\n",
        "            boxes.append([x0,y0,x1,y1])\n",
        "            #boxes.append([offset_col*box_scalex,\n",
        "            #              offset_row*box_scaley,\n",
        "            #              (xmax-skip_points[2])*box_scalex,\n",
        "            #              (ymax-skip_points[0])*box_scaley])\n",
        "            if (dbprint == 1):\n",
        "                print('boxes= ',boxes)\n",
        "\n",
        "            if (dbprint == 1):\n",
        "                print('offsets are (col,row) ',offset_col, offset_row)\n",
        "                print('skip points are ', skip_points)\n",
        "                print('xmax,min,ymax,min = ', xmax,xmin, ymax,ymin)\n",
        "            #boxes.append([xmin, ymin, xmax, ymax])\n",
        "            #area = (xmax-skip_points[0] - offset_col) * (ymax-skip_points[2] - offset_row) \n",
        "            #adjust area to include new scaled box sizes\n",
        "            area = ((xmax-skip_points[0] - offset_col)*box_scalex) * ((ymax-skip_points[2] - offset_row) * box_scaley)\n",
        "            #area += (xmax-xmin)*(ymax-ymin)#!! alter this\n",
        "\n",
        "\n",
        "        # Handle empty bounding boxes\n",
        "        # -- UCLA data without an annotation is benign.\n",
        "        # -- BUSI data without an annotation is normal, but benign cases will \n",
        "        #    have an annotation along with malignant\n",
        "\n",
        "        #if there isn't an annotation (pos is empty)\n",
        "        if (len(pos) ==0): #num_objs == 0:\n",
        "            #boxes.append([0,0,0,0])\n",
        "            #boxes.append([0,0,5,5]) #testing out something with an area\n",
        "            #boxes = torch.zeros((1, 4), dtype=torch.double)\n",
        "            #try using the whole image as negative\n",
        "            nz,nr,nc = np.shape(img)\n",
        "            #print('--- ',nz,nr,nc)\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            #trying empty boxes instead of full size images\n",
        "            #boxes.append([0.0,0.0,0.0,0.0])\n",
        "\n",
        "            #### works: boxes.append([0.0,0.0,nc,nr])\n",
        "            area = nr*nc\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.double)\n",
        "            #print('empty box size is ',np.shape(boxes))\n",
        "            #boxes = torch.zeros((0, 4), dtype=torch.double)\n",
        "            #area = 0 #10*10\n",
        "            area = torch.as_tensor(area, dtype=torch.double)\n",
        "\n",
        "            '''\n",
        "            #label = torch.as_tensor(0, dtype=torch.int64) #put as background if no boxes\n",
        "            if ('B' in file_label): #benign case, label should be 0\n",
        "                label = torch.zeros((1,), dtype=torch.int64)\n",
        "            elif ('M' in file_label): #malignant case, label should be 1\n",
        "                label = torch.ones((1,), dtype=torch.int64)\n",
        "            else: #something else made it through, database problem\n",
        "                print('!!!LABEL ERROR!!!')\n",
        "            '''\n",
        "\n",
        "\n",
        "            label = torch.zeros((1,), dtype=torch.int64)\n",
        "\n",
        "            iscrowd=torch.ones((1,), dtype=torch.int64)\n",
        "\n",
        "        else:\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.double) \n",
        "            #print('filled box size is ',np.shape(boxes))\n",
        "            area = torch.as_tensor(area, dtype=torch.double)\n",
        "        \n",
        "            #label = torch.as_tensor(1, dtype=torch.int64)\n",
        "            label = torch.ones((1,), dtype=torch.int64)\n",
        "            iscrowd=torch.zeros((1,), dtype=torch.int64)\n",
        "\n",
        "\n",
        "        # Use a generic label setup for UCLA, as the test directories contain\n",
        "        # Malignant cases without annotations\n",
        "        #if (len(pos) ==0): #Benign and normal\n",
        "        #    label = torch.zeros((1,), dtype=torch.int64)\n",
        "        #else:\n",
        "        #    label = torch.ones((1,), dtype=torch.int64)\n",
        "\n",
        "            ''' Use for labels\n",
        "            if ('B' in file_label): #benign case, label should be 0\n",
        "                label = torch.zeros((1,), dtype=torch.int64)\n",
        "            elif ('M' in file_label): #malignant case, label should be 1\n",
        "                label = torch.ones((1,), dtype=torch.int64)\n",
        "            else: #something else made it through, database problem\n",
        "                print('!!!LABEL ERROR!!!')\n",
        "                stop\n",
        "            '''\n",
        "\n",
        "        #\n",
        "        # Protect against zero images from earlier in this function.\n",
        "        #\n",
        "        if (fail_crop == 1):\n",
        "            #force this image to be a background image for training\n",
        "            print('forcing image as background for failed image')\n",
        "            label = torch.zeros((1,), dtype=torch.int64)\n",
        "            iscrowd=torch.ones((1,), dtype=torch.int64)\n",
        "\n",
        "        if (dbprint == 1):\n",
        "            print('shape of boxes is ', np.shape(boxes))\n",
        "\n",
        "\n",
        "        # there is only one class\n",
        "        #labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        #masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "\n",
        "        #image_id = torch.tensor([idx])\n",
        "        #area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        # suppose all instances are not crowd\n",
        "        ###iscrowd = torch.zeros((len(self.imgs),), dtype=torch.double)\n",
        "\n",
        "        if (dbprint == 1):\n",
        "            print('setting target')\n",
        "            print('label is ', label, type(label))\n",
        "            print('area is ', area)\n",
        "        \n",
        "\n",
        "\n",
        "        target = []\n",
        "        d = {}\n",
        "        d['boxes'] = boxes  #np.squeeze(boxes,0)\n",
        "        d['labels'] = label\n",
        "        d['image_id'] = torch.as_tensor(index, dtype=torch.double) \n",
        "        d['area'] = area \n",
        "        d['iscrowd'] = iscrowd \n",
        "        target.append(d)\n",
        "\n",
        "        #self.transform(self.x_data[index]), self.transform(self.y_data[index])\n",
        "        #return {'image': torch.from_numpy(image),\n",
        "#                'landmarks': torch.from_numpy(landmarks)}\n",
        "        #return self.transform(img), self.transform(target)\n",
        "        \n",
        "        #print('image type before is ', type(img))\n",
        "        img = torch.as_tensor(img, dtype=torch.float32) #model has float32 \n",
        "        #img= torch.from_numpy(img)\n",
        "        #print('image type after is ', type(img))\n",
        "        #img = torchvision.transforms.ToTensor()(image)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-4SEgAAkVnmT"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):  #borrowed\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI_gE6lyWv_y"
      },
      "source": [
        "#GENERATE ALL FILE PATHS AND TRIMMED CSV DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "211LJzRiN9a1",
        "outputId": "efea2839-62e6-4272-c42a-2abb1b1a6eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up UCLA Ultrasound Training Data\n",
            "setting default vid name  1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip\n",
            "setting default vid name  1_076up782_a_dcc4675o_1.mp4-2021_09_03_16_36_25-labelme 3.0.zip\n",
            "setting default vid name  1_0zw0m57r_a_6v90rk5f_0.mp4-2021_08_24_23_23_01-labelme 3.0.zip\n",
            "setting default vid name  1_0zw0m57r_a_6v90rk5f_1.mp4-2021_08_24_23_27_07-labelme 3.0.zip\n",
            "setting default vid name  1_1y57j09v_a_1clh6ogf_1.mp4-2021_09_26_17_36_15-labelme 3.0.zip\n",
            "setting default vid name  1_25s1kz8d_a_a7a2a5ah_0.mp4-2021_08_11_19_24_29-labelme 3.0.zip\n",
            "setting default vid name  1_25s1kz8d_a_a7a2a5ah_1.mp4-2021_08_11_19_27_06-labelme 3.0.zip\n",
            "failed vcount =  18272\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-9c77e0574734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m#no match found, error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'failed vcount = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# files '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Assign CSV data to each of the pre-generated files. Since some raw files may \n",
        "# not pass the cropping stage, the 1:1 correspondence between # images and CSV\n",
        "# rows was broken.\n",
        "#\n",
        "\n",
        "if (training_set ==0):\n",
        "\n",
        "    print('Setting up UCLA Ultrasound Training Data')\n",
        "    full_file_list=[]\n",
        "    bb_final=[]\n",
        "    label_first50=[]\n",
        "    video_id_final =[]\n",
        "    accession_final = []\n",
        "    image_path_final = []\n",
        "    skip_points_final=[]\n",
        "\n",
        "    '''\n",
        "    array_rows = np.array(annotation_rows)\n",
        "    mrn = array_rows[:,1]\n",
        "    accession = array_rows[:,2]\n",
        "    video_id = array_rows[:,3]\n",
        "    frame_id = array_rows[:,4]\n",
        "    image_path = array_rows[:,5]\n",
        "    bounding_box = array_rows[:,6]\n",
        "    diagnosis = array_rows[:,7]\n",
        "    biopsy_site = array_rows[:,8]\n",
        "    diagnosis2 = array_rows[:,9]\n",
        "    first50 = array_rows[:,10]\n",
        "    '''\n",
        "\n",
        "    #\n",
        "    # The pickle list contains full file locations for files in the pre-processed\n",
        "    # folder. Any raw data that was corrupt or couldn't be cropped is not \n",
        "    # included in this list.\n",
        "    # One problem with this shortened file list is that our csv rows do not \n",
        "    # align with the files anymore. Re-align them.\n",
        "    #\n",
        "    video_last =''\n",
        "    for file_counter,fname in enumerate(ucla_pickle_list):\n",
        "        #print('------------',fname)\n",
        "        #if ('1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip' in fname):\n",
        "        #    pass\n",
        "        #else:\n",
        "        #    continue\n",
        "\n",
        "        match_found = 0  #toggle when a bounding box is assigned\n",
        "\n",
        "        ########################################################################\n",
        "        # Get the video info from the filename. Use this to match up to the\n",
        "        # raw CSV info from the annotation files\n",
        "        ########################################################################\n",
        "        #index = fname.find(ucla_converted_main_dir)\n",
        "        index = fname.index(ucla_converted_main_dir) + len(ucla_converted_main_dir)+1\n",
        "\n",
        "\n",
        "        #print('index = ', index)\n",
        "        short_name = fname[index:]  #removed the starting directory\n",
        "        parts = short_name.split('/')\n",
        "        #print(fname[index:])\n",
        "        #print(parts)\n",
        "        video_part = parts[0] #get the video idfrom the parsed string\n",
        "        fileonly = os.path.basename(fname) #filename without full pathing\n",
        "        #converted_name = fname.replace(old_string, new_string)\n",
        "\n",
        "        #get the original image sizes from the filename\n",
        "        fnumber = re.findall(r\"\\d+\",fileonly)\n",
        "        temp_frameid = fnumber[0]  #frame id\n",
        "        original_row = fnumber[1]\n",
        "        original_col = fnumber[2]\n",
        "        skip_points = fnumber[3:]\n",
        "\n",
        "        if (len(video_part) < 20):\n",
        "            print('Name is not long enough.')\n",
        "            stop\n",
        "\n",
        "        if (video_part == video_last):\n",
        "            pass\n",
        "        else:\n",
        "            #first time seeing this video, set it to default and reset frame counter\n",
        "            print('setting default vid name ',video_part)\n",
        "            video_last = video_part\n",
        "            frames_found_already =[]\n",
        "\n",
        "        #scan through the video id list to get a match, then drill down to \n",
        "        #the frame number. There's probably a more python way to do this...\n",
        "        for vcount,vid in enumerate(video_id):\n",
        "\n",
        "            #frames_found_already =[] #keep a record of frames processed for vid\n",
        "            #print('---vcount ', vcount, video_part, vid)\n",
        "            if (video_part == vid):\n",
        "\n",
        "                #match, so now check the frame\n",
        "                #print('video matches', vcount, video_part, frame_id[vcount])\n",
        "                for fcount, frame in enumerate(frame_id[vcount:]):\n",
        "                    if ((int(temp_frameid) == int(frame)) and  \n",
        "                        (int(temp_frameid) not in frames_found_already[:])\n",
        "                        ):\n",
        "                        #print('frame is ', vcount,fcount,temp_frameid,frame, bounding_box[fcount], vid, file_counter)\n",
        "                        frames_found_already.append(int(frame))\n",
        "                        match_found =1\n",
        "                        break\n",
        "\n",
        "                if (match_found == 1):\n",
        "                    break\n",
        "            else:\n",
        "                continue\n",
        "            if (match_found == 1):\n",
        "                break\n",
        "\n",
        "        if (match_found == 1):\n",
        "            #\n",
        "            # Assign the row data to our final table\n",
        "            #\n",
        "            full_file_list.append(fname)\n",
        "            bb_final.append(bounding_box[fcount])\n",
        "            label_first50.append(first50[fcount])\n",
        "            video_id_final.append(video_id[fcount])\n",
        "            accession_final.append(accession[fcount])\n",
        "            image_path_final.append(fname) #image_path[vcount])\n",
        "            skip_points_final.append(skip_points)\n",
        "        else:\n",
        "            #no match found, error\n",
        "            print('failed vcount = ',vcount)\n",
        "            stop\n",
        "    \n",
        "    print('# files ',len(full_file_list))\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# BUSI and mixed UCLA/BUSI set\n",
        "#\n",
        "################################################################################\n",
        "if (training_set ==2):\n",
        "    print('Setting up BUSI data set')\n",
        "    if (training_set == 2): # we need initial list setups, since UCLA data was\n",
        "    # not processed\n",
        "        full_file_list = []\n",
        "        bounding_box = []\n",
        "        first50=[]\n",
        "    else:\n",
        "        print('Using lists defined in UCLA Dataset')\n",
        "        bounding_box = list(bounding_box)\n",
        "        first50 = list(first50)\n",
        "\n",
        "    for category in busi_dirs:\n",
        "        if ('malignant' in category):\n",
        "            for key_val in image_m_dict.keys():\n",
        "                full_file_list.append(image_m_dict[key_val])\n",
        "                bounding_box.append(np.str(mask_m_dict[key_val]))\n",
        "                first50.append(np.str('M'))\n",
        "\n",
        "            print('done with adding malignant files')\n",
        "        elif ('normal' in category):\n",
        "            for key_val in image_n_dict.keys():\n",
        "                full_file_list.append(image_n_dict[key_val])\n",
        "                bounding_box.append(np.str(mask_n_dict[key_val]))\n",
        "                first50.append(np.str('B'))\n",
        "\n",
        "            print('done with adding normal files')\n",
        "        else:\n",
        "            for key_val in image_b_dict.keys():\n",
        "                full_file_list.append(image_b_dict[key_val])\n",
        "                bounding_box.append(np.str(mask_b_dict[key_val]))\n",
        "                first50.append(np.str('B'))\n",
        "\n",
        "            print('done with adding benign files')\n",
        "    original_file_length = len(full_file_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(video_id_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKu1-XB4lxjB",
        "outputId": "1a18fdf0-cf02-42aa-f0af-d0e732bfda40"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip',\n",
              " '1_076up782_a_dcc4675o_1.mp4-2021_09_03_16_36_25-labelme 3.0.zip',\n",
              " '1_0zw0m57r_a_6v90rk5f_0.mp4-2021_08_24_23_23_01-labelme 3.0.zip',\n",
              " '1_0zw0m57r_a_6v90rk5f_1.mp4-2021_08_24_23_27_07-labelme 3.0.zip',\n",
              " '1_1y57j09v_a_1clh6ogf_1.mp4-2021_09_26_17_36_15-labelme 3.0.zip',\n",
              " '1_25s1kz8d_a_a7a2a5ah_0.mp4-2021_08_11_19_24_29-labelme 3.0.zip'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ii in range(0,7):\n",
        "    print(video_id[ii], bounding_box[ii])\n",
        "    print(video_id_final[ii],bb_final[ii])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK1qeTkvOmr8",
        "outputId": "765a48e6-9d44-4df1-f275-9d45d2904e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip []\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n",
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip []\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n",
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip []\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n",
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n",
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n",
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n",
            "1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip [(274, 197), (615, 197), (615, 395), (274, 395)]\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ucla_pickle_list))\n",
        "print(len(full_file_list))\n",
        "print(len(bb_final))\n",
        "print(parts[0])\n",
        "print(int(temp_frameid))\n",
        "print(len(set(image_path_final)))\n",
        "\n",
        "temp_csv= os.path.join(local_dir,'out.csv')\n",
        "with open(temp_csv, 'w') as f:\n",
        "    # create the csv writer\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    for rcount in range(0,len(bb_final)):\n",
        "\n",
        "        # write a row to the csv file\n",
        "        rowdata = [rcount,video_id[rcount], bounding_box[rcount]]\n",
        "        writer.writerow(rowdata)\n",
        "\n",
        "\n",
        "    '''\n",
        "    array_rows = np.array(annotation_rows)\n",
        "    mrn = array_rows[:,1]\n",
        "    accession = array_rows[:,2]\n",
        "    video_id = array_rows[:,3]\n",
        "    frame_id = array_rows[:,4]\n",
        "    image_path = array_rows[:,5]\n",
        "    bounding_box = array_rows[:,6]\n",
        "    diagnosis = array_rows[:,7]\n",
        "    biopsy_site = array_rows[:,8]\n",
        "    diagnosis2 = array_rows[:,9]\n",
        "    first50 = array_rows[:,10]\n",
        "    '''\n",
        "'''\n",
        "for count,ii in enumerate(bb_final):\n",
        "    if (ii ==  '[]'):\n",
        "        print(count, 'empty')\n",
        "    else:\n",
        "        print(count,'------bb')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "d0gCzw1azMxE",
        "outputId": "4d6a1344-c598-4c0b-a444-f607baa84962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18273\n",
            "18273\n",
            "18273\n",
            "1_pq8nn45n_a_x4g5x404_2.mp4-2022_01_10_00_50_42-labelme 3.0.zip\n",
            "112\n",
            "18273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor count,ii in enumerate(bb_final):\\n    if (ii ==  '[]'):\\n        print(count, 'empty')\\n    else:\\n        print(count,'------bb')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrkfWeZJB7Iv"
      },
      "source": [
        "# Bounding Box information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB8180Q-rGe7"
      },
      "outputs": [],
      "source": [
        "if (0):\n",
        "    #------not needed??\n",
        "    # Bounding box info\n",
        "    #\n",
        "\n",
        "    import torch\n",
        "    print('-------')\n",
        "    uvids = set(video_id)\n",
        "\n",
        "    for v in uvids:\n",
        "        for count,ii in enumerate(video_id):\n",
        "            if (v in ii):\n",
        "                #get bb info\n",
        "                box_info = bounding_box[count]\n",
        "                #box_info = box_info.strip('][') #.split(', ')\n",
        "\n",
        "                if (not (box_info =='[]')):\n",
        "                    \n",
        "                    corners=literal_eval(box_info)\n",
        "                    bbox = torch.FloatTensor(corners)\n",
        "                    #print(corners)\n",
        "                else:\n",
        "                    continue\n",
        "    '''\n",
        "    print(full_file_list[0])\n",
        "    if (use_busi == 1):\n",
        "        print('Adding BUSI bounding boxes')\n",
        "        for filename in full_file_list:\n",
        "            if ('BUSI_DATA' in filename):\n",
        "                print(filename)\n",
        "                #found one of our busi sets, check what category\n",
        "                #TODO  replace if set with scanf utility to get category\n",
        "                if ('malignant' in filename):\n",
        "                    print(filename)\n",
        "                    first50.append('M')\n",
        "                    bounding_box.append(mask_m_dict[])\n",
        "                    break\n",
        "    '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hbL1lkun1MR"
      },
      "source": [
        "#BOUNDING BOX STATISTICS **** ADJUST FOR BUSI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM1oXD-itHex",
        "outputId": "093f5455-5758-47fa-e9f4-e79b1eb4b92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos:  6\n",
            "Number of annotated cases  6\n",
            "Number of unannotated cases  0\n",
            "Videos with no Annotations: 0\n",
            "[165, 5031, 5395, 104, 65, 206]\n",
            "------- NO ANNOTATION VIDEOS --------\n",
            "[] [] [] /content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000000.PNG_600_800_105_569_134_721.pck\n",
            "[] [] [] /content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000002.PNG_600_800_105_569_134_721.pck\n",
            "[] [] [] /content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000001.PNG_600_800_105_569_134_721.pck\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)] /content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000003.PNG_600_800_105_569_134_721.pck\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)] /content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000004.PNG_600_800_105_569_134_721.pck\n",
            "[(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)] [(274, 197), (615, 197), (615, 395), (274, 395)] /content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000005.PNG_600_800_105_569_134_721.pck\n"
          ]
        }
      ],
      "source": [
        "if (training_set ==0):\n",
        "    ############################################################################\n",
        "    #\n",
        "    # UCLA DATA\n",
        "    ############################################################################\n",
        "    \n",
        "    #\n",
        "    # Reassign the updated set of csv data to the old names. This lets us resuse\n",
        "    # some of the pre-existing functions and code\n",
        "    #\n",
        "\n",
        "    #full_file_list.append(fname)\n",
        "    #bb_final.append(bounding_box[vcount])\n",
        "    #label_first50.append(first50[vcount])\n",
        "    #video_id_final.append(video_id[vcount])\n",
        "    #accession_final.append(accession[vcount])\n",
        "    #image_path_final.append(image_path[vcount])\n",
        "    #skip_points_final.append(skip_points)\n",
        "\n",
        "\n",
        "    bbox = []\n",
        "    first50 = []\n",
        "    video_id = []\n",
        "    image_path = []\n",
        "    accession = []\n",
        "\n",
        "    bbox = bb_final.copy()\n",
        "    first50=label_first50.copy()\n",
        "    video_id = video_id_final.copy()\n",
        "    image_path = image_path_final.copy()\n",
        "    accession = accession_final.copy()\n",
        "\n",
        "\n",
        "    #generate stats on bounding boxes\n",
        "\n",
        "    #get a list of all the unique video ids to remove the extra rows\n",
        "    uvids = set(video_id)\n",
        "\n",
        "    #\n",
        "    # Store metrics on bounding box information present\n",
        "    #\n",
        "    box_collect=[]\n",
        "    frames_collect=[]\n",
        "    empty_annotations=[]\n",
        "\n",
        "    for count, v in enumerate(uvids):\n",
        "        #go through each unique video name and do a search to find every \n",
        "        #match with that unique id\n",
        "        number_frames = 0\n",
        "        number_boxes = 0\n",
        "        \n",
        "        #print('---- loading: ', v)\n",
        "        for icount,ivideo in enumerate(video_id):\n",
        "            if (ivideo == v): #if the unique vid matches this video id\n",
        "\n",
        "                #print(icount,v,bounding_box[icount])\n",
        "                #print(csv_counter[icount],v,bounding_box[icount])\n",
        "                box_info = bb_final[icount] #bounding_box[icount]\n",
        "                number_frames+=1\n",
        "\n",
        "                #if ('1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip' in ivideo):\n",
        "                #if ('1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip' in ivideo):\n",
        "                #    print('{} {} {} {} {} {}'.format(icount, bb_final[icount],box_info,number_frames,image_path[icount],ivideo))\n",
        "                if ((box_info =='[]')):\n",
        "                    pass\n",
        "                else:\n",
        "                    number_boxes = number_boxes +1\n",
        "                    #print('no annotation', frame_id[icount])\n",
        "        #collect metrics on findings\n",
        "        frames_collect.append(number_frames)\n",
        "        box_collect.append(number_boxes)\n",
        "        #print(v,number_frames,number_boxes)\n",
        "        if (number_boxes == 0):\n",
        "            empty_annotations.append(v)\n",
        "            #print('EMPTY:   ',v)\n",
        "            \n",
        "\n",
        "\n",
        "    print('Number of videos: ',np.size(frames_collect[:]))\n",
        "    print('Number of annotated cases ',np.size(box_collect))\n",
        "    print('Number of unannotated cases ', np.size(empty_annotations))\n",
        "    print('Videos with no Annotations:', np.size(empty_annotations))\n",
        "    print(box_collect)\n",
        "        #get_bb_stats(v, video_id,bounding_box, image_path)\n",
        "\n",
        "    print('------- NO ANNOTATION VIDEOS --------')\n",
        "    for ii in range(0,6):\n",
        "        print(bbox[ii],bb_final[ii],bounding_box[ii],image_path[ii] )\n",
        "\n",
        "\n",
        "else:\n",
        "    print('Skipping Bounding box statistics for UCLA data')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ucla_pickle_list[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2NOyiZKGgka",
        "outputId": "3caee24c-a824-48a1-bbc6-c9bab33842a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000000.PNG_600_800_105_569_134_721.pck',\n",
              " '/content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000002.PNG_600_800_105_569_134_721.pck',\n",
              " '/content/gdrive/My Drive/BreastUS/0TO1NORM/UCLA_DATA_CONTRAST_EQUALIZED/1_076up782_a_dcc4675o_0.mp4-2021_09_03_16_33_59-labelme 3.0.zip/default/frame_000001.PNG_600_800_105_569_134_721.pck']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(video_id))\n",
        "print(len(bounding_box))\n",
        "print(len(video_id))\n",
        "print(bb_final)\n",
        "#for ii in range(0,len(bb_final)):\n",
        "#    print(ii,video_id[ii], bounding_box[ii])\n",
        "\n",
        "vcount = 0\n",
        "#for counter, vv in enumerate(video_id_final):\n",
        "#    if ('1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip' in vv):\n",
        "#        vcount +=1\n",
        "#        print(vcount,counter,vv,bb_final[counter])\n",
        "\n",
        "for ii in range(15500,15796):\n",
        "    print(ii, video_id_final[ii], bb_final[ii]  )\n",
        "\n",
        "stop\n",
        "#for ii in range(0,100):\n",
        "#    print(bounding_box[ii],video_id[ii], frame_id[ii])\n",
        "'''\n",
        "array_rows = np.array(annotation_rows)\n",
        "csv_counter = array_rows[:,0] #csv line number\n",
        "mrn = array_rows[:,1]\n",
        "accession = array_rows[:,2]\n",
        "video_id = array_rows[:,3]\n",
        "frame_id = array_rows[:,4]\n",
        "image_path = array_rows[:,5]\n",
        "bounding_box = array_rows[:,6]\n",
        "diagnosis = array_rows[:,7]\n",
        "biopsy_site = array_rows[:,8]\n",
        "diagnosis2 = array_rows[:,9]\n",
        "first50 = array_rows[:,10]\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MBRViP0xbli6",
        "outputId": "245cdff8-776c-4c83-8b0b-863a498115a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18273\n",
            "18688\n",
            "18273\n",
            "['[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[(328, 167), (564, 167), (564, 334), (328, 334)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[(393, 193), (596, 193), (596, 353), (393, 353)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[(346, 128), (624, 128), (624, 339), (346, 339)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[(422, 169), (633, 169), (633, 332), (422, 332)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(286, 179), (610, 179), (610, 414), (286, 414)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(265, 207), (641, 207), (641, 449), (265, 449)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(377, 127), (675, 127), (675, 317), (377, 317)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[(366, 125), (653, 125), (653, 308), (366, 308)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[(234, 125), (636, 125), (636, 446), (234, 446)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[(389, 205), (522, 205), (522, 307), (389, 307)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(256, 149), (656, 149), (656, 457), (256, 457)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[(193, 114), (688, 114), (688, 458), (193, 458)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[(276, 248), (474, 248), (474, 363), (276, 363)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[(274, 187), (488, 187), (488, 338), (274, 338)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(180, 106), (728, 106), (728, 465), (180, 465)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(186, 117), (731, 117), (731, 446), (186, 446)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(165, 120), (720, 120), (720, 441), (165, 441)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(164, 125), (738, 125), (738, 471), (164, 471)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[(187, 125), (723, 125), (723, 431), (187, 431)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[(346, 208), (486, 208), (486, 280), (346, 280)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(272, 166), (590, 166), (590, 411), (272, 411)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(259, 148), (470, 148), (470, 290), (259, 290)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[(358, 147), (524, 147), (524, 282), (358, 282)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[(239, 196), (633, 196), (633, 411), (239, 411)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[(377, 249), (507, 249), (507, 353), (377, 353)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(401, 250), (540, 250), (540, 329), (401, 329)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[(346, 260), (432, 260), (432, 343), (346, 343)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(203, 129), (683, 129), (683, 445), (203, 445)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[(184, 129), (654, 129), (654, 429), (184, 429)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[(237, 389), (237, 521), (352, 521), (352, 389)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[(191, 349), (191, 474), (306, 474), (306, 349)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[(130, 335), (130, 464), (221, 464), (221, 335)]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]']\n",
            "15500 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15501 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15502 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15503 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15504 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15505 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15506 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15507 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15508 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15509 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15510 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15511 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15512 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15513 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15514 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15515 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15516 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15517 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15518 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15519 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15520 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15521 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15522 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15523 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15524 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15525 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15526 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15527 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15528 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15529 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15530 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15531 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15532 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15533 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15534 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15535 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15536 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15537 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15538 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15539 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15540 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15541 1_dgw51j3w_a_531r5jn5_1.mp4-2022_01_31_00_07_11-labelme 3.0.zip []\n",
            "15542 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15543 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15544 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15545 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15546 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15547 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15548 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15549 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15550 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15551 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15552 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15553 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15554 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15555 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15556 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15557 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15558 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15559 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15560 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15561 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15562 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15563 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15564 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15565 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15566 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15567 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15568 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15569 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15570 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15571 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15572 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15573 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15574 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15575 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15576 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15577 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15578 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15579 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15580 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15581 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15582 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15583 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15584 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15585 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15586 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15587 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15588 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15589 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15590 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15591 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15592 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15593 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15594 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15595 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15596 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15597 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15598 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15599 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15600 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15601 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15602 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15603 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15604 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15605 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15606 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15607 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15608 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15609 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15610 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15611 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15612 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15613 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15614 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15615 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15616 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15617 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15618 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15619 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15620 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15621 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15622 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15623 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15624 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15625 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15626 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15627 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15628 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15629 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15630 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15631 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15632 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15633 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15634 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15635 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15636 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15637 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15638 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15639 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15640 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15641 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15642 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15643 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15644 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15645 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15646 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15647 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15648 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15649 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15650 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15651 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15652 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15653 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15654 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15655 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15656 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15657 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15658 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15659 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15660 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15661 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15662 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15663 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15664 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15665 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15666 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15667 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15668 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15669 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15670 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15671 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15672 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15673 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15674 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15675 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15676 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15677 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15678 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15679 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15680 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15681 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15682 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15683 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15684 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15685 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15686 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15687 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15688 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15689 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15690 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15691 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15692 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15693 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15694 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15695 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15696 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15697 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15698 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15699 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15700 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15701 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15702 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15703 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15704 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15705 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15706 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15707 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15708 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15709 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15710 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15711 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15712 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15713 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15714 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15715 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15716 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15717 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15718 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15719 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15720 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15721 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15722 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15723 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15724 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15725 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15726 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15727 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15728 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15729 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15730 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15731 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15732 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15733 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15734 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15735 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15736 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15737 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15738 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15739 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15740 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15741 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15742 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15743 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15744 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15745 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15746 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15747 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15748 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15749 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15750 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15751 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15752 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15753 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15754 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15755 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15756 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15757 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15758 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15759 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15760 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15761 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15762 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15763 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15764 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15765 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15766 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15767 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15768 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15769 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15770 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15771 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15772 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15773 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15774 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15775 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15776 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15777 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15778 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15779 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15780 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15781 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15782 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15783 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15784 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15785 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15786 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15787 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15788 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15789 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15790 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15791 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15792 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15793 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15794 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n",
            "15795 1_4u573x42_a_3k55o0c8_1.mp4-2022_02_04_22_29_00-labelme 3.0.zip []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-87d599e4f0ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#for ii in range(0,100):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#    print(bounding_box[ii],video_id[ii], frame_id[ii])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoFrtsmB_PNG"
      },
      "outputs": [],
      "source": [
        "if (training_set ==0):\n",
        "\n",
        "    #bounding_box\n",
        "    ta,box_num,num_h, num_w=get_bb_stats(bounding_box)\n",
        "\n",
        "    avg_area = sum(ta)/len(ta)\n",
        "    print(avg_area)\n",
        "\n",
        "    #avg width\n",
        "    print(np.average(num_w))\n",
        "    #get smallest box\n",
        "\n",
        "    print('smallest width is ', np.min(num_w))\n",
        "    print('largest width is  ', np.max(num_w))\n",
        "\n",
        "    #avg height\n",
        "    print(np.average(num_h))\n",
        "    print('smallest height is ', np.min(num_h))\n",
        "    print('largest height is  ',np.max(num_h))\n",
        "\n",
        "    vv,_,_=plt.hist(num_h, bins = 50)\n",
        "    plt.title('h')\n",
        "    print('-----',vv)\n",
        "\n",
        "    for ii in range(0,5):\n",
        "        bin_max = np.max(vv[ii*10:ii*10+9])\n",
        "        print('max Height bin is ', ii,bin_max)\n",
        "\n",
        "    vv,_,_=plt.hist(num_w, bins = 50)\n",
        "    plt.title('w')\n",
        "    print('-----',vv)\n",
        "\n",
        "    for ii in range(0,5):\n",
        "        bin_max = np.max(vv[ii*10:ii*10+9])\n",
        "        print('max Width bin is ', ii,bin_max)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(num_h, bins=50,alpha=0.5, label=\"Heights\")\n",
        "    plt.hist(num_w,bins=50,alpha=0.5, label=\"Widths\")\n",
        "    plt.title('Histogram of Annotation Heights')\n",
        "    plt.ylabel('Number of Occurences')\n",
        "    plt.xlabel('Annotation Length (pixels)')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(num_w,bins=50,alpha=0.5, label=\"Widths\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amG8T6UodFdV"
      },
      "source": [
        "#SPLIT INTO TRAIN/VAL/TEST FOLDERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEBbhgjdc_FZ"
      },
      "outputs": [],
      "source": [
        "if (training_set ==0):\n",
        "\n",
        "    #break into a training and validation set\n",
        "    '''\n",
        "    array_rows = np.array(annotation_rows)\n",
        "    mrn = array_rows[:,1]\n",
        "    accession = array_rows[:,2]\n",
        "    video_id = array_rows[:,3]\n",
        "    frame_id = array_rows[:,4]\n",
        "    image_path = array_rows[:,5]\n",
        "    bounding_box = array_rows[:,6]\n",
        "    diagnosis = array_rows[:,7]\n",
        "    biopsy_site = array_rows[:,8]\n",
        "    diagnosis2 = array_rows[:,9]\n",
        "    first50 = array_rows[:,10]\n",
        "    '''\n",
        "    types_acc = np.unique(accession)\n",
        "    num_acc = len(types_acc)\n",
        "    print('number of csv rows found: ', len(array_rows))\n",
        "    print('number of unique accs is ', num_acc, len(accession))\n",
        "\n",
        "    unique_vidid = np.unique(video_id)\n",
        "\n",
        "    train_pct = 0.6\n",
        "    val_pct = 0.2\n",
        "    test_pct = 1-train_pct-val_pct\n",
        "\n",
        "\n",
        "    cancer_status ={}\n",
        "    for vname in unique_vidid:\n",
        "        for pcount, pathname in enumerate(image_path):\n",
        "            if (vname in pathname):\n",
        "                cancer_status[vname] = first50[pcount]\n",
        "                break\n",
        "\n",
        "    print(cancer_status)\n",
        "    print(cancer_status.values())\n",
        "\n",
        "    vid_vals = list(cancer_status.keys())\n",
        "    cvals = list(cancer_status.values())\n",
        "    print(cvals)\n",
        "    print(vid_vals)\n",
        "\n",
        "\n",
        "    '''\n",
        "    #Remove the bad counters \n",
        "    bad_files = os.path.join(local_dir,'counters_to_remove.pickle')\n",
        "    bad_count = pickle.load( open( bad_files, \"rb\" ) )\n",
        "    print(len(bad_count[0]))\n",
        "\n",
        "    bad_vidid = np.unique(video_id[bad_count[0]])\n",
        "    print('bad video ids: ', bad_vidid)\n",
        "\n",
        "\n",
        "    good_list=[]\n",
        "\n",
        "    for counter,ii in enumerate(image_path):\n",
        "        skip_me = 0\n",
        "        for jj in bad_vidid:\n",
        "            if(jj in video_id[counter]):\n",
        "                print('bad video id found: ',ii)\n",
        "                skip_me=1\n",
        "                break\n",
        "\n",
        "        if (skip_me == 1):\n",
        "            good_list.append(counter)\n",
        "\n",
        "    '''\n",
        "    #print(len(bad_vidid))\n",
        "    print('len of image path is ', len(image_path))#, len(bad_vidid), len(bad_count[0]))\n",
        "    #print('len good list: ',len(good_list))\n",
        "\n",
        "    '''\n",
        "    print(image_path[good_list[0]])\n",
        "    print('bad count = ', bad_count[0][80:90])\n",
        "    print(image_path[bad_count[0][500]])\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RUpGJ6G1-wQ"
      },
      "source": [
        "#Test out cropping on bad images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHxQO_g517VJ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Test all of the bad crops against new crop functions\n",
        "#\n",
        "\n",
        "if(0):\n",
        "    #Remove the bad counters \n",
        "    bad_files = os.path.join(local_dir,'counters_to_remove.pickle')\n",
        "    bad_count = pickle.load( open( bad_files, \"rb\" ) )\n",
        "    print(len(bad_count[0]))\n",
        "\n",
        "    number_failed = []\n",
        "    for ii in bad_count[0]:\n",
        "        filename = full_file_list[ii]\n",
        "        print('now on file ',ii)\n",
        "        #print(filename)\n",
        "\n",
        "        img_data = image.imread(filename)\n",
        "        ## Convert the RGB input into grayscale\n",
        "        R, G, B = img_data[:,:,0], img_data[:,:,1], img_data[:,:,2]\n",
        "        imgGray = 0.2989 * R + 0.5870 * G + 0.1140 * B\n",
        "\n",
        "\n",
        "        #crop_img, skipped, status= crop_us_image(imgGray,debug =1)\n",
        "        binary_image=(imgGray>0).astype(int)\n",
        "        #print('shape in ',np.shape(binary_image))\n",
        "        #print('sum is ', np.sum(binary_image[:,0]))\n",
        "        nr,nc = np.shape(binary_image)\n",
        "        cen_row = np.uint(nr/2)\n",
        "        cen_col = np.uint(nc/2)\n",
        "        #print('cenc col ', cen_col)\n",
        "        #print('cen row ', cen_row)\n",
        "        #plt.figure()\n",
        "        #plt.imshow(binary_image, cmap='gray')\n",
        "        colum_edges, cstatus= extract_edge(binary_image, nc, cen_col,roworcol=1)\n",
        "        row_edges, rstatus =  extract_edge(binary_image, nr,cen_row,roworcol=0)\n",
        "\n",
        "        if ((cstatus == 0) or (rstatus == 0)):\n",
        "            print('-----failed crop')\n",
        "            number_failed.append(ii)\n",
        "\n",
        "\n",
        "        '''\n",
        "        #plt.figure()\n",
        "        #plt.imshow(binary_image[row_edges[0]:row_edges[1],column_edges[0]:column_edges[1]],cmap='gray')\n",
        "        break\n",
        "        '''\n",
        "    bad_remaining = os.path.join(local_dir,'remaining_bad_counters_to_remove.pickle')\n",
        "    pickle.dump(number_failed,open( bad_remaining, \"wb\" ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44VxBT_tRpQ_"
      },
      "source": [
        "#REMOVE PRE-DETERMINED LIST OF UNCROPPABLE IMAGES\n",
        "---- REMOVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ7b9QluP_Qg"
      },
      "outputs": [],
      "source": [
        "#skipped due to a better cropping setup\n",
        "if (0):\n",
        "    #Remove the bad counters \n",
        "    bad_files = os.path.join(local_dir,'counters_to_remove.pickle')\n",
        "    bad_count = pickle.load( open( bad_files, \"rb\" ) )\n",
        "    print(len(bad_count[0]))\n",
        "\n",
        "    new_flist =[]\n",
        "    new_bb = []\n",
        "    new_first50=[]\n",
        "    for counter, fname in enumerate(full_file_list):\n",
        "        if counter in bad_count[0]:\n",
        "            print('found bad counter ',counter)\n",
        "        else:\n",
        "            new_flist.append(fname)\n",
        "            new_bb.append(bounding_box[counter])\n",
        "            new_first50.append(first50[counter])\n",
        "\n",
        "    full_file_list = new_flist\n",
        "    bounding_box = new_bb\n",
        "    first50=new_first50\n",
        "else:\n",
        "    print('All Data Sets added to lists')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUcjXKXr8NZ8"
      },
      "source": [
        "#ASSIGN TRAINING/VALIDATION/TEST FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFV5QSHG5In4"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_val_dataset(dataset, val_split=0.20):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))),\n",
        "                                          test_size=val_split)\n",
        "    #datasets = {}\n",
        "    #datasets['train'] = Subset(dataset, train_idx)\n",
        "    #datasets['val'] = Subset(dataset, val_idx)\n",
        "    return train_idx, val_idx #datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7n97HTHtQA"
      },
      "source": [
        "#Split BUSI Data into Train/Val sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPmkh1r56Gw5"
      },
      "outputs": [],
      "source": [
        "#Split the BUSI data files, as they're not related sets\n",
        "if (training_set == 1): #mixed -- no longer used\n",
        "\n",
        "    t,v = train_val_dataset(full_file_list[8842:], val_split=0.2)\n",
        "    for counter, ii in enumerate(t):\n",
        "        t[counter] = ii+original_file_length\n",
        "    for counter, ii in enumerate(v):\n",
        "        v[counter] = ii + original_file_length\n",
        "\n",
        "    print(len(full_file_list))\n",
        "    print(np.max(t), np.max(v))\n",
        "    for ii in t:\n",
        "        print(full_file_list[ii])\n",
        "    \n",
        "    stop\n",
        "elif(training_set == 2):\n",
        "    print('Splitting ONLY BUSI data')\n",
        "    t,v = train_val_dataset(full_file_list, val_split=0.2)\n",
        "\n",
        "    print(len(full_file_list), len(t), len(v))\n",
        "    print(np.max(t), np.max(v))\n",
        "    for ii in t:\n",
        "        print(full_file_list[ii])\n",
        "else:\n",
        "    print('Non-BUSI being used.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ABHNGsElYCU"
      },
      "outputs": [],
      "source": [
        "if (training_set ==0):\n",
        "\n",
        "    num_train = np.uint16(np.floor(train_pct*len(unique_vidid)))\n",
        "    num_val = np.floor(val_pct*len(unique_vidid))\n",
        "    num_test = np.uint16(np.floor(test_pct*len(unique_vidid)))\n",
        "\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    test_list = []\n",
        "    train_labels=[]\n",
        "    val_labels =[]\n",
        "    test_labels = []\n",
        "    train_box =[]\n",
        "    val_box=[]\n",
        "    test_box = []\n",
        "\n",
        "    '''\n",
        "    train_skip =[]\n",
        "    val_skip =[]\n",
        "    test_skip =[]\n",
        "    '''\n",
        "\n",
        "    \n",
        "    train_vidid=[]\n",
        "    val_vidid = []\n",
        "    test_vidid = []\n",
        "\n",
        "    print('num unique vid id ',len(unique_vidid))\n",
        "    train_length = train_pct * len(unique_vidid)\n",
        "    val_length = val_pct * len(unique_vidid)\n",
        "    test_length = test_pct * len(unique_vidid)\n",
        "\n",
        "    for counter, vname in enumerate(unique_vidid):\n",
        "        if (counter <= train_length): #train_pct*len(unique_vidid)): #*100):\n",
        "            train_vidid.append(vname)\n",
        "        elif ((counter > train_length) and (counter <= (train_length +val_length))):\n",
        "            val_vidid.append(vname)\n",
        "        else:\n",
        "            test_vidid.append(vname)\n",
        "\n",
        "    for counter, filename in enumerate(full_file_list):\n",
        "\n",
        "        for vname in train_vidid:\n",
        "            if(vname in filename):\n",
        "                train_list.append(filename)\n",
        "                train_labels.append(first50[counter])\n",
        "                train_box.append(bounding_box[counter])\n",
        "                #train_skip.append(skip_points_final[counter])\n",
        "                break\n",
        "                    \n",
        "        for vname in val_vidid:\n",
        "            if(vname in filename):   \n",
        "                val_list.append(filename)\n",
        "                val_labels.append(first50[counter])\n",
        "                val_box.append(bounding_box[counter])\n",
        "                #val_skip.append(skip_points_final[counter])\n",
        "                break\n",
        "\n",
        "        for vname in test_vidid:\n",
        "            if(vname in filename):   \n",
        "                test_list.append(filename)\n",
        "                test_labels.append(first50[counter])\n",
        "                test_box.append(bounding_box[counter])\n",
        "                #test_skip.append(skip_points_final[counter])\n",
        "                break                \n",
        "\n",
        "\n",
        "elif (training_set == 2):\n",
        "    #Add BUSI data to the end of the lists\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    test_list = []\n",
        "    train_labels=[]\n",
        "    val_labels =[]\n",
        "    test_labels = []\n",
        "    train_box =[]\n",
        "    val_box=[]\n",
        "    test_box = []\n",
        "    for counter, ii in enumerate(t):\n",
        "        train_list.append(full_file_list[ii])\n",
        "        train_labels.append(first50[ii])\n",
        "        train_box.append(bounding_box[ii])\n",
        "    for counter, ii in enumerate(v):\n",
        "        val_list.append(full_file_list[ii])\n",
        "        val_labels.append(first50[ii])\n",
        "        val_box.append(bounding_box[ii])\n",
        "\n",
        "else:\n",
        "    print('Mixed Data (UCLA + BUSI) no longer allowed')\n",
        "    '''\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    train_labels=[]\n",
        "    val_labels =[]\n",
        "    train_box =[]\n",
        "    val_box=[]\n",
        "\n",
        "\n",
        "    for counter,dir_name in enumerate(train_vidid):\n",
        "        print(dir_name)\n",
        "        for ii in os.path.join()\n",
        "        train_list.append(fname)\n",
        "    '''\n",
        "\n",
        "#print the files used for later stages and their labes and boxes\n",
        "data_file = os.path.join(model_dir,'train_val_test_data.pickle')\n",
        "pickle.dump([train_list,\n",
        "            train_labels,\n",
        "            train_box,\n",
        "            val_list,\n",
        "            val_labels,\n",
        "            val_box, \n",
        "            test_list,\n",
        "            test_labels,\n",
        "            test_box,],open( data_file, \"wb\" ),protocol=5 )\n",
        "print('Finished writing file data to disk')\n",
        "\n",
        "print('--- ',len(train_list), len(val_list), len(test_list)) #,num_train, num_val,num_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hwrX7xUaZ34"
      },
      "source": [
        "#DEBUG: CROP AND ANNOTATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGlW0--cnug8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#MISSING SKIP COORDINATES, SO ANNOTATIONS ARE NOT CORRECT\n",
        "if(0):\n",
        "    boxes=[]\n",
        "  \n",
        "    ii= 6255\n",
        "    print(train_list[ii])\n",
        "    img = pickle.load( open( train_list[ii], \"rb\" ) )\n",
        "    #img = image.imread(train_list[ii])\n",
        "    print('--- ', len(train_box[ii]))\n",
        "    pos=literal_eval(train_box[ii])\n",
        "\n",
        "\n",
        "    print('pos length = ',len(pos))\n",
        "    if (len(pos) <1 ):\n",
        "        print('no annotation to view')\n",
        "    else:\n",
        "        pos = np.int32(pos)\n",
        "        xmin = pos[0][0]\n",
        "        xmax = pos[1][0]\n",
        "        ymin = pos[0][1]\n",
        "        ymax = pos[2][1]\n",
        "\n",
        "        print('bounding box = (xmin,ymin,xmax,ymax) ', xmin, ymin, xmax,ymax)\n",
        "\n",
        "        ### Correct for the cropped image as annotation points are for the \n",
        "        ### main image with subset\n",
        "\n",
        "        skip_points = []\n",
        "        for xx in skip_points_final[ii]:\n",
        "            skip_points.append(int(xx))\n",
        "        print('skip points = ', skip_points)\n",
        "        offset_row = ymin-skip_points[0]\n",
        "        offset_col = xmin-skip_points[2]\n",
        "        max_row = ymax - skip_points[0]\n",
        "        max_col = xmax - skip_points[2]\n",
        "\n",
        "        #boxes.append([offset_col, offset_row, \n",
        "        #              xmax-skip_points[2], \n",
        "        #              ymax-skip_points[0]])\n",
        "\n",
        "        nr,nc = np.shape(img[0,:,:]) #this is the new resized image\n",
        "        oldc = 610\n",
        "        oldr = 800\n",
        "        box_scalex = nc/oldc\n",
        "        box_scaley = nr/oldr\n",
        "        x0 = offset_col * box_scalex\n",
        "        y0 = offset_row * box_scaley\n",
        "        x1 = max_col * box_scalex\n",
        "        y1 = max_row * box_scaley\n",
        "\n",
        "        print('scalex,y = ', box_scalex, box_scaley)\n",
        "        w = x1-x0\n",
        "        h = y1-y0\n",
        "        if ((w <10) or (h <10)):\n",
        "            print('!!!!!! Unusable h/w found: ',h,w)\n",
        "            print(x0,y0,w,h)\n",
        "            print('box scale x,y ',box_scalex, box_scaley)\n",
        "            print('xmin,ymin,xmax,ymax ',xmin,ymin,xmax,ymax)\n",
        "            print('index is ',index)\n",
        "            print('skip points ',skip_points)\n",
        "            print('offset col, row =',offset_col, offset_row)\n",
        "        boxes.append([x0,y0,x1,y1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        target_boxes = [x0,y0,x1,y1] #pos #train_box[ii]\n",
        "        plt.figure()\n",
        "        plt.imshow(img[1,:,:],cmap='gray')\n",
        "\n",
        "\n",
        "        print(target_boxes)\n",
        "        ax = plt.gca()\n",
        "        rect2 = patches.Rectangle((np.uint(x0),\n",
        "                                np.uint(y0)),\n",
        "                                np.uint(x1)-(np.uint(x0)),\n",
        "                                np.uint(y1)-(np.uint(y0)),\n",
        "                                linewidth=1.2,edgecolor='k',facecolor='none')\n",
        "\n",
        "\n",
        "            # Add the patch to the Axes\n",
        "\n",
        "        if (len(target_boxes)==0):\n",
        "            legend_text = ['Prediction']\n",
        "        else:\n",
        "            ax.add_patch(rect2)\n",
        "            legend_text = ['Prediction', 'Annotation']\n",
        "        plt.legend(legend_text)\n",
        "        plt.colorbar()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko8A-AF-RTLh"
      },
      "outputs": [],
      "source": [
        "for counter,ii in enumerate(train_box):\n",
        "    print(counter, ii)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzxqwcYqcfdE"
      },
      "source": [
        "#SET UP TRAINING DATA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-0XJgWWHnPz"
      },
      "outputs": [],
      "source": [
        "#load up with the pre-sized patch images\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "'''\n",
        "training_data = CustomDataset(img_dir=annotated_dir,\n",
        "                                label_data = first50,\n",
        "                                category = '', #full_category_name, \n",
        "                                file_count=len(full_file_list), #full_file_count,\n",
        "                                file_list = full_file_list, \n",
        "                                transform=None, \n",
        "                                target_transform=None)\n",
        "'''\n",
        "\n",
        "training_data = CustomDataset(img_dir=annotated_dir,\n",
        "                                bounding_boxes = train_box,\n",
        "                                label_data = train_labels,\n",
        "                                category = '', #full_category_name, \n",
        "                                file_count=len(train_list), #full_file_count,\n",
        "                                file_list = train_list, \n",
        "                                data_type = training_set, #0=UCLA, 1 = BUSI\n",
        "                                transform=None, \n",
        "                                target_transform=None)\n",
        "\n",
        "\n",
        "\n",
        "validation_data = CustomDataset(img_dir=annotated_dir,\n",
        "                                bounding_boxes = val_box,\n",
        "                                label_data = val_labels,\n",
        "                                category = '', #full_category_name, \n",
        "                                file_count=len(val_list), #full_file_count,\n",
        "                                file_list = val_list,\n",
        "                                data_type = training_set, #0=UCLA, 1 = BUSI\n",
        "                                transform=None, \n",
        "                                target_transform=None)\n",
        "\n",
        "\n",
        "test_data = CustomDataset(img_dir=annotated_dir,\n",
        "                                bounding_boxes = test_box,\n",
        "                                label_data = test_labels,\n",
        "                                category = '', #full_category_name, \n",
        "                                file_count=len(test_list), #full_file_count,\n",
        "                                file_list = test_list,\n",
        "                                data_type = training_set, #0=UCLA, 1 = BUSI\n",
        "                                transform=None, \n",
        "                                target_transform=None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-ci4ZDzv0_O"
      },
      "source": [
        "#Save Train/Val/Test data sets for reuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5EfBZoUvz9n"
      },
      "outputs": [],
      "source": [
        "#Save the generated data for use in restarting epochs to avoid mixing training\n",
        "#data with val or test data\n",
        "\n",
        "if(1):\n",
        "    stored_data =[training_data, validation_data, test_data, bounding_box,\n",
        "                first50]\n",
        "    last_data_file = os.path.join(model_dir,'last_data_set.pickle')\n",
        "    pickle.dump([stored_data],open( last_data_file, \"wb\" ),protocol=5 )\n",
        "    print('****** STORED GENERATED DATA SETS *******')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GTnnttazqte"
      },
      "outputs": [],
      "source": [
        "def bb_intersection_over_union(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = abs(max(0, xB - xA + 1) * max(0, yB - yA + 1))\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yxSxZdbJi9f"
      },
      "source": [
        "#Keep_HighScore Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nef9kjEpzzYn"
      },
      "outputs": [],
      "source": [
        "def keep_Highscore(output):\n",
        "    processed_dict = []\n",
        "    processed_dict_scores=[]\n",
        "    processed_dict_labels=[] #for use in the metrics\n",
        "    for i in range(len(output)):\n",
        "        out = output[i]['boxes'].cpu().numpy().squeeze()\n",
        "        scores = output[i]['scores'].cpu().numpy().squeeze()\n",
        "        labels = output[i]['labels'].cpu().numpy().squeeze()\n",
        "        if len(out.shape) > 1:\n",
        "            if len(out) == 0:\n",
        "                processed_dict.append({'boxes': []})\n",
        "                processed_dict_scores.append({'scores': []})\n",
        "                processed_dict_labels.append({'labels': []})\n",
        "            else:\n",
        "                #keep the maximum score\n",
        "                processed_dict_scores.append({'scores': scores[np.argmax(scores)]})\n",
        "                processed_dict.append({'boxes': out[np.argmax(scores)]})\n",
        "                processed_dict_labels.append({'labels': labels[np.argmax(scores)]})\n",
        "        elif (len(out.shape) == 1):\n",
        "            processed_dict.append({'boxes': out})\n",
        "            processed_dict_scores.append({'scores': scores}) #out[np.argmax(scores)]})\n",
        "\n",
        "            processed_dict_labels.append({'labels': labels}) #labels[np.argmax(scores)]})\n",
        "        else:\n",
        "            print('Found a non-matched highest output size ', len(out.shape))\n",
        "            print('keep high --scores ',scores)\n",
        "            print('labels, argmax', labels,np.argmax(scores))\n",
        "            print('shape = ', len(out.shape) ,np.shape(out),np.shape(scores),np.shape(labels))\n",
        "            print('** ',labels[0])\n",
        "           \n",
        "            print('-----> ', labels[np.argmax(scores)])\n",
        "    return processed_dict, processed_dict_scores, processed_dict_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTOk6K7zskap"
      },
      "source": [
        "#IOU Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XzzVsW8Wspz"
      },
      "outputs": [],
      "source": [
        "def IOU(box1, box2):\n",
        "\n",
        "    db_print = 1\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x3, y3, x4, y4 = box2\n",
        "    x_inter1 = max(x1, x3)\n",
        "    y_inter1 = max(y1, y3)\n",
        "    x_inter2 = min(x2, x4)\n",
        "    y_inter2 = min(y2, y4)\n",
        " \n",
        "    if (db_print ==1):\n",
        "        print('IOU calc:----')\n",
        "        print('box1, box2, xinter1, yinter1, xinter2, yinter2')\n",
        "        print(box1)\n",
        "        print(box2)\n",
        "        print(x_inter1, y_inter1, x_inter2, y_inter2)\n",
        "        print('----')\n",
        "\n",
        "    width_inter = abs(x_inter2 - x_inter1)\n",
        "    height_inter = abs(y_inter2 - y_inter1)\n",
        "    area_inter = width_inter * height_inter\n",
        "    width_box1 = abs(x2 - x1)\n",
        "    height_box1 = abs(y2 - y1)\n",
        "    width_box2 = abs(x4 - x3)\n",
        "    height_box2 = abs(y4 - y3)\n",
        "    area_box1 = width_box1 * height_box1\n",
        "    area_box2 = width_box2 * height_box2\n",
        "    area_union = area_box1 + area_box2 - area_inter\n",
        "\n",
        "    if (db_print == 1):\n",
        "        print('IOU calc2:----')\n",
        "        print('areaunion = areabox1 + areabox2 - area_intersection')\n",
        "        print('area box 1, box2, area union:')\n",
        "        print(area_box1, area_box2, area_union)\n",
        "        print('area inter = ', area_inter)\n",
        "\n",
        "    iou = area_inter / area_union\n",
        "\n",
        "\n",
        "    ''' \n",
        "    We assume that the box follows the format:\n",
        "    box1 = [x1,y1,x2,y2], and box2 = [x3,y3,x4,y4],\n",
        "    where (x1,y1) and (x3,y3) represent the top left coordinate,\n",
        "    and (x2,y2) and (x4,y4) represent the bottom right coordinate \n",
        "    '''\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-29Kav9kH-5p"
      },
      "outputs": [],
      "source": [
        "\n",
        "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "#summary(modelr)\n",
        "#del modelr\n",
        "#summary(modelr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snJpkHyrCBz1"
      },
      "source": [
        "# Model Import/Design\n",
        "-- load a pre-trained model here, as we may want to load it outside of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_uPk5EJ1dsy"
      },
      "outputs": [],
      "source": [
        "\n",
        "#anchor_generator = AnchorGenerator(sizes=((64, 128,256, 512, 600),),\n",
        "#                                   aspect_ratios=((0.5, 0.75, 1.0),))\n",
        "\n",
        "#Set Anchor sizes and aspect\n",
        "#anchor_sizes = ((64,), (128,), (256,), (512,), (600,)) \n",
        "anchor_sizes = ((32,), (64,), (128,), (256,), (512,)) \n",
        "aspect_ratios = ((0.5, 0.75, 1.0),) * len(anchor_sizes) \n",
        "anchor_generator = AnchorGenerator(anchor_sizes, aspect_ratios)\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "modelr=torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, \n",
        "                                                            num_classes=2,\n",
        "                                                            pretrained_backbone=True)\n",
        "#modelr = torchvision.models.detection.maskrcnn_resnet50_fpn(num_classes=2)\n",
        "#resnet50_fpn = torchvision.models.detection.maskrcnn_resnet50_fpn(num_classes=2)\n",
        "\n",
        "'''\n",
        "backbone_fpn = nn.Sequential(\n",
        "\tresnet50_fpn.backbone.body.conv1,\n",
        "\tresnet50_fpn.backbone.body.bn1,\n",
        "\tresnet50_fpn.backbone.body.relu,\n",
        "\tresnet50_fpn.backbone.body.maxpool,\n",
        "\tresnet50_fpn.backbone.body.layer1,\n",
        "\tresnet50_fpn.backbone.body.layer2,\n",
        "\tresnet50_fpn.backbone.body.layer3,\n",
        "\tresnet50_fpn.backbone.body.layer4\n",
        "\t)\n",
        "backbone_fpn.out_channels = 2048\n",
        "modelr = FasterRCNN(backbone_fpn,num_classes=2,rpn_anchor_generator=anchor_generator)\n",
        "'''\n",
        "\n",
        "#resnet_net = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "'''\n",
        "modules = list(resnet_net.children())[:-1]\n",
        "backbone = nn.Sequential(*modules)\n",
        "backbone.out_channels = 2048\n",
        "#backbone = resnet50_fpn('resnet50', pretrained_backbone)\n",
        "modelr = FasterRCNN(backbone,num_classes=2,rpn_anchor_generator=anchor_generator)\n",
        "#resnet50_fpn.out_channels=2048\n",
        "#modelr = FasterRCNN(resnet50_fpn,num_classes=2,rpn_anchor_generator=anchor_generator)\n",
        "'''\n",
        "#num_features = modelr.in_features\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "# get the number of input features \n",
        "in_features = modelr.roi_heads.box_predictor.cls_score.in_features\n",
        "# define a new head for the detector with required number of classes\n",
        "modelr.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
        "modelr.rpn.anchor_generator = anchor_generator   #adding in customized anchors\n",
        "\n",
        "\n",
        "#freeze all layers\n",
        "for param in modelr.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#kaggle setup\n",
        "#unfreeze the classification and box prediction \n",
        "for p in modelr.roi_heads.box_predictor.parameters():\n",
        "    p.requires_grad =True\n",
        "\n",
        "for p in modelr.rpn.parameters():\n",
        "    p.requires_grad = True #True\n",
        "\n",
        "for p in modelr.backbone.fpn.parameters():\n",
        "    p.requires_grad = False #True\n",
        "\n",
        "for p in modelr.roi_heads.box_head.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "#save parameters requiring a gradient update\n",
        "params = [p for p in modelr.parameters() if p.requires_grad]\n",
        "print(summary(modelr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# freeze the fc6 layer in roi_heads\n",
        "'''\n",
        "for p in modelr.roi_heads.box_head.fc6.parameters():\n",
        "    p.requires_grad = False\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "#Add a fully connected layer at the end with two outputs for our classes\n",
        "#modelr.fc = nn.Sequential(\n",
        "#               nn.Linear(2048, 128),\n",
        "#               nn.ReLU(inplace=True),\n",
        "#               nn.Linear(128, 2)).to(dev)\n",
        "\n",
        "\n",
        "#fc_inputs = modelr.fc.in_features\n",
        "modelr.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(256, 2),\n",
        "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
        ")\n",
        "for param in modelr.fc:\n",
        "    param.requires_grad = True \n",
        "\n",
        "\n",
        "for p in modelr.rpn.parameters():\n",
        "    print(p)\n",
        "    p.requires_grad = True\n",
        "\n",
        "print('Model Params with Grad=True')\n",
        "for n, param in modelr.named_parameters():\n",
        "  if param.requires_grad==True:\n",
        "    print(n)\n",
        "'''\n",
        "\n",
        "\n",
        "#params = [p for p in self.model.parameters() if p.requires_grad]\n",
        "#for param in modelr.fc():\n",
        "#    param.requires_grad==True\n",
        "\n",
        "#optimizer = optim.Adam(modelr.fc.parameters(), lr=0.01)\n",
        "\n",
        "#optimizer = torch.optim.Adam(params,lr=1e-3) #, weight_decay=0.0005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5x9dSXJh3pI"
      },
      "source": [
        "#STOP AFTER LOADING MODEL & PAUSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_esW8D4o3deV"
      },
      "outputs": [],
      "source": [
        "if(training_set == 0):\n",
        "    print('!!!!! Loading Pre-Trained Model !!!!')\n",
        "    submodel_dir = '0TO1_BUSI_BEST'\n",
        "    saved_dict= os.path.join(model_dir,submodel_dir,'BestIOU_0.7361612431704998')\n",
        "    #BestIOU_0.4736143966161136')\n",
        "                             #'BUSI_FINAL','BestIOU_0.7071668678352858')\n",
        "    modelr.load_state_dict(torch.load(saved_dict))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7tzcTRt3K_e"
      },
      "outputs": [],
      "source": [
        "#tensorboard for debugging views\n",
        "use_tensorboard = 1\n",
        "if (use_tensorboard == 1):\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    writer = SummaryWriter(tensorboard_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDeYv1rXIvEf"
      },
      "source": [
        "#GET IOU METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo-sv0awGf_Z"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Calculate the Classification output and then IOUs for relevant classes\n",
        "################################################################################\n",
        "def get_IOU(pbox,\n",
        "            annotation,\n",
        "            score,\n",
        "            plabel,\n",
        "            tlabel,\n",
        "            score_cutoff,\n",
        "            iou_cutoff):\n",
        "    iou_counter = 0\n",
        "    iou=0.0\n",
        "    #metrics\n",
        "    TP=0\n",
        "    FP=0\n",
        "    TN=0\n",
        "    FN=0\n",
        "\n",
        "\n",
        "    #Get Classification\n",
        "    # - This is a general classification, using the status of annotation presence\n",
        "    # and the raw label prediction (no scoring)\n",
        "\n",
        "\n",
        "\n",
        "    #\n",
        "    # Adjust confidence score and predicted label\n",
        "    #\n",
        "    '''\n",
        "    if (score['scores']): #if something in here\n",
        "        if (score['scores']> 0): #there's a valid score produced\n",
        "            confidence_score = score['scores']\n",
        "        else:\n",
        "            confidence_score = 0.0\n",
        "    else:\n",
        "        confidence_score = 0.0\n",
        "    '''\n",
        "\n",
        "    #Assign confidence score\n",
        "    #The predicted score should have been \"fixed\"\n",
        "    #before passing in to remove [] sizes\n",
        "    if (score > 0):\n",
        "        confidence_score = score\n",
        "    else:\n",
        "        confidence_score = 0.0\n",
        "            \n",
        "    if (plabel): #test if not empty\n",
        "        if (plabel > 0):\n",
        "            pass #keep plabel as is\n",
        "        else:\n",
        "            plabel = 0 #background\n",
        "    else:\n",
        "        plabel = 0\n",
        "\n",
        "    if (confidence_score < score_cutoff):\n",
        "                #don't trust the predicted label\n",
        "                plabel = 0 #predicted label isn't right, default to 0\n",
        "\n",
        "\n",
        "    if ((plabel == 1) and (tlabel == 1)):\n",
        "        TP+=1\n",
        "        iou = bb_intersection_over_union(annotation[0], \n",
        "                                         pbox['boxes'])\n",
        "        #print('---!!!--- iou calculation on TP: ', iou)\n",
        "    elif((plabel == 0) and (tlabel == 0)):\n",
        "        TN+=1\n",
        "    elif((plabel == 0) and (tlabel == 1)):\n",
        "        FN+=1\n",
        "        iou = 0.0\n",
        "    elif((plabel ==1) and (tlabel == 0)):\n",
        "        FP+=1\n",
        "        iou = 0.0\n",
        "    else:\n",
        "        #shouldn't get here, but just in case\n",
        "        print('plabel, tlabel ', \n",
        "              plabel, tlabel)\n",
        "        stop\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return iou, TP, FP, TN,FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szM2cIAhiXVc"
      },
      "source": [
        "#RESNET50 PRE-TRAINED  w/ CUSTOM ANCHOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_W26LydiN3v"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Stop after loading if we want the files loaded\n",
        "################################################################################\n",
        "run_testing_only = 1\n",
        "if (run_testing_only ==1):\n",
        "    print('STOPPING SO PLOT RESULTS CAN BE CREATED WITH INTERMEDIATE DATA')\n",
        "    stop #kill it so that files were loaded\n",
        "else:\n",
        "    print('TRAINING STARTING')\n",
        "    pass #continue onward to training\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "optimizer = torch.optim.SGD(params, lr=1e-4,momentum=0.9,weight_decay=0.0005) #, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.SGD(modelr.fc.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1)\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "#                                                       mode='min',\n",
        "#                                                       factor = 0.1,\n",
        "#                                                       patience=2,\n",
        "#                                                       verbose=True)\n",
        "\n",
        "if (train_on_gpu):\n",
        "    modelr = modelr.to(dev)\n",
        "\n",
        "# define list to store the smooth loss and learning rate\n",
        "smooth_loss_list  = []\n",
        "lr_list = []\n",
        "batch_num = 0\n",
        "avg_loss = 0\n",
        "best_loss = 0\n",
        "\n",
        "\n",
        "epoch_loss = []\n",
        "min_intersection =0.0\n",
        "highest_intersection =0\n",
        "\n",
        "truth_label =[]\n",
        "\n",
        "#\n",
        "# store the metrics for later review\n",
        "#\n",
        "metric_TP=[]\n",
        "metric_FP=[]\n",
        "metric_TN=[]\n",
        "metric_FN=[]\n",
        "metric_IOU= []\n",
        "\n",
        "\n",
        "train_loss_per_epoch=[]\n",
        "val_loss_per_epoch=[]\n",
        "\n",
        "start_epoch = 0\n",
        "num_epochs = 700\n",
        "\n",
        "\n",
        "####################################################################\n",
        "# GRADING CRITERIA\n",
        "#\n",
        "####################################################################\n",
        "score_cutoff = 0.4 #50% confidence is a valid result\n",
        "iou_cutoff = 0.15 #lower limit of valid iou result\n",
        "\n",
        "\n",
        "#\n",
        "# Continue previous training from a known state\n",
        "#\n",
        "use_last_epoch = 1\n",
        "if (use_last_epoch == 1):\n",
        "    saved_dict= os.path.join(model_dir,'0TO1_UCLA_BEST','RETRYTRAINING','fasterrcnn_trained_last')\n",
        "    #modelr.load_state_dict(torch.load(saved_dict))\n",
        "\n",
        "    checkpoint = torch.load(saved_dict)\n",
        "    modelr.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "\n",
        "\n",
        "    print('LOADED CHECKPOINT MODEL')\n",
        "\n",
        "    last_data_list ='/content/gdrive/My Drive/BreastUS/MODEL_SAVE/0TO1_UCLA_BEST/RETRYTRAINING/last_data_set.pickle'\n",
        "\n",
        "    archived_data = pickle.load( open( last_data_list, \"rb\" ) )\n",
        "    training_data = archived_data[0][0]\n",
        "    validation_data = archived_data[0][1]\n",
        "    test_data =archived_data[0][2]\n",
        "    bounding_box = archived_data[0][3]\n",
        "    first50 =archived_data[0][4]\n",
        "\n",
        "    #training_data, validation_data, test_data, bounding_box, first50 = pickle.load( open( last_data_file, \"rb\" ) )\n",
        "    #---disable optimizer hard set here if loading from saved checkpoint\n",
        "    optimizer = torch.optim.SGD(params, lr=1e-4, momentum=0.9, weight_decay=0.0005)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=90, gamma=0.5)\n",
        "    #start_epoch = 0\n",
        "    num_epochs = 400\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "data_loader = torch.utils.data.DataLoader(training_data,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2,\n",
        "                                          drop_last=True,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(validation_data,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2,\n",
        "                                          drop_last=True,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "training_loss_dict ={} #keep each epoch of loss together\n",
        "for epoch in range(start_epoch,num_epochs):\n",
        "    print('-------------- Epoch ',epoch)\n",
        "    print(optimizer)\n",
        "    epoch_loss = []\n",
        "    train_loss =0\n",
        "    training_loss_sample =[] #store all training loss each sample\n",
        "\n",
        "    ############################################################################\n",
        "    #\n",
        "    #                          TRAINING PHASE\n",
        "    ############################################################################\n",
        "    #with torch.no_grad(): #trying enabled\n",
        "    with torch.set_grad_enabled(True):\n",
        "        for i, data in enumerate(data_loader, 0):\n",
        "            if (i%100 == 0) and (i>0):\n",
        "                print('----> Batch Training load epoch & training loss ',i,train_loss/i/batch_size)\n",
        "            \n",
        "            ####################################################################\n",
        "            # set model to update weights\n",
        "            ####################################################################\n",
        "            modelr.train() # set eval for forward pass --eval()\n",
        "\n",
        "            #\n",
        "            # Separate Image and target data from the batch provided by the \n",
        "            # dataloader\n",
        "            #\n",
        "            images = data[0]\n",
        "            targets = data[1]\n",
        "\n",
        "\n",
        "            ####################################################################\n",
        "            # ResNet style models require lists of image volumes\n",
        "            #\n",
        "            ####################################################################\n",
        "            imagelist=[]\n",
        "            for ii in range(0,len(images)):\n",
        "                #imagelist.append(images[ii])\n",
        "                if (train_on_gpu):\n",
        "                    imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32).to(dev))\n",
        "                else:\n",
        "                    imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32))\n",
        "\n",
        "            #print(np.shape(images), len(images))\n",
        "            #print(np.shape(imagelist[0]))\n",
        "\n",
        "\n",
        "            ####################################################################\n",
        "            # Reformat the target dictionary. ResNet style requires the format\n",
        "            # structure follow below with the expected dictionaries\n",
        "            ####################################################################\n",
        "            target_new = []\n",
        "            for ii in range(0,len(images) ): #batch_size):\n",
        "                d={}\n",
        "\n",
        "                if (train_on_gpu == 1):\n",
        "                    d['boxes'] = torch.as_tensor(targets[ii][0]['boxes']).to(dev)\n",
        "                    d['labels'] = torch.as_tensor(targets[ii][0]['labels']).to(dev)\n",
        "                    d['image_id'] = torch.as_tensor(targets[ii][0]['image_id']).to(dev)\n",
        "                    d['area'] = torch.as_tensor(targets[ii][0]['area']).to(dev)\n",
        "                else:\n",
        "                    d['boxes'] = targets[ii][0]['boxes']\n",
        "                    d['labels'] = targets[ii][0]['labels']\n",
        "                    d['image_id'] = targets[ii][0]['image_id']\n",
        "                    d['area'] = targets[ii][0]['area']                  \n",
        "                target_new.append(d)\n",
        "\n",
        "\n",
        "            ####################################################################\n",
        "            # Perform a forward pass and generate loss updates\n",
        "            ####################################################################\n",
        "            loss_dict = modelr(imagelist, target_new) #targets)\n",
        "\n",
        "            training_loss_sample.append(loss_dict) #save for later review\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            \n",
        "            #print('*** SUMMED losses is ', losses)\n",
        "            #print(loss_dict)\n",
        "            train_loss += losses\n",
        "\n",
        "            #if (i%1== 0):\n",
        "            #    print('training loss ', train_loss/i/batch_size)\n",
        "\n",
        "            # backward pass\n",
        "            losses.backward()\n",
        "            # update optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss.append(float(losses.item() * len(imagelist)))\n",
        "    scheduler.step()\n",
        "    ###scheduler.step(np.mean(epoch_loss))\n",
        "\n",
        "    training_loss_dict[epoch] = training_loss_sample\n",
        "\n",
        "    # Save the latest set of training losses\n",
        "    training_loss_file  = os.path.join(model_dir,'training_loss_epoch.pickle')\n",
        "    pickle.dump([training_loss_dict],open( training_loss_file, \"wb\" )) #,protocol=5 )\n",
        "\n",
        "\n",
        "    #\n",
        "    # Tensorboard write\n",
        "    #\n",
        "    if (use_tensorboard == 1):\n",
        "        writer.add_scalar(' Training Loss per epoch', train_loss, epoch)\n",
        "        writer.flush() #write out all the info to the board\n",
        "\n",
        "    ############################################################################\n",
        "    #\n",
        "    # VALIDATION STEP\n",
        "    #\n",
        "    ############################################################################\n",
        "\n",
        "    val_epoch_iou = 0.0\n",
        "    avg_iou_batch_list=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        modelr.eval()     # Optional when not using Model Specific layer\n",
        "        \n",
        "        for vcount, vdata in enumerate(val_data_loader, 0):\n",
        "            TP=0\n",
        "            FP=0\n",
        "            TN=0\n",
        "            FN=0\n",
        "            avg_iou_per_batch=0.0\n",
        "\n",
        "\n",
        "            if (vcount%5 == 0):\n",
        "                print('----> Batch Validation load #',vcount)\n",
        "\n",
        "\n",
        "            val_images = vdata[0]\n",
        "            val_targets = vdata[1]\n",
        "            #targets = targets.to(dev)\n",
        "            #np.squeeze(targets[0]['boxes'], 1)\n",
        "\n",
        "            #\n",
        "            # Resnet needs a list of images\n",
        "            #\n",
        "            val_imagelist=[]\n",
        "            for kk in range(0,len(val_images)):\n",
        "                #imagelist.append(images[ii])\n",
        "                if (train_on_gpu):\n",
        "                    val_imagelist.append(torch.as_tensor(val_images[kk], dtype=torch.float32).to(dev))\n",
        "                else:\n",
        "                    val_imagelist.append(torch.as_tensor(val_images[kk], dtype=torch.float32))\n",
        "\n",
        "\n",
        "            #\n",
        "            # Reformat the target dictionary\n",
        "            #\n",
        "            target_val = []\n",
        "            for kk in range(0,batch_size):\n",
        "                d={}\n",
        "                #d['boxes'] = targets[0]['boxes'][ii]\n",
        "                '''\n",
        "                #MOBILENET ARCH\n",
        "                if (train_on_gpu == 1):\n",
        "                    d['boxes'] = torch.as_tensor(val_targets[0]['boxes'][ii]).to(dev)\n",
        "                    d['labels'] = torch.as_tensor(val_targets[0]['labels'][ii]).to(dev)\n",
        "                    d['image_id'] = torch.as_tensor(val_targets[0]['image_id'][ii]).to(dev)\n",
        "                    d['area'] = torch.as_tensor(val_targets[0]['area'][ii]).to(dev)\n",
        "                else:\n",
        "                    d['boxes'] = val_targets[0]['boxes'][ii]\n",
        "                    d['labels'] = val_targets[0]['labels'][ii]\n",
        "                    d['image_id'] = val_targets[0]['image_id'][ii]\n",
        "                    d['area'] = val_targets[0]['area'][ii]                  \n",
        "                target_val.append(d)\n",
        "                '''\n",
        "\n",
        "                #RESNET50 ARCH\n",
        "                if (train_on_gpu == 1):\n",
        "                    d['boxes'] = torch.as_tensor(val_targets[kk][0]['boxes']).to(dev)\n",
        "                    d['labels'] = torch.as_tensor(val_targets[kk][0]['labels']).to(dev)\n",
        "                    d['image_id'] = torch.as_tensor(val_targets[kk][0]['image_id']).to(dev)\n",
        "                    d['area'] = torch.as_tensor(val_targets[kk][0]['area']).to(dev)\n",
        "                else:\n",
        "                    d['boxes'] = val_targets[kk][0]['boxes']\n",
        "                    d['labels'] = val_targets[kk][0]['labels']\n",
        "                    d['image_id'] = val_targets[kk][0]['image_id']\n",
        "                    d['area'] = val_targets[kk][0]['area']                  \n",
        "                target_val.append(d)\n",
        "\n",
        "            ############################################################\n",
        "            #forward pass \n",
        "            #- this is going to generate predictions on a test volume\n",
        "            ############################################################\n",
        "            eval_out = modelr(val_imagelist) #targets)\n",
        "\n",
        "            #\n",
        "            # temporary assignment of predictions and truth data.\n",
        "            # These are filled with batch_size data\n",
        "            #\n",
        "            annotations = target_val\n",
        "            output = eval_out\n",
        "\n",
        "\n",
        "            #\n",
        "            # Loop over every image in the batch_size images returned\n",
        "            # - eval_out is batch size number of returns, so loop over \n",
        "            # the batch size to calculate stats on one prediction at \n",
        "            # a time\n",
        "            #\n",
        "            #\n",
        "            iou_over_batch = 0.0\n",
        "            #Keep only the boxes with highest score for the eval out \n",
        "            #this returns the highest box/score/label for X batch sizes\n",
        "            high_out, high_scores,high_labels = keep_Highscore(eval_out) #From Anil's setup\n",
        "\n",
        "            for image_batch in range(0,len(high_out)):\n",
        "\n",
        "\n",
        "                #reset the iou for each image\n",
        "                iou=0.0\n",
        "\n",
        "\n",
        "                #predicted information for this image\n",
        "                #pred_boxes = high_out #eval_out[0]['boxes']\n",
        "                #score = high_score #eval_out[0]['scores']\n",
        "                plabel = high_labels[image_batch]\n",
        "                pscore = high_scores[image_batch]\n",
        "                pbox = high_out[image_batch]\n",
        "\n",
        "                #truth data\n",
        "                annotation = val_targets[image_batch][0]['boxes'] \n",
        "                truth_label.append(val_targets[image_batch][0]['labels'])\n",
        "                crowd_setting = val_targets[image_batch][0]['iscrowd']\n",
        "\n",
        "                #Protect against empty scores\n",
        "                if (pscore['scores']):\n",
        "                    pscore = pscore['scores'] #not empty, so keep\n",
        "\n",
        "                else:\n",
        "                    pscore = 0.0\n",
        "\n",
        "                #Is there a truth ground box\n",
        "                if (len(annotation) <1):\n",
        "                    #truth is empty, so make this a Normal label\n",
        "                    tlabel = 0\n",
        "                else:\n",
        "                    tlabel = 1\n",
        "\n",
        "\n",
        "\n",
        "                #\n",
        "                # Calculate IOU and Metrics\n",
        "                #\n",
        "                iou, TP_out, FP_out, TN_out, FN_out = get_IOU(pbox,\n",
        "                                                            annotation,\n",
        "                                                            pscore,\n",
        "                                                            plabel['labels'],\n",
        "                                                            tlabel,\n",
        "                                                            score_cutoff,\n",
        "                                                            iou_cutoff)\n",
        "                #print('TP/FP/TN/FN = ', TP_out, FP_out, TN_out, FN_out)\n",
        "                \n",
        "                TP+=TP_out\n",
        "                FP+=FP_out\n",
        "                TN+=TN_out\n",
        "                FN+=FN_out\n",
        "\n",
        "\n",
        "                iou = np.float32(iou)\n",
        "                iou_over_batch += iou\n",
        "                #if (TP_out >0): #check any valid TP outcomes\n",
        "                #    print('incoming IOU is ', iou)\n",
        "\n",
        "\n",
        "            metric_TP.append(TP)\n",
        "            metric_FP.append(FP)\n",
        "            metric_TN.append(TN)\n",
        "            metric_FN.append(FN)\n",
        "        \n",
        "        #after every batch (10 images usually), calculate batch stats\n",
        "        avg_iou_per_batch =iou_over_batch/(np.double(TP + FN + FP + eps)) #len(high_out)\n",
        "        #Store metrics for this batch load\n",
        "        avg_iou_batch_list.append(avg_iou_per_batch)\n",
        "\n",
        "        if (vcount%5 == 0):\n",
        "            print('avg iou/batch @ batch#, total_iou',avg_iou_per_batch,vcount, iou_over_batch)\n",
        "            print('    Metrics (TP,FP,TN,FN)', TP, FP, TN, FN)\n",
        "        \n",
        "        avg_batch_iou = np.sum(avg_iou_batch_list)/ len(avg_iou_batch_list)\n",
        "        val_epoch_iou =avg_batch_iou #/validation_data\n",
        "        print('*** val_epoch_iou ***')\n",
        "    val_loss_per_epoch.append(val_epoch_iou)\n",
        "\n",
        "    #save the validation loss values per each epoch\n",
        "    val_loss_file  = os.path.join(model_dir,'validation_loss_epoch.pickle')\n",
        "    pickle.dump([val_loss_per_epoch],open( val_loss_file, \"wb\" )) #,protocol=5 )\n",
        "\n",
        "    ############################################################################\n",
        "    # Save a new model checkpoint if the IOU has improved\n",
        "    ############################################################################\n",
        "    if (val_epoch_iou > highest_intersection):\n",
        "        print('New high avg iou = ',val_epoch_iou)\n",
        "        highest_intersection = val_epoch_iou\n",
        "        print(\"-\" * 20)\n",
        "        best_model_name = 'BestIOU_' + str(highest_intersection) # str(np.int(best_accuracy*100)) + '_EPOCH_' +str(epoch)+'_' + str(valid_loss)\n",
        "        #torch.save(modelr.state_dict(),os.path.join(model_dir,best_model_name))\n",
        "        torch.save({'epoch': epoch,\n",
        "            'model_state_dict':modelr.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()},\n",
        "            os.path.join(model_dir,best_model_name))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print('Mean Epoch Loss = ', np.mean(epoch_loss))\n",
        "    print('highest val IOU is: ',highest_intersection)\n",
        "\n",
        "    #save intermediate dictionary each epoch\n",
        "    #torch.save(modelr.state_dict(),os.path.join(model_dir,'fasterrcnn_trained_last'))\n",
        "\n",
        "    torch.save({'epoch': epoch,\n",
        "               'model_state_dict': modelr.state_dict(),\n",
        "               'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss':loss_dict},\n",
        "               os.path.join(model_dir,'fasterrcnn_trained_last'))\n",
        "\n",
        "\n",
        "\n",
        "#save the metrics\n",
        "\n",
        "loss_file = os.path.join(model_dir,'train_val_loss.pickle')\n",
        "pickle.dump([train_loss_per_epoch, val_loss_per_epoch],open( loss_file, \"wb\" ),protocol=5 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #epoch_loss.append(train_loss/batch_size)\n",
        "        \n",
        "################################################################################\n",
        "# Finalize the tensor file \n",
        "if (use_tensorboard == 1):\n",
        "    writer.close()\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK1EPtUnv859"
      },
      "outputs": [],
      "source": [
        "plabel\n",
        "#truth data\n",
        "print(annotation) # = val_targets[image_batch][0]['boxes'] \n",
        "print(truth_label[-1]) #.append(val_targets[image_batch][0]['labels'])\n",
        "#crowd_setting = val_targets[image_batch][0]['iscrowd']\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "393H7NorUG4Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "annotations = target_val\n",
        "output = eval_out\n",
        "\n",
        "iou_over_batch = 0.0\n",
        "iou=0.0\n",
        "\n",
        "#Keep only the box with highest score \n",
        "high_out, high_scores,high_labels = keep_Highscore(eval_out) #From Anil's setup\n",
        "\n",
        "#predicted information for this image\n",
        "#pred_boxes = high_out #eval_out[0]['boxes']\n",
        "#score = high_score #eval_out[0]['scores']\n",
        "plabel = high_labels\n",
        "\n",
        "#truth data\n",
        "annotation = val_targets[ii][0]['boxes'] \n",
        "truth_label.append(val_targets[ii][0]['labels'])\n",
        "crowd_setting = val_targets[ii][0]['iscrowd']\n",
        "\n",
        "\n",
        "\n",
        "#Is there a truth ground box\n",
        "if (len(annotation) <1):\n",
        "    #truth is empty, so make this a Normal label\n",
        "    tlabel = 0\n",
        "else:\n",
        "    tlabel = 1\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# Calculate IOU and Metrics\n",
        "#\n",
        "\n",
        "iou, TP_out, FP_out, TN_out, FN_out = get_IOU(pbox,\n",
        "                                            annotation,\n",
        "                                            pscore,\n",
        "                                            plabel,\n",
        "                                            tlabel,\n",
        "                                            score_cutoff,\n",
        "                                            iou_cutoff)\n",
        "print('TP/FP/TN/FN = ', TP_out, FP_out, TN_out, FN_out)\n",
        "\n",
        "\n",
        "#\n",
        "# Calculate IOU and Metrics\n",
        "\n",
        "iou, TP_out, FP_out, TN_out, FN_out = get_IOU(eval_out,\n",
        "                                                annotation,\n",
        "                                                high_scores,\n",
        "                                                plabel,\n",
        "                                                tlabel,\n",
        "                                                score_cutoff,\n",
        "                                                iou_cutoff)    \n",
        "print(iou)\n",
        "print(TP_out,FP_out, TN_out, FN_out)  \n",
        "\n",
        "print(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU9hgmmU088F"
      },
      "outputs": [],
      "source": [
        "print(pscore)\n",
        "print(plabel)\n",
        "iou, TP_out, FP_out, TN_out, FN_out = get_IOU(pbox,\n",
        "                                            annotation,\n",
        "                                            pscore,\n",
        "                                            plabel['labels'],\n",
        "                                            tlabel,\n",
        "                                            score_cutoff,\n",
        "                                            iou_cutoff)\n",
        "print('TP/FP/TN/FN = ', TP_out, FP_out, TN_out, FN_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0MJCkbqwpXH"
      },
      "outputs": [],
      "source": [
        "#data_loader = torch.utils.data.DataLoader(training_data,\n",
        "#optimizer\n",
        "#iou, TP, FP, TN, FN, calculated_iou = get_IOU(out,  annotation)\n",
        "file_name ='/content/gdrive/My Drive/BreastUS/UCLA_DATA_CONTRAST_EQUALIZED/1_25s1kz8d_a_a7a2a5ah_1.mp4-2021_08_11_19_27_06-labelme 3.0.zip/default/frame_000102.PNG_600_800_150_521_117_734.pck'\n",
        "img = pickle.load( open( file_name, \"rb\" ) )\n",
        "'''\n",
        "for count,file_name in enumerate(train_list):\n",
        "    try:\n",
        "        img = pickle.load( open( file_name, \"rb\" ) )\n",
        "    except:\n",
        "        print(file_name)\n",
        "    #print(count,file_name)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxsNzOmB8RJD"
      },
      "outputs": [],
      "source": [
        "#These files failed reading:\n",
        "#file_name ='/content/gdrive/My Drive/BreastUS/UCLA_DATA_CONTRAST_EQUALIZED/1_25s1kz8d_a_a7a2a5ah_1.mp4-2021_08_11_19_27_06-labelme 3.0.zip/default/frame_000102.PNG_600_800_150_521_117_734.pck'\n",
        "!ls \n",
        "!rm '/content/gdrive/My Drive/BreastUS/UCLA_DATA_CONTRAST_EQUALIZED/1_25s1kz8d_a_a7a2a5ah_1.mp4-2021_08_11_19_27_06-labelme 3.0.zip/default/frame_000102.PNG_600_800_150_521_117_734.pck'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgyB3lPaJRDA"
      },
      "outputs": [],
      "source": [
        "#optimizer\n",
        "print(i)\n",
        "#high_out, box_scores,highest_label \n",
        "print(high_out[i], box_scores[i], highest_label[i])\n",
        "print(highest_label[i]['labels'], annotations[i]['labels'].cpu().numpy())\n",
        "#print(val_imagelist[i])\n",
        "print(val_targets[i])\n",
        "print(full_file_list[803])\n",
        "print(eval_out[1])\n",
        "print(output[1])\n",
        "idata = image.imread(full_file_list[803])\n",
        "plt.figure()\n",
        "plt.imshow(idata[:,:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXpMD-UDd4Ws"
      },
      "source": [
        "#scratch code area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGI6YsJngkrA"
      },
      "outputs": [],
      "source": [
        "checkpoint.keys()\n",
        "optimizer = torch.optim.SGD(params, lr=1e-5, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "checkpoint = torch.load(saved_dict)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "checkpoint['optimizer_state_dict']\n",
        "#f='/content/gdrive/My Drive/BreastUS/0TO1NORM/BUSI_DATA_CONTRAST_EQUALIZED/benign/benign (350).png_580_786.pck'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKGKegkXnagY"
      },
      "outputs": [],
      "source": [
        "#annotations[i]['labels'].cpu().numpy()\n",
        "#output[0]['labels'][3].cpu().numpy().squeeze()\n",
        "scores = output[0]['scores'].cpu().numpy().squeeze()\n",
        "print(scores)\n",
        "#output[0][np.argmax(scores)]\n",
        "id = np.argmax(scores)\n",
        "print(id)\n",
        "\n",
        "\n",
        "high_out, box_scores,highest_label = keep_Highscore(output) \n",
        "\n",
        "\n",
        "\n",
        "valid_count = 0\n",
        "\n",
        "# Basic metrics for confusion matrix\n",
        "val_TP = 0\n",
        "val_FP = 0\n",
        "val_TN = 0\n",
        "val_FN = 0\n",
        "for i in range(len(high_out)): #output)):\n",
        "\n",
        "    #single values for the predicted box and truth box\n",
        "    out = high_out[i]['boxes']\n",
        "    annotation = annotations[i]['boxes'].cpu().numpy().squeeze()\n",
        "    print('------------------------')\n",
        "    print(i)\n",
        "    print('out: ', out)\n",
        "    print('anno: ', annotation)\n",
        "    print('scores = ',output[i]['scores'].cpu().numpy())\n",
        "\n",
        "    #\n",
        "    # Calculate IOU and Metrics\n",
        "    #\n",
        "    if ((highest_label[i]['labels'] == 0) and \n",
        "        (annotations[i]['labels'].cpu().numpy() ==0)):\n",
        "        #This is a TRUE NEGATIVE MATCH\n",
        "        val_TN = val_TN + 1\n",
        "    elif (( highest_label[i]['labels'] == 1) and\n",
        "        (annotations[i]['labels'].cpu().numpy() ==0)):\n",
        "        val_FP = val_FP + 1\n",
        "        iou = 0.0\n",
        "    elif ((highest_label[i]['labels']  == 1) and\n",
        "        (annotations[i]['labels'].cpu().numpy() ==1)):\n",
        "        val_TP = val_TP + 1\n",
        "        #this should have its IOU calculated \n",
        "        iou = bb_intersection_over_union(annotation, out)\n",
        "        iou_over_batch += iou\n",
        "        valid_count = valid_count + 1\n",
        "    elif ((highest_label[i]['labels']  == 0) and\n",
        "        (annotations[i]['labels'].cpu().numpy() ==1)):\n",
        "        val_FN = val_FN + 1\n",
        "        iou = 0.0\n",
        "\n",
        "print(out)\n",
        "print(annotation)\n",
        "\n",
        "#output[i]['labels'].cpu().numpy()[0]\n",
        "#optimizer\n",
        "#modelr.roi_heads.box_head\n",
        "\n",
        "\n",
        "#for p in modelr.roi_heads.box_head.parameters():\n",
        "#    p.requires_grad = True\n",
        "\n",
        "#├─RoIHeads: 1-4                                         --\n",
        "#│    └─MultiScaleRoIAlign: 2-5                          --\n",
        "#│    └─TwoMLPHead: 2-6                                  --\n",
        "#│    │    └─Linear: 3-15                                (12,846,080)\n",
        "#│    │    └─Linear: 3-16                                (1,049,600\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NzGzH8QOtbi"
      },
      "outputs": [],
      "source": [
        "modelr.rpn\n",
        "\n",
        "#modelr.rpn.anchor_generator = anchor_generator\n",
        "#rpn_anchor_generator=anchor_generator\n",
        "\n",
        "anchor_sizes = ((32,), (64,), (128,), (256,), (512,)) \n",
        "aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes) \n",
        "anchor_generator = AnchorGenerator(anchor_sizes, aspect_ratios)\n",
        "                                   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT1092IiKboO"
      },
      "source": [
        "#Load Saved model dictionary for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTeAXgZLnL84"
      },
      "outputs": [],
      "source": [
        "#final_file = os.path.join(model_dir,'vgg16_best_accuracy_97_gpu')\n",
        "#subdir = '0TO1_UCLA_BEST'\n",
        "subdir = '0TO1_BUSI_BEST'\n",
        "\n",
        "model_type = 0 #0=UCLA, 1 = BUSI\n",
        "\n",
        "if (model_type == 0):\n",
        "    subdir = '0TO1_UCLA_BEST'\n",
        "    mname = 'BestIOU_0.2930135428905487'\n",
        "else:\n",
        "    subdir = '0TO1_BUSI_BEST'\n",
        "    mname = 'BestIOU_0.7361612431704998'\n",
        "\n",
        "model_dict=os.path.join(model_dir, subdir, mname   )\n",
        "                        \n",
        "                        # -1 to 1   'UCLA_FINAL', 'BestIOU_0.3265211880207062')\n",
        "                        #'UCLA_FINETUNE','BestIOU_0.22196083524357255')\n",
        "                        #'BUSI_FINAL','BestIOU_0.7071668678352858')\n",
        "#'121521_50epoch_Adam','BestIOU_0.43511341297247597_121521') #BestIOU_0.31124280825584255') #BestIOU_0.2270519932219383')\n",
        "modelr.load_state_dict(torch.load(model_dict))\n",
        "\n",
        "#\n",
        "# Load relevant saved train/validation/test file sets\n",
        "#\n",
        "print('Loading previous set of train/val/test files')\n",
        "#subdir = '0TO1_UCLA_BEST'\n",
        "last_data_list = os.path.join(model_dir, subdir,'last_data_set.pickle') #0TO1\n",
        "#'/content/gdrive/My Drive/BreastUS/MODEL_SAVE/UCLA_FINAL/last_data_set.pickle'\n",
        "\n",
        "archived_data = pickle.load( open( last_data_list, \"rb\" ) )\n",
        "training_data = archived_data[0][0]\n",
        "validation_data = archived_data[0][1]\n",
        "test_data =archived_data[0][2]\n",
        "bounding_box = archived_data[0][3]\n",
        "first50 =archived_data[0][4]\n",
        "\n",
        "#training_loss_file  = os.path.join(model_dir,'training_loss_epoch.pickle')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzBNg_9Kqlyh"
      },
      "source": [
        "##CAM TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1aDpFvZDHvL"
      },
      "outputs": [],
      "source": [
        "no_of_layers=0\n",
        "conv_layers=[]\n",
        " \n",
        "model_children=list(modelr.children())\n",
        " \n",
        "\n",
        " \n",
        "for child in model_children:\n",
        "  if type(child)==nn.Conv2d:\n",
        "    no_of_layers+=1\n",
        "    conv_layers.append(child)\n",
        "  elif type(child)==nn.Sequential:\n",
        "    for layer in child.children():\n",
        "      if type(layer)==nn.Conv2d:\n",
        "        no_of_layers+=1\n",
        "        conv_layers.append(layer)\n",
        "print(no_of_layers)\n",
        "\n",
        "print(modelr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ohDlduNuue8"
      },
      "outputs": [],
      "source": [
        "def normalize_output(img):\n",
        "    img = img - img.min()\n",
        "    img = img / img.max()\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOWa0iNegNPr"
      },
      "outputs": [],
      "source": [
        "# Visualize feature maps\n",
        "# -- needed for CAM setup\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wau_ER5VMGa"
      },
      "outputs": [],
      "source": [
        "\n",
        "activation = {}\n",
        "'''\n",
        "    (2): Bottleneck(\n",
        "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
        "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
        "        (relu): ReLU(inplace=True)\n",
        "'''\n",
        "print(modelr.backbone.body.layer4[0])\n",
        "print(modelr.rpn.head.cls_logits)\n",
        "print('-----')\n",
        "#modelr.roi_heads.box_predictor.cls_score\n",
        "print(modelr.backbone.body.layer4[0].conv1)\n",
        "modelr.backbone.body.layer4[-1].conv3.register_forward_hook(get_activation('conv2D'))\n",
        "#modelr.rpn.head.bbox_pred.register_forward_hook(get_activation('conv2D'))\n",
        "\n",
        "#modelr.rpn.head.cls_logits.register_forward_hook(get_activation('conv2D'))\n",
        "\n",
        "#modelr.roi_heads.box_predictor.cls_score.register_forward_hook(get_activation('Linear'))\n",
        "#model.conv1.register_forward_hook(get_activation('conv1'))\n",
        "#modelr.roi_heads.box_predictor.cls_score.register_forward_hook(get_activation('conv2D')) #'Dense'))\n",
        "\n",
        "\n",
        "batch_size =10\n",
        "val_data_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2,\n",
        "                                          drop_last=True,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "for vcount, vdata in enumerate(val_data_loader, 0):\n",
        "    avg_iou_per_batch=0.0\n",
        "    if (vcount%5 == 0):\n",
        "        print('----> Batch Validation load #',vcount)\n",
        "    val_images = vdata[0]\n",
        "    val_targets = vdata[1]\n",
        "    #targets = targets.to(dev)\n",
        "    #np.squeeze(targets[0]['boxes'], 1)\n",
        "\n",
        "    val_imagelist=[]\n",
        "    for kk in range(0,len(val_images)):\n",
        "        #imagelist.append(images[ii])\n",
        "        if (train_on_gpu):\n",
        "            val_imagelist.append(torch.as_tensor(val_images[kk], dtype=torch.float32).to(dev))\n",
        "        else:\n",
        "            val_imagelist.append(torch.as_tensor(val_images[kk], dtype=torch.float32))\n",
        "    \n",
        "    break\n",
        "\n",
        "modelr.cuda() #just in case skipping some steps above for cam only runs\n",
        "modelr.eval()\n",
        "\n",
        "print('length of val images ',len(val_imagelist))\n",
        "eval_out = modelr(val_imagelist)\n",
        "#print(eval_out)\n",
        "\n",
        "\n",
        "for ii in range(0,3):\n",
        "    print('shape of val image is ', np.shape(val_imagelist[ii]))\n",
        "    plt.figure()\n",
        "    plt.imshow(val_imagelist[ii][1,:,:].to('cpu'), cmap='gray')\n",
        "    plt.colorbar()\n",
        "    ttext = 'Image# ' + str(ii)\n",
        "    plt.title(ttext)\n",
        "\n",
        "\n",
        "    print('get activation')\n",
        "    act = activation['conv2D'].squeeze() #conv2D\n",
        "    print('shape act, size(0) ',np.shape(act),act.size(0))\n",
        "    fig, axarr = plt.subplots(1,act.size(0),figsize=(20,20))\n",
        "    for idx in range(0,act.size(0)):\n",
        "        axarr[idx].imshow(act[idx][0,:,:].to('cpu'),cmap='jet')\n",
        "\n",
        "\n",
        "    print('adding cam elements and heatmap')\n",
        "    cam = act[0].to('cpu')\n",
        "    w= 800\n",
        "    h= 600\n",
        "    cam = cv2.resize(np.float32(cam), (w,h))\n",
        "    print('cam resized')\n",
        "    print(type(cam))\n",
        "    print('max in image is ', np.max(cam))\n",
        "    plt.figure()\n",
        "    plt.imshow(cam[:,:,0],cmap='jet')\n",
        "    plt.colorbar()\n",
        "\n",
        "    cam = (cam - np.min(cam))/np.ptp(cam)\n",
        "    print('max after conversion is ', np.max(cam), np.min(cam))\n",
        "    cam = cam[:,:,0]\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(heatmap,cmap='jet')\n",
        "    tempimage = val_imagelist[ii][1,:,:]\n",
        "    print('shape of heatmap is ', np.shape(heatmap))\n",
        "    cam = heatmap[:,:,0] + np.float32(tempimage.to('cpu'))\n",
        "    cam = cam / np.max(cam)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(cam,cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.title('Heatmap')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqFTExq0DaVA"
      },
      "outputs": [],
      "source": [
        "if(0): #Viz doesn't work\n",
        "    list(modelr.children())\n",
        "    modelr.backbone.body.layer4[0]\n",
        "    model_children=list(modelr.backbone.body.layer4[2].children())\n",
        "\n",
        "\n",
        "    no_of_layers=0\n",
        "    conv_layers=[]\n",
        "    #print(model_children)\n",
        "    for child in model_children:\n",
        "        print(type(child))\n",
        "\n",
        "        if (type(child) == nn.Conv2d):\n",
        "            no_of_layers+=1\n",
        "            conv_layers.append(child)\n",
        "        elif type(child)==nn.Sequential:\n",
        "            for layer in child.children():\n",
        "                if type(layer)==nn.Conv2d:\n",
        "                    no_of_layers+=1\n",
        "                    conv_layers.append(layer)    \n",
        "    print(no_of_layers)    \n",
        "\n",
        "\n",
        "\n",
        "    temp_image = cv2.resize(val_imagelist[0][0,:,:].cpu().numpy(), (2048,512))\n",
        "\n",
        "    temp_image = temp_image[:,:,None,None]\n",
        "    #t_resized = F.resize(temp_image, 1)\n",
        "\n",
        "\n",
        "    print(np.shape(temp_image))\n",
        "    #idata = torch.rand(512,2048,1,100)\n",
        "    #idata=normalize_output(idata)\n",
        "    #idata = idata.cuda()\n",
        "\n",
        "\n",
        "    temp_image = normalize_output(temp_image)\n",
        "    temp_image = torch.tensor(temp_image).cuda()\n",
        "    results =[]\n",
        "    print('conv[0] ',conv_layers[0])\n",
        "    results = [conv_layers[0](temp_image)]\n",
        "    plt.figure()\n",
        "    plt.imshow(temp_image[:,:,0,0].cpu())\n",
        "\n",
        "\n",
        "    for i in range(1, len(conv_layers)):\n",
        "        print('----> now on i= ',i,conv_layers[i])\n",
        "        print(conv_layers[i])\n",
        "        \n",
        "        results.append(conv_layers[i](results[-1]))\n",
        "        outputs = results\n",
        "    outputs = results\n",
        "\n",
        "\n",
        "\n",
        "    layer_viz = outputs[0][1, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    np.shape(layer_viz.data)\n",
        "    plt.figure()\n",
        "    plt.plot(layer_viz.data[:,0,0].to('cpu'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_gD9OVrMZOc"
      },
      "outputs": [],
      "source": [
        "if(0):\n",
        "    for num_layer in range(len(outputs)):\n",
        "        plt.figure(figsize=(50, 10))\n",
        "        layer_viz = outputs[num_layer][0, :, :, :]\n",
        "        layer_viz = layer_viz.data\n",
        "        print(\"Layer \",num_layer+1)\n",
        "        for i, filter in enumerate(layer_viz):\n",
        "            if i == 16: \n",
        "                break\n",
        "            \n",
        "            plt.subplot(2, 8, i + 1)\n",
        "            filter = filter.to('cpu')\n",
        "            plt.imshow(filter, cmap='gray')\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4POcz3Q8pkI3"
      },
      "outputs": [],
      "source": [
        "def printnorm(self, input, output):\n",
        "    # input is a tuple of packed inputs\n",
        "    # output is a Tensor. output.data is the Tensor we are interested\n",
        "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
        "    print('')\n",
        "    print('input: ', type(input))\n",
        "    print('input[0]: ', type(input[0]))\n",
        "    print('output: ', type(output))\n",
        "    print('')\n",
        "    print('input size:', input[0].size())\n",
        "    print('output size:', output.data.size())\n",
        "    print('output norm:', output.data.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fcqQe5z6e6T"
      },
      "outputs": [],
      "source": [
        "def get_last_conv_name(net):\n",
        "    \"\"\"\n",
        "    :param net:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    layer_name = None\n",
        "    for name, m in net.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            layer_name = name\n",
        "    return layer_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqpOFcUx6zyv"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage import io\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "!pip install -q timm grad-cam\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM,EigenCAM, EigenGradCAM, LayerCAM, FullGrad\n",
        "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\n",
        "\n",
        "#from interpretability.grad_cam import GradCAM, GradCamPlusPlus\n",
        "#from interpretability.guided_back_propagation import GuidedBackPropagation\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--network', type=str, default='resnet50',\n",
        "                    help='ImageNet classification network')\n",
        "#arguments = parser.parse_args()\n",
        "layer_name = get_last_conv_name(modelr) #if args.layer_name is None else args.layer_name\n",
        "print(layer_name)\n",
        "modelr.rpn.head.bbox_pred.register_forward_hook\n",
        "\n",
        "grad_cam = GradCAM(modelr, layer_name)\n",
        "mask = grad_cam(inputs, args.class_id)  # cam mask\n",
        "image_dict['cam'], image_dict['heatmap'] = gen_cam(img, mask)\n",
        "grad_cam.remove_handlers()\n",
        "# Grad-CAM++\n",
        "grad_cam_plus_plus = GradCamPlusPlus(net, layer_name)\n",
        "mask_plus_plus = grad_cam_plus_plus(inputs, args.class_id)  # cam mask\n",
        "image_dict['cam++'], image_dict['heatmap++'] = gen_cam(img, mask_plus_plus)\n",
        "grad_cam_plus_plus.remove_handlers()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9UOdnxFTMnL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#net.conv2.register_forward_hook(printnorm)\n",
        "\n",
        "\n",
        "\n",
        "print(modelr)\n",
        "modelr.roi_heads.box_predictor\n",
        "#modelr.register_forward_hook\n",
        "print('*' * 20)\n",
        "print(modelr.backbone.body.layer4[2].conv3)\n",
        "last_cnn = modelr.backbone.body.layer4[2].conv3\n",
        "modelr.backbone.body.layer4.register_forward_hook(printnorm)\n",
        "#modelr._modules.get('backbone')   #'cls_logits')\n",
        "#print('--' * 20)\n",
        "#print(last_cnn)\n",
        "\n",
        "print(val_imagelist)\n",
        "out_data = modelr(val_imagelist)\n",
        "print(out_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4xV6HxTvgzp"
      },
      "outputs": [],
      "source": [
        "!pip install -q captum\n",
        "\n",
        "\n",
        "import captum\n",
        "from captum.attr import IntegratedGradients, Occlusion, LayerGradCam, LayerAttribution\n",
        "from captum.attr import visualization as viz\n",
        "\n",
        "# Initialize the attribution algorithm with the model\n",
        "integrated_gradients = IntegratedGradients(modelr)\n",
        "\n",
        "print(np.shape(val_imagelist[0]))\n",
        "\n",
        "layer_gradcam = LayerGradCam(modelr,modelr.backbone.body.layer4[2].conv3)# model.layer3[1].conv2)\n",
        "\n",
        "idata = torch.zeros((1,3,244,244))\n",
        "idata = idata.cuda()\n",
        "\n",
        "\n",
        "images_batch = torch.from_numpy(np.array(val_imagelist[0].cpu()))\n",
        "attributions_lgc = layer_gradcam.attribute(idata, target=1)\n",
        "_ = viz.visualize_image_attr(attributions_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n",
        "                             sign=\"all\",\n",
        "                             title=\"Layer 4 Conv 3\")\n",
        "\n",
        "\n",
        "# Ask the algorithm to attribute our output target to\n",
        "#attributions_ig = integrated_gradients.attribute(val_imagelist[0], n_steps =1) #, target=pred_label_idx, n_steps=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfXKPjSOhfGJ"
      },
      "outputs": [],
      "source": [
        "activated_features = SaveFeatures(last_cnn) \n",
        "\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM,EigenCAM, EigenGradCAM, LayerCAM, FullGrad\n",
        "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\n",
        "\n",
        "cam=GradCAM(model=modelr,\n",
        "                    target_layers=modelr.backbone.body.layer4, #[2].conv3, \n",
        "                    use_cuda=True)\n",
        "#cam.batch_size = 32\n",
        "\n",
        "input_tensor = idata[0].unsqueeze_(0)\n",
        "\n",
        "#input_tensor = input_tensor.to(dev)\n",
        "target_category = None\n",
        "grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LARZ3p3EhdCN"
      },
      "outputs": [],
      "source": [
        "class SaveFeatures(): \n",
        "    features=None\n",
        "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)  # attach the hook to the specified layer\n",
        "    def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy() # copy the activation features as an instance variable\n",
        "    def remove(self): self.hook.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pcjGDLy50AW"
      },
      "outputs": [],
      "source": [
        "test_data_loader = torch.utils.data.DataLoader(validation_data,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2,\n",
        "                                          drop_last=True,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "counter =0\n",
        "for idata,tdata in test_data_loader: #val_data_loader:\n",
        "\n",
        "    for ii in range(0,len(tdata)):\n",
        "        counter =counter+1\n",
        "\n",
        "        #reset \n",
        "        iou = 0.0\n",
        "\n",
        "\n",
        "        val_imagelist=[]\n",
        "        if (train_on_gpu):\n",
        "            val_imagelist.append(torch.as_tensor(idata[ii], dtype=torch.float32).to(dev))\n",
        "        else:\n",
        "            val_imagelist.append(torch.as_tensor(idata[ii], dtype=torch.float32))\n",
        "        \n",
        "        break\n",
        "\n",
        "len(idata[0][0,:,:])\n",
        "np.shape(idata[0])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(idata[0][0,:,:])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WK2Q-NeKmvk"
      },
      "source": [
        "#ERASE----Produce Training and Validation Loss Plots  -BUSI original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pcbSsdBKlCg"
      },
      "outputs": [],
      "source": [
        "##################### ERASE THIS ########################\n",
        "'''\n",
        "stop\n",
        "mfolder = '0TO1_BUSI_BEST' #'UCLA_FINETUNE'\n",
        "training_loss_file  = os.path.join(model_dir,mfolder,'training_loss_epoch.pickle')\n",
        "validation_loss_file  = os.path.join(model_dir,mfolder,'validation_loss_epoch.pickle')\n",
        "#tloss = load(training_loss_file)\n",
        "data = pickle.load( open( training_loss_file, \"rb\" ) )\n",
        "vdata = pickle.load( open( validation_loss_file, \"rb\" ) )\n",
        "tloss = data[0]\n",
        "vloss = vdata[0]\n",
        "\n",
        "batch_size=10\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(validation_data,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2,\n",
        "                                          drop_last=True,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "print(len(data))\n",
        "#print(np.array(tloss))\n",
        "num_files = len(   val_data_loader)\n",
        "num_training_files = len(training_data)\n",
        "print('number of training files = ',num_training_files)\n",
        "#print(len(train_loss_per_epoch))\n",
        "#print(len(val_loss_per_epoch))\n",
        "#print(len(data_loader))\n",
        "#epoch_loss.append(float(losses.item() * len(imagelist)))\n",
        "tdata =[]\n",
        "for ii in tloss:\n",
        "    temp = ii.cpu()\n",
        "    temp = temp.detach().numpy()\n",
        "    tdata.append(temp)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(tdata)/(num_training_files),'ro-')\n",
        "\n",
        "plt.title('BUSI Fine-Tuning Total Loss Training')\n",
        "plt.legend(['Training Loss'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(vloss),'b.-') #/len(val_data_loader))\n",
        "plt.title('BUSI Fine-Tuning Validation IOU Training')\n",
        "plt.legend(['Validation IOU'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IOU')\n",
        "#train_epoch= np.array(train_loss_per_epoch)/1000\n",
        "#plt.figure()\n",
        "#plt.plot(val_loss_per_epoch,'b.-')\n",
        "#plt.plot(train_epoch,'ro-')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsJnndYBO4ry"
      },
      "source": [
        "#Produce BUSI TRAINING LOSS PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Hha7cVOU_0"
      },
      "outputs": [],
      "source": [
        "mfolder = '0TO1_BUSI_BEST' #'UCLA_FINETUNE'\n",
        "training_loss_file  = os.path.join(model_dir,mfolder,'training_loss_epoch.pickle')\n",
        "validation_loss_file  = os.path.join(model_dir,mfolder,'validation_loss_epoch.pickle')\n",
        "file_pickle = os.path.join(model_dir,mfolder,'train_val_test_data.pickle')\n",
        "file_data = pickle.load(open(file_pickle,\"rb\"))\n",
        "#stored_data =[training_data, validation_data, test_data, bounding_box,\n",
        "#                first50]\n",
        "\n",
        "#tloss = load(training_loss_file)\n",
        "data = pickle.load( open( training_loss_file, \"rb\" ) )\n",
        "vdata = pickle.load( open( validation_loss_file, \"rb\" ) )\n",
        "tloss = data[0]\n",
        "vloss = vdata[0]\n",
        "\n",
        "batch_size=10\n",
        "\n",
        "\n",
        "print(len(data))\n",
        "#print(np.array(tloss))\n",
        "num_files = len(   val_data_loader)\n",
        "num_training_files = len(file_data[0])\n",
        "print('number of training files = ',num_training_files)\n",
        "\n",
        "#\n",
        "# Training Loss Categories stored\n",
        "#\n",
        "class_loss =[]\n",
        "box_reg_loss = []\n",
        "objectness_loss = []\n",
        "rpn_box_reg_loss = []\n",
        "total_loss = []\n",
        "for tkey in tloss.keys():\n",
        "    tdata = tloss[tkey]\n",
        "    for jj in tdata:\n",
        "        cl = jj['loss_classifier'].cpu().detach().numpy()\n",
        "        brl =jj['loss_box_reg'].cpu().detach().numpy()\n",
        "\n",
        "        ol = jj['loss_objectness'].cpu().detach().numpy()\n",
        "        rbrl = jj['loss_rpn_box_reg'].cpu().detach().numpy()\n",
        "\n",
        "        class_loss.append(cl)\n",
        "        box_reg_loss.append(brl)\n",
        "        objectness_loss.append(ol)\n",
        "        rpn_box_reg_loss.append(rbrl)\n",
        "        total_loss.append(cl+brl+ol+rbrl)\n",
        "    #temp = ii.cpu()\n",
        "    #temp = temp.detach().numpy()\n",
        "    \n",
        "plot_skip = int(num_training_files/10)\n",
        "\n",
        "shortened_class_loss = class_loss[0:len(class_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_class_loss,'ro-')\n",
        "#plt.xticks(ticks=np.arange(0, len(shortened_class_loss), 10),\n",
        "#           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classifier Loss')\n",
        "plt.title('Training Classifier Loss Vs Epoch')\n",
        "\n",
        "\n",
        "shortened_box_reg_loss = box_reg_loss[0:len(box_reg_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_box_reg_loss,'ro-')\n",
        "#plt.xticks(ticks=np.arange(0, len(shortened_box_reg_loss), 10),\n",
        "#           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Box Reg Loss')\n",
        "plt.title('Training Box Reg Loss Vs Epoch')\n",
        "\n",
        "\n",
        "\n",
        "shortened_objectness_loss = objectness_loss[0:len(objectness_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_objectness_loss,'ro-')\n",
        "#plt.xticks(ticks=np.arange(0, len(shortened_objectness_loss), 10),\n",
        "#           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('objectness Loss')\n",
        "plt.title('Training objectness Loss Vs Epoch')\n",
        "\n",
        "\n",
        "shortened_rpn_box_reg_loss = rpn_box_reg_loss[0:len(rpn_box_reg_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_rpn_box_reg_loss,'ro-')\n",
        "#plt.xticks(ticks=np.arange(0, len(shortened_rpn_box_reg_loss), 10),\n",
        "#           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('RPN Box Reg Loss')\n",
        "plt.title('Training RPN Box Reg Loss Vs Epoch')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "shortened_total_loss = total_loss[0:len(total_loss):plot_skip]\n",
        "plt.plot(shortened_total_loss,'ro-')\n",
        "\n",
        "plt.title('BUSI Fine-Tuning Total Loss Training')\n",
        "plt.legend(['Training Loss'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(vloss),'b.-') #/len(val_data_loader))\n",
        "plt.title('BUSI Fine-Tuning Validation IOU Training')\n",
        "plt.legend(['Validation IOU'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IOU')\n",
        "#train_epoch= np.array(train_loss_per_epoch)/1000\n",
        "#plt.figure()\n",
        "#plt.plot(val_loss_per_epoch,'b.-')\n",
        "#plt.plot(train_epoch,'ro-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dayJgwtPqLC"
      },
      "outputs": [],
      "source": [
        "len(total_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgL7pRJDBflD"
      },
      "source": [
        "#Produce Training and Validation Loss Plots UCLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK51REyIw0TH"
      },
      "outputs": [],
      "source": [
        "mfolder = '0TO1_UCLA_BEST' #'UCLA_FINAL' #'UCLA_FINETUNE'\n",
        "training_loss_file  = os.path.join(model_dir,mfolder,'training_loss_epoch.pickle')\n",
        "validation_loss_file  = os.path.join(model_dir,mfolder,'validation_loss_epoch.pickle')\n",
        "#tloss = load(training_loss_file)\n",
        "data = pickle.load( open( training_loss_file, \"rb\" ) )\n",
        "vdata = pickle.load( open( validation_loss_file, \"rb\" ) )\n",
        "tloss = data[0]\n",
        "vloss = vdata[0]\n",
        "\n",
        "batch_size=10\n",
        "\n",
        "\n",
        "print(len(data))\n",
        "#print(np.array(tloss))\n",
        "num_files = len(   test_data_loader)\n",
        "num_training_files = len(training_data)\n",
        "print('number of training files = ',num_training_files)\n",
        "\n",
        "#\n",
        "# Training Loss Categories stored\n",
        "#\n",
        "class_loss =[]\n",
        "box_reg_loss = []\n",
        "objectness_loss = []\n",
        "rpn_box_reg_loss = []\n",
        "for tkey in tloss.keys():\n",
        "    tdata = tloss[tkey]\n",
        "    for jj in tdata:\n",
        "        class_loss.append(jj['loss_classifier'].cpu().detach().numpy())\n",
        "        box_reg_loss.append(jj['loss_box_reg'].cpu().detach().numpy())\n",
        "        objectness_loss.append(jj['loss_objectness'].cpu().detach().numpy())\n",
        "        rpn_box_reg_loss.append(jj['loss_rpn_box_reg'].cpu().detach().numpy())\n",
        "\n",
        "    #temp = ii.cpu()\n",
        "    #temp = temp.detach().numpy()\n",
        "    \n",
        "plot_skip = 100\n",
        "shortened_class_loss = class_loss[0:len(class_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_class_loss,'ro-')\n",
        "plt.xticks(ticks=np.arange(0, len(shortened_class_loss), 10),\n",
        "           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classifier Loss')\n",
        "plt.title('Training Classifier Loss Vs Epoch')\n",
        "\n",
        "plot_skip = 100\n",
        "shortened_box_reg_loss = box_reg_loss[0:len(box_reg_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_box_reg_loss,'ro-')\n",
        "plt.xticks(ticks=np.arange(0, len(shortened_box_reg_loss), 10),\n",
        "           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Box Reg Loss')\n",
        "plt.title('Training Box Reg Loss Vs Epoch')\n",
        "\n",
        "\n",
        "plot_skip = 100\n",
        "shortened_objectness_loss = objectness_loss[0:len(objectness_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_objectness_loss,'ro-')\n",
        "plt.xticks(ticks=np.arange(0, len(shortened_objectness_loss), 10),\n",
        "           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('objectness Loss')\n",
        "plt.title('Training objectness Loss Vs Epoch')\n",
        "\n",
        "\n",
        "plot_skip = 100\n",
        "shortened_rpn_box_reg_loss = rpn_box_reg_loss[0:len(rpn_box_reg_loss):plot_skip]\n",
        "plt.figure()\n",
        "plt.plot(shortened_rpn_box_reg_loss,'ro-')\n",
        "plt.xticks(ticks=np.arange(0, len(shortened_rpn_box_reg_loss), 10),\n",
        "           labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('RPN Box Reg Loss')\n",
        "plt.title('Training RPN Box Reg Loss Vs Epoch')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(tdata)/(num_training_files),'ro-')\n",
        "\n",
        "plt.title('UCLA Fine-Tuning Total Loss Training')\n",
        "plt.legend(['Training Loss'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(vloss),'b.-') #/len(val_data_loader))\n",
        "plt.title('UCLA Fine-Tuning Validation IOU Training')\n",
        "plt.legend(['Validation IOU'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IOU')\n",
        "#train_epoch= np.array(train_loss_per_epoch)/1000\n",
        "#plt.figure()\n",
        "#plt.plot(val_loss_per_epoch,'b.-')\n",
        "#plt.plot(train_epoch,'ro-')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4FiFY0LIxww"
      },
      "outputs": [],
      "source": [
        "tloss[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8ErgHbf43Ew"
      },
      "outputs": [],
      "source": [
        "class GradCam:\n",
        "    def __init__(self, model):\n",
        "        import torch.nn.functional as F\n",
        "        self.model = model.eval()\n",
        "        self.feature = None\n",
        "        self.gradient = None\n",
        "\n",
        "    def save_gradient(self, grad):\n",
        "        self.gradient = grad\n",
        "\n",
        "    def __call__(self, x):\n",
        "        image_size = (x.size(0), x.size(1),x.size(2))\n",
        "        print('image_size = ', image_size)\n",
        "        feature_maps = []\n",
        "        \n",
        "        for i in range(x.size(0)):\n",
        "            img = x[i].data.cpu().numpy()\n",
        "            img = img - np.min(img)\n",
        "            if np.max(img) != 0:\n",
        "                img = img / np.max(img)\n",
        "\n",
        "            feature = x[i].unsqueeze(0)\n",
        "            \n",
        "            for name, module in self.model.named_children():\n",
        "                if name == 'classifier':\n",
        "                    feature = feature.view(feature.size(0), -1)\n",
        "                feature = module(feature)\n",
        "                if name == 'features':\n",
        "                    feature.register_hook(self.save_gradient)\n",
        "                    self.feature = feature\n",
        "                    \n",
        "            classes = F.sigmoid(feature)\n",
        "            one_hot, _ = classes.max(dim=-1)\n",
        "            self.model.zero_grad()\n",
        "            one_hot.backward()\n",
        "\n",
        "            weight = self.gradient.mean(dim=-1, keepdim=True).mean(dim=-2, keepdim=True)\n",
        "            \n",
        "            mask = F.relu((weight * self.feature).sum(dim=1)).squeeze(0)\n",
        "            mask = cv2.resize(mask.data.cpu().numpy(), image_size)\n",
        "            mask = mask - np.min(mask)\n",
        "            \n",
        "            if np.max(mask) != 0:\n",
        "                mask = mask / np.max(mask)\n",
        "                \n",
        "            feature_map = np.float32(cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET))\n",
        "            cam = feature_map + np.float32((np.uint8(img.transpose((1, 2, 0)) * 255)))\n",
        "            cam = cam - np.min(cam)\n",
        "            \n",
        "            if np.max(cam) != 0:\n",
        "                cam = cam / np.max(cam)\n",
        "                \n",
        "            feature_maps.append(transforms.ToTensor()(cv2.cvtColor(np.uint8(255 * cam), cv2.COLOR_BGR2RGB)))\n",
        "            \n",
        "        feature_maps = torch.stack(feature_maps)\n",
        "        \n",
        "        return feature_maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqv50ZF9kB4W"
      },
      "outputs": [],
      "source": [
        "#for idata,tdata in val_data_loader:\n",
        "#    print(tdata)\n",
        "summary(modelr)\n",
        "#fmaps=GradCam(modelr)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#image = Image.open(\"lena.png\")\n",
        "#np_array = np.array(image)\n",
        "\n",
        "#pil_image=Image.fromarray(np_array)\n",
        "#pil_image.show()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((800, 600)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "random = torch.rand(3,800,600).to(dev)\n",
        "random = torch.tensor(random).double()\n",
        "array=random\n",
        "#array = np.random.randint(255, size=(800, 600),dtype=np.uint8)\n",
        "image = array #Image.fromarray(array)\n",
        "\n",
        "#test_image = np.zeros((3,600,800))\n",
        "#pil_image = Image.fromarray(test_image)\n",
        "#test_image = Image.open(\"../images/cavy.jpg\")\n",
        "test_image_tensor = image #(transform((image))) #.unsqueeze(dim=0)\n",
        "\n",
        "\n",
        "grad_cam = GradCam(modelr)\n",
        "\n",
        "#test_image_tensor = (transform((test_image))).unsqueeze(dim=0)\n",
        "#test_image_tensor = torch.tensor(test_image_tensor)\n",
        "\n",
        "feature_image = grad_cam(test_image_tensor) #.squeeze(dim=0)\n",
        "feature_image = transforms.ToPILImage()(feature_image)\n",
        "\n",
        "pred_idx = model(test_image_tensor).max(1)[1]\n",
        "print(\"pred: \", labels[int(pred_idx)])\n",
        "plt.title(\"Grad-CAM feature image\")\n",
        "plt.imshow(feature_image.resize(image_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41vyqCekGE1P"
      },
      "source": [
        "#GRADCAM INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtzygShmZsGY"
      },
      "outputs": [],
      "source": [
        "modelr\n",
        "#modelr.backbone.body #.layer4[0].conv3\n",
        "target_layer = model.layer4[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3ghvIc6uFAB"
      },
      "source": [
        "#Plot Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DrXBpolrGm0"
      },
      "outputs": [],
      "source": [
        "#Box coordinates output by Faster RCNN\n",
        "#Here x, y, w, and h correspond to the (x, y) coordinates of the box centre and the height h and width w of the box. \n",
        "\n",
        "\n",
        "#target coordinates follow this format:\n",
        "#            boxes.append([offset_col, offset_row, \n",
        "#                          xmax-skip_points[2], \n",
        "#                          ymax-skip_points[0]])\n",
        "\n",
        "batch_size = 10\n",
        "#!!!! Temporarily subbing in validation data\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2,\n",
        "                                          drop_last=True,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\"\"\" We assume that the box follows the format:\n",
        "    box1 = [x1,y1,x2,y2], and box2 = [x3,y3,x4,y4],\n",
        "    where (x1,y1) and (x3,y3) represent the top left coordinate,\n",
        "    and (x2,y2) and (x4,y4) represent the bottom right coordinate \n",
        "\"\"\"\n",
        "\n",
        "#print(eval_out)\n",
        "image_index=[]\n",
        "pred_label =[]\n",
        "truth_label = []\n",
        "pred_score=[]\n",
        "truth_box_present=[]\n",
        "pred_box_present=[]\n",
        "iou_val = []\n",
        "with torch.no_grad():\n",
        "\n",
        "    counter =0\n",
        "    for idata,tdata in test_data_loader: #val_data_loader:\n",
        "\n",
        "        for ii in range(0,len(tdata)):\n",
        "            counter =counter+1\n",
        "\n",
        "            #reset \n",
        "            iou = 0.0\n",
        "\n",
        "            #print('-------NEW IMAGE-------')\n",
        "            modelr.eval()\n",
        "\n",
        "            modelr = modelr.cuda()\n",
        "            val_imagelist=[]\n",
        "            if (train_on_gpu):\n",
        "                val_imagelist.append(torch.as_tensor(idata[ii], dtype=torch.float32).to(dev))\n",
        "            else:\n",
        "                val_imagelist.append(torch.as_tensor(idata[ii], dtype=torch.float32))\n",
        "\n",
        "            #\n",
        "            #model calculation\n",
        "            #\n",
        "            eval_out = modelr(val_imagelist)\n",
        "\n",
        "            \n",
        "            high_out, high_score, high_labels = keep_Highscore(eval_out) #From Anil's setup\n",
        "\n",
        "            \n",
        "            if (len(high_out) > 1):\n",
        "                print('high out >1@ ',ii)\n",
        "            if (len(high_score) >1):\n",
        "                print('scores >1@ ',ii)\n",
        "\n",
        "            #predicted information for this image\n",
        "            pred_boxes = high_out #eval_out[0]['boxes']\n",
        "            score = high_score #eval_out[0]['scores']\n",
        "            calc_label = high_labels\n",
        "            \n",
        "\n",
        "            eval_label = eval_out[0]['labels'].cpu()\n",
        "\n",
        "            #truth data\n",
        "            annotation = tdata[ii][0]['boxes'] \n",
        "            truth_label.append(tdata[ii][0]['labels'])\n",
        "            idnumber = tdata[ii][0]['image_id']\n",
        "\n",
        "            print('-----' * 20)\n",
        "            print('predicted label = ', calc_label)\n",
        "            print('predicted score = ',score)\n",
        "            print('predicted box = ', pred_boxes)\n",
        "            print('truth box = ',annotation)\n",
        "            print('truth label = ',truth_label[ii])\n",
        "            print('image id for subset is ', idnumber)\n",
        "\n",
        "            #continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if len(high_out) == 0: # or len(annotation) == 0:\n",
        "                iou = 0.0\n",
        "            elif (len(annotation) == 0):\n",
        "                #print('No annotation found')\n",
        "                iou=0.0\n",
        "            elif (len(pred_boxes[0]['boxes']) ==0):\n",
        "                #print('no predicted box')\n",
        "                iou=0.0\n",
        "            else:\n",
        "                #print(annotation, pred_boxes)\n",
        "                #iou = bb_intersection_over_union(annotation[0], pred_boxes)\n",
        "                #print('iou inputs: ',annotation[0], pred_boxes[0]['boxes'])\n",
        "                iou = IOU(annotation[0], pred_boxes[0]['boxes'])\n",
        "            \n",
        "            #\n",
        "            # Store metrics for review\n",
        "            #\n",
        "            iou_val.append(iou)\n",
        "            image_index.append(tdata[0][0]['image_id'])\n",
        "            pred_label.append(eval_label.cpu().numpy())\n",
        "            #pred_score.append(score.cpu().numpy())\n",
        "            if (len(annotation) == 0):\n",
        "                truth_box_present.append(0)\n",
        "            else:\n",
        "                truth_box_present.append(1)\n",
        "            if (len(high_out) == 0):\n",
        "                pred_box_present.append(0)\n",
        "            else:\n",
        "                pred_box_present.append(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            bdata = pred_boxes #eval_out[0]['boxes'][ii]\n",
        "            target_boxes = annotation #tdata['boxes']\n",
        "            #target_boxes = val_targets[ii][0]['boxes']\n",
        "\n",
        "            #print(target_boxes)\n",
        "            img = idata[ii] #.to('cpu')\n",
        "            #img = val_imagelist[ii].to('cpu')\n",
        "\n",
        "\n",
        "\n",
        "            show_images = 1\n",
        "            if (show_images == 1):\n",
        "                ############################################\n",
        "                #MATPLOTLIB STUFF\n",
        "                ############################################\n",
        "                plt.figure(figsize=(8, 6), dpi=80)\n",
        "                plt.imshow(img[1,:,:],cmap='gray')\n",
        "\n",
        "                iou_value = f'{iou:.2f}'\n",
        "                if (len(eval_label) >0):\n",
        "                    label_value = f'{eval_label[0]:.1f}'\n",
        "                else:\n",
        "                    label_value = 'N/A'\n",
        "                \n",
        "                pscore = score[0]['scores']\n",
        "                if (pscore):\n",
        "                    score_value = f'{pscore:.1f}'\n",
        "                else:\n",
        "                    score_value = 'N/A'\n",
        "                ttext = 'iou=' + str(iou_value)+'_label='+str(label_value)+ \\\n",
        "                    '_score_'+str(score_value)+'_'+str(int(idnumber))\n",
        "                plt.title(ttext)\n",
        "                #print('iou = ', iou)\n",
        "                #print('------------------------------------------')\n",
        "\n",
        "                ax = plt.gca()\n",
        "                if (len(pred_boxes[0]['boxes']) == 0):\n",
        "                    pass\n",
        "                else:\n",
        "                    rect = patches.Rectangle((np.uint(pred_boxes[0]['boxes'][0]),\n",
        "                                            np.uint(pred_boxes[0]['boxes'][1] )), #np.uint(bdata[1].cpu() )),\n",
        "                                            np.uint(pred_boxes[0]['boxes'][2])-(np.uint(pred_boxes[0]['boxes'][0])),\n",
        "                                            np.uint(pred_boxes[0]['boxes'][3])-(np.uint(pred_boxes[0]['boxes'][1])),\n",
        "                                            linewidth=1.5,edgecolor='r',facecolor='none')\n",
        "\n",
        "                if (len(target_boxes)==0):\n",
        "                    #skip this, no rectangular annotation to plot\n",
        "                    pass\n",
        "                else:\n",
        "                    rect2 = patches.Rectangle((np.uint(target_boxes[0][0].cpu()),\n",
        "                                            np.uint(target_boxes[0][1].cpu() )),\n",
        "                                            np.uint(target_boxes[0][2].cpu())-(np.uint(target_boxes[0][0].cpu())),\n",
        "                                            np.uint(target_boxes[0][3].cpu())-(np.uint(target_boxes[0][1].cpu())),\n",
        "                                            linewidth=1.2,edgecolor='k',facecolor='none')\n",
        "\n",
        "\n",
        "                    # Add the patch to the Axes\n",
        "                if (len(pred_boxes[0]['boxes']) >0):\n",
        "                    ax.add_patch(rect)\n",
        "                if (len(target_boxes)==0):\n",
        "                    legend_text = ['Prediction']\n",
        "                else:\n",
        "                    ax.add_patch(rect2)\n",
        "                    legend_text = ['Prediction', 'Annotation']\n",
        "                plt.legend(legend_text)\n",
        "                plt.colorbar()\n",
        "\n",
        "                plt.figure()\n",
        "                plt.hist(img[1,:,:])\n",
        "        if (counter >20):    \n",
        "            break\n",
        "\n",
        "print('Metrics and Images Done')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlHytbFwN20W"
      },
      "source": [
        "#DEBUG: TEST HISTOGRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5usP1gXFogK"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fnum = int(tdata[0][0]['image_id'])\n",
        "fname = test_list[222]\n",
        "\n",
        "print(fname)\n",
        "img = pickle.load( open( fname, \"rb\" ) )\n",
        "print('initial image type is ',type(img[1,0,0]))\n",
        "plt.figure()\n",
        "plt.imshow(img[1,:,:],cmap='gray')\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(img[1,:,:])\n",
        "plt.title('Original')\n",
        "\n",
        "img2=img.astype(np.float32)\n",
        "plt.figure()\n",
        "plt.hist(img2[1,:,:])\n",
        "plt.title('numpy float32')\n",
        "\n",
        "img = torch.as_tensor(img, dtype=torch.float32) \n",
        "plt.figure()\n",
        "plt.hist(img[1,:,:])\n",
        "plt.title('tensor float32')\n",
        "print('tensor type ', type(img))\n",
        "\n",
        "T=torch.histc(img[1,:,:],bins=1024)\n",
        "\n",
        "bins = 1024\n",
        "x = range(bins)\n",
        "plt.figure()\n",
        "plt.bar(x, T, align='center')\n",
        "plt.xlabel('Bins')\n",
        "plt.ylabel('Frequency')\n",
        "plt.ylim(0,1000)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "new_img = transforms.functional.equalize(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK4AdvJxevK6"
      },
      "outputs": [],
      "source": [
        "eval_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEGA08hhzaCS"
      },
      "outputs": [],
      "source": [
        "annotations = target_val\n",
        "output = loss_dict_val\n",
        "iou_over_batch = 0.0\n",
        "\n",
        "high_out = keep_Highscore(output)\n",
        "print('---------------------------')\n",
        "print(high_out)\n",
        "for i in range(len(high_out)): #output)):\n",
        "    out = high_out[i]['boxes']\n",
        "    annotation = annotations[i]['boxes'].cpu().numpy().squeeze()\n",
        "    if len(out) == 0 or len(annotation) == 0:\n",
        "        iou = 0.0\n",
        "    else:\n",
        "        iou = bb_intersection_over_union(annotation, out)\n",
        "    iou_over_batch += iou\n",
        "\n",
        "print(iou_over_batch / len(output))\n",
        "#return iou_over_batch / len(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFHEnaLIlR87"
      },
      "outputs": [],
      "source": [
        "print(annotation)\n",
        "print(out)\n",
        "print(len(loss_dict_val))\n",
        "print(high_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njeJ_YB_k5kI"
      },
      "outputs": [],
      "source": [
        "'''   \n",
        "    def bb_intersection_over_union(boxA, boxB):\n",
        "        xA = max(boxA[0], boxB[0])\n",
        "        yA = max(boxA[1], boxB[1])\n",
        "        xB = min(boxA[2], boxB[2])\n",
        "        yB = min(boxA[3], boxB[3])\n",
        "        interArea = abs(max(0, xB - xA + 1) * max(0, yB - yA + 1))\n",
        "        if interArea == 0:\n",
        "            return 0.0\n",
        "        boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "        boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "        iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "        return iou\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3m86Pl1mKt3"
      },
      "outputs": [],
      "source": [
        "'''    \n",
        "    def keep_Highscore(output):\n",
        "        processed_dict = []\n",
        "        for i in range(len(output)):\n",
        "            out = output[i]['boxes'].cpu().numpy().squeeze()\n",
        "            if len(out.shape) > 1:\n",
        "                if len(out) == 0:\n",
        "                    processed_dict.append({'boxes': []})\n",
        "                else:\n",
        "                    scores = output[i]['scores'].cpu().numpy().squeeze()\n",
        "                    processed_dict.append({'boxes': out[np.argmax(scores)]})\n",
        "            else:\n",
        "                processed_dict.append({'boxes': out})\n",
        "        return processed_dict\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4IswwLpjunl"
      },
      "outputs": [],
      "source": [
        "for p in modelr.rpn.parameters():\n",
        "    print(p)\n",
        "    p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTEVY6GtocP2"
      },
      "outputs": [],
      "source": [
        "loss_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoHox6spRHU7"
      },
      "outputs": [],
      "source": [
        "#print(summary(modelr,(3,244,244), batch_size = 5))\n",
        "#print(modelr)\n",
        "len(targets)\n",
        "tsave  = targets\n",
        "\n",
        "print(targets[0].keys())\n",
        "target_new = []\n",
        "for ii in range(0,5):\n",
        "    d={}\n",
        "    d['boxes'] = targets[0]['boxes'][ii]\n",
        "    d['labels'] = targets[0]['labels'][ii]\n",
        "    d['image_id'] = targets[0]['image_id'][ii]\n",
        "    d['area'] = targets[0]['area'][ii]\n",
        "    target_new.append(d)\n",
        "\n",
        "len(target_new)\n",
        "target_new[4]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwQAjjiSffsI"
      },
      "outputs": [],
      "source": [
        "print(loss_dict)\n",
        "ll=nn.CrossEntropyLoss(loss_dict['loss_classifier'])\n",
        "print(ll)\n",
        "ll.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKoAfTd5cKjR"
      },
      "outputs": [],
      "source": [
        "summary(modelr)\n",
        "fname = full_file_list[1419]\n",
        "print(fname)\n",
        "img_data = image.imread(fname) #'/content/gdrive/Shareddrives/BreastUS/Annotated data/unzipped_updated/1_srh8gfhj_a_0629s3fh_0.mp4-2021_07_15_17_21_15-labelme 3.0.zip/default/frame_000030.PNG')\n",
        "plt.figure()\n",
        "plt.imshow(img_data[:,:,0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Afis5F7nwH7"
      },
      "outputs": [],
      "source": [
        "idx = targets['image_id']\n",
        "print(targets['boxes'])\n",
        "full_file_list[idx[0]]\n",
        "len(bounding_box)\n",
        "print(len(full_file_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trATj4Qg6yHc"
      },
      "outputs": [],
      "source": [
        "idx=targets['image_id']\n",
        "print(idx)\n",
        "\n",
        "for fcount,ival in enumerate(idx): #imagelist):\n",
        "    print(full_file_list[ival])\n",
        "    idata = images[fcount]\n",
        "    plt.figure(figsize=(8, 6), dpi=80)\n",
        "    plt.imshow(idata[0,:,:].cpu(),cmap='gray')\n",
        "\n",
        "    cancer_status = targets['labels'][fcount]\n",
        "    if (cancer_status == 0):\n",
        "        clabel = 'Benign'\n",
        "    else:\n",
        "        clabel = 'Malignant'\n",
        "    findex=full_file_list[ival].find('updated/')\n",
        "    sname = full_file_list[ival][findex+8:]\n",
        "    findex = sname.find('/')\n",
        "    sname = sname[:findex] +'_' + str(int(ival)) + '_' + clabel\n",
        "    plt.title(sname)\n",
        "\n",
        "\n",
        "\n",
        "    for counter,blist in enumerate(range(0,len(out_custom[fcount]['boxes']))): #out['boxes']):\n",
        "        for ii in range(0,blist):\n",
        "            points = out_custom[fcount]['boxes'][ii]\n",
        "\n",
        "            #ii = out[counter]['boxes'][0]\n",
        "            newbox = [torch.detach(points[0]),torch.detach(points[1]),torch.detach(points[2]),torch.detach(points[3])]\n",
        "            #idata = imagelist[counter]\n",
        "\n",
        "            rect = patches.Rectangle((np.uint(newbox[0].cpu()),\n",
        "                                    np.uint(newbox[1].cpu())),\n",
        "                                    np.uint(newbox[2].cpu())-(np.uint(newbox[0].cpu())),\n",
        "                                    np.uint(newbox[3].cpu())-(np.uint(newbox[1].cpu())),\n",
        "                                    linewidth=0.8,\n",
        "                                    edgecolor='r',\n",
        "                                    facecolor='none')\n",
        "\n",
        "\n",
        "\n",
        "                # Get the current reference\n",
        "            ax = plt.gca()\n",
        "                # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "\n",
        "    #add annotation box\n",
        "    points = targets['boxes'][fcount]\n",
        "    print('points are ', points)\n",
        "    rect = patches.Rectangle((np.uint(points[0][0].cpu()),\n",
        "                    np.uint(points[0][1].cpu())),\n",
        "                    np.uint(points[0][2].cpu())-(np.uint(points[0][0].cpu())),\n",
        "                    np.uint(points[0][3].cpu())-(np.uint(points[0][1].cpu())),\n",
        "                    linewidth=0.8,\n",
        "                    edgecolor='g',\n",
        "                    facecolor='none')\n",
        "    # Get the current reference\n",
        "    ax = plt.gca()\n",
        "        # Add the patch to the Axes\n",
        "    ax.add_patch(rect)\n",
        "    #add annotation box\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbFL--9jDzoL"
      },
      "outputs": [],
      "source": [
        "targets['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dH9NaLGRXNg"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "#del resnet50\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "#from torchsummary import summary\n",
        "!pip3 install -q torchinfo\n",
        "\n",
        "from torchinfo import summary as s2 #works with lists of tensors\n",
        "\n",
        "# load a model pre-trained on COCO\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# replace the classifier with a new one, that has\n",
        "# num_classes which is user-defined\n",
        "num_classes = 2  # 1 class (person) + background\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "\n",
        "if (train_on_gpu ==1):\n",
        "    model=model.to(dev)\n",
        "else:\n",
        "    pass\n",
        "resnet50= model #.roi_heads.box_predictor\n",
        "resnet50.eval()\n",
        "#summary(resnet50,[(3, 600, 600)])\n",
        "print(model)\n",
        "#summary(resnet50,(3,800,800))\n",
        "a=sum([param.nelement() for param in model.parameters()])\n",
        "print(a)\n",
        "print(model.rpn)\n",
        "\n",
        "bb=10\n",
        "s2(model,input_size=(bb, 3, 800, 800))\n",
        "del resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OssLJlK_OjvK"
      },
      "source": [
        "# TEST UCLA FINAL MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTknFamYOget"
      },
      "outputs": [],
      "source": [
        "def test_ucla_classification(modelr,input_dataset, batch_size,score_cutoff = 0.4, iou_cutoff =0.15):\n",
        "    \n",
        "    test_data = input_dataset\n",
        "    #Box coordinates output by Faster RCNN\n",
        "    #Here x, y, w, and h correspond to the (x, y) coordinates of the box centre and the height h and width w of the box. \n",
        "\n",
        "\n",
        "    #target coordinates follow this format:\n",
        "    #            boxes.append([offset_col, offset_row, \n",
        "    #                          xmax-skip_points[2], \n",
        "    #                          ymax-skip_points[0]])\n",
        "\n",
        "    batch_size = 10\n",
        "    test_data_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=True,\n",
        "                                                num_workers=2,\n",
        "                                                drop_last=True,\n",
        "                                                collate_fn=collate_fn)\n",
        "\n",
        "    modelr.cuda()\n",
        "    \"\"\" We assume that the box follows the format:\n",
        "        box1 = [x1,y1,x2,y2], and box2 = [x3,y3,x4,y4],\n",
        "        where (x1,y1) and (x3,y3) represent the top left coordinate,\n",
        "        and (x2,y2) and (x4,y4) represent the bottom right coordinate \n",
        "    \"\"\"\n",
        "\n",
        "    #print(eval_out)\n",
        "    image_index=[]\n",
        "    pred_label =[]\n",
        "    truth_label = []\n",
        "    pred_score=[]\n",
        "    truth_box_present=[]\n",
        "    pred_box_present=[]\n",
        "    iou_val = []\n",
        "\n",
        "    #\n",
        "    # store the metrics for later review\n",
        "    #\n",
        "    metric_TP=[]\n",
        "    metric_FP=[]\n",
        "    metric_TN=[]\n",
        "    metric_FN=[]\n",
        "    metric_IOU= []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        counter =0\n",
        "        for idata,tdata in test_data_loader: #val_data_loader:\n",
        "            \n",
        "            TP=0\n",
        "            FP=0\n",
        "            TN=0\n",
        "            FN=0\n",
        "            iou_counter =0\n",
        "            for ii in range(0,len(tdata)):\n",
        "                counter =counter+1\n",
        "\n",
        "                image_batch = ii #temp measure since we are only doing one image at a time\n",
        "                #reset \n",
        "                iou = 0.0\n",
        "\n",
        "                #print('-------NEW IMAGE-------')\n",
        "                modelr.eval()\n",
        "\n",
        "\n",
        "                val_imagelist=[]\n",
        "                if (train_on_gpu):\n",
        "                    val_imagelist.append(torch.as_tensor(idata[ii], dtype=torch.float32).to(dev))\n",
        "                else:\n",
        "                    val_imagelist.append(torch.as_tensor(idata[ii], dtype=torch.float32))\n",
        "\n",
        "                #\n",
        "                #model calculation\n",
        "                #\n",
        "                eval_out = modelr(val_imagelist)\n",
        "                out = eval_out\n",
        "\n",
        "                high_out, high_score, high_labels = keep_Highscore(eval_out) #From Anil's setup\n",
        "\n",
        "                \n",
        "                if (len(high_out) > 1):\n",
        "                    print('high out >1@ ',ii)\n",
        "                if (len(high_score) >1):\n",
        "                    print('scores >1@ ',ii)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                '''\n",
        "                #predicted information for this image\n",
        "                pred_boxes = high_out #eval_out[0]['boxes']\n",
        "                score = high_score #eval_out[0]['scores']\n",
        "                plabel = high_labels\n",
        "                '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                #predicted information for this image\n",
        "                #pred_boxes = high_out #eval_out[0]['boxes']\n",
        "                #score = high_score #eval_out[0]['scores']\n",
        "                plabel = high_labels[0] #[image_batch]\n",
        "                pscore = high_score[0] #[image_batch]\n",
        "                pbox = high_out[0] #[image_batch]\n",
        "\n",
        "                if (pscore['scores']):\n",
        "                    pscore = pscore['scores'] #not empty, so keep\n",
        "                else:\n",
        "                    pscore = 0.0\n",
        "\n",
        "                #truth data\n",
        "                annotation = tdata[image_batch][0]['boxes'] \n",
        "                truth_label.append(tdata[image_batch][0]['labels'])\n",
        "                crowd_setting = tdata[image_batch][0]['iscrowd']\n",
        "\n",
        "\n",
        "\n",
        "                #Is there a truth ground box\n",
        "                if (len(annotation) <1):\n",
        "                    #truth is empty, so make this a Normal label\n",
        "                    tlabel = 0\n",
        "                else:\n",
        "                    tlabel = 1\n",
        "\n",
        "\n",
        "\n",
        "                #\n",
        "                # Calculate IOU and Metrics\n",
        "                #\n",
        "                iou, TP_out, FP_out, TN_out, FN_out = get_IOU(pbox,\n",
        "                                                            annotation,\n",
        "                                                            pscore,\n",
        "                                                            plabel['labels'],\n",
        "                                                            tlabel,\n",
        "                                                            score_cutoff,\n",
        "                                                            iou_cutoff)\n",
        "                #print('TP/FP/TN/FN = ', TP_out, FP_out, TN_out, FN_out)\n",
        "                \n",
        "                TP+=TP_out\n",
        "                FP+=FP_out\n",
        "                TN+=TN_out\n",
        "                FN+=FN_out\n",
        "\n",
        "\n",
        "                metric_IOU.append(iou)\n",
        "\n",
        "\n",
        "                #print('----------TP/FP/TN/FN =', TP, FP, TN, FN)\n",
        "\n",
        "                tag = 'NA'\n",
        "                fcounter = 999999\n",
        "                if (TP_out == 1):\n",
        "                    tag = 'TP'\n",
        "                    fcounter = int(np.sum(metric_TP) + TP)\n",
        "                elif(FP_out == 1):\n",
        "                    tag = 'FP'\n",
        "                    fcounter = int(np.sum(metric_FP) + FP)\n",
        "                elif(TN_out == 1):\n",
        "                    tag = 'TN'\n",
        "                    fcounter = int(np.sum(metric_TN) + TN)\n",
        "                elif(FN_out == 1):\n",
        "                    tag = 'FN'\n",
        "                    fcounter = int(np.sum(metric_FN) + FN)\n",
        "                else:\n",
        "                    print('NO CATEGORY FILLED IN')\n",
        "                    stop\n",
        "\n",
        "\n",
        "                #print(target_boxes)\n",
        "                img = idata[ii] #.to('cpu')\n",
        "                #img = val_imagelist[ii].to('cpu')\n",
        "\n",
        "                show_images = 0\n",
        "                if (show_images == 1):\n",
        "                    #img_eq = exposure.equalize_adapthist(img[1,:,:], clip_limit=0.01)\n",
        "                    #img[1,:,:] = torch.FloatTensor(img_eq)\n",
        "                    evallable = {}\n",
        "                    evallable[0] = 0\n",
        "\n",
        "                    #number format for use in figure title\n",
        "                    iou_value = '{:04.2f}'.format(iou)\n",
        "                    score_value = '{:04.2f}'.format(pscore)\n",
        "    \n",
        "                    output_file = str(tag) + '_' + str(fcounter) + '_' + \\\n",
        "                            'iou_' + str(iou_value) +'_' + \\\n",
        "                            'score_' + str(score_value) +'.png'\n",
        "\n",
        "                    annotation_plot(img, \n",
        "                                    evallable,\n",
        "                                    iou,\n",
        "                                    pscore, #['scores'],\n",
        "                                    plabel['labels'],\n",
        "                                    pbox,\n",
        "                                    annotation,\n",
        "                                    savedir =ucla_output_image_dir,\n",
        "                                    savename=output_file,\n",
        "                                    figsave=1)\n",
        "\n",
        "\n",
        "            metric_TP.append(TP)\n",
        "            metric_FP.append(FP)\n",
        "            metric_TN.append(TN)\n",
        "            metric_FN.append(FN)\n",
        "            \n",
        "\n",
        "                \n",
        "            print('*' *20)\n",
        "            print('TP,FP,TN,FN, iou/counter = ',TP,FP,TN,FN)\n",
        "            print('*' *20)\n",
        "            \n",
        "    num_metrics = counter\n",
        "    print('FINAL TP FP TN FN ',np.sum(metric_TP)/counter,\n",
        "        np.sum(metric_FP)/num_metrics,\n",
        "        np.sum(metric_TN)/num_metrics,\n",
        "        np.sum(metric_FN)/num_metrics)\n",
        "    print('Raw Final Metrics: TP/FP/TN/FN ', np.sum(metric_TP),\n",
        "        np.sum(metric_FP),\n",
        "        np.sum(metric_TN),\n",
        "        np.sum(metric_FN))\n",
        "        \n",
        "\n",
        "    print('Metric IOU = ',np.sum(metric_IOU)/len(metric_IOU))\n",
        "    print('score cutoff and iou cutoff = ', score_cutoff, iou_cutoff)\n",
        "\n",
        "\n",
        "    print('Raw Final Metrics: TP/FP/TN/FN ', np.sum(metric_TP),\n",
        "        np.sum(metric_FP),\n",
        "        np.sum(metric_TN),\n",
        "        np.sum(metric_FN))\n",
        "\n",
        "    precision = np.sum(metric_TP) / (np.sum(metric_FP) + np.sum(metric_TP) +eps)\n",
        "    recall = np.sum(metric_TP) / (np.sum(metric_FN) + np.sum(metric_TP) + eps)\n",
        "    accuracy= (np.sum(metric_TP)  + (np.sum(metric_TN)) ) / ((np.sum(metric_FN) + np.sum(metric_TP) + np.sum(metric_TN) + np.sum(metric_FP))+eps)\n",
        "\n",
        "\n",
        "    print('Precision = ', precision)\n",
        "    print('Recall = ', recall)\n",
        "    print('Accuracy = ', accuracy)\n",
        "\n",
        "    print('Metrics and Images Done')\n",
        "\n",
        "    #\n",
        "    # Package metrics for use outside this function\n",
        "    #\n",
        "    final_metrics ={}\n",
        "    final_metrics['precision'] = precision\n",
        "    final_metrics['accuracy'] = accuracy\n",
        "    final_metrics['recall'] = recall\n",
        "    final_metrics['metric_TP'] = metric_TP\n",
        "    final_metrics['metric_FP'] = metric_FP\n",
        "    final_metrics['metric_TN'] = metric_TN\n",
        "    final_metrics['metric_FN'] = metric_FN\n",
        "    final_metrics['metric_IOU'] = metric_IOU\n",
        "\n",
        "\n",
        "    return final_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zllzjD2HR0b9"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "####################################################################\n",
        "# GRADING CRITERIA\n",
        "#\n",
        "####################################################################\n",
        "score_cutoff = 0.40 #50% confidence is a valid result\n",
        "iou_cutoff = 0.15 #lower limit of valid iou result\n",
        "\n",
        "saved_metrics = {}\n",
        "\n",
        "for loop in range(0,10,1):\n",
        "    score_cutoff =  float(loop/10) #to get floating point step sizes\n",
        "    test_metrics = test_ucla_classification(modelr,input_dataset=test_data, \n",
        "                                            batch_size=batch_size, \n",
        "                                            score_cutoff=score_cutoff, \n",
        "                                            iou_cutoff = iou_cutoff)\n",
        "    saved_metrics[loop] = test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2OYATv4iRNq"
      },
      "source": [
        "#Plot FINAL UCLA METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC8ZqQY-wIz5"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Plot UCLA Test metrics\n",
        "#\n",
        "saved_metrics[0]['precision']\n",
        "print(saved_metrics[0].keys())\n",
        "\n",
        "\n",
        "precision_list = []\n",
        "accuracy_list = []\n",
        "recall_list = []\n",
        "TP=[]\n",
        "FP=[]\n",
        "TN=[]\n",
        "FN=[]\n",
        "IOU =[]\n",
        "\n",
        "for kk in saved_metrics.keys():\n",
        "    accuracy_list.append(saved_metrics[kk]['accuracy'])\n",
        "    precision_list.append(saved_metrics[kk]['precision'])\n",
        "    recall_list.append(saved_metrics[kk]['recall'])\n",
        "    TP.append(saved_metrics[kk]['metric_TP'])\n",
        "    FP.append(saved_metrics[kk]['metric_FP'])\n",
        "    TN.append(saved_metrics[kk]['metric_TN'])\n",
        "    FN.append(saved_metrics[kk]['metric_FN'])\n",
        "    IOU.append(saved_metrics[kk]['metric_IOU'])\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Accuracy/Precision/Recall Per Confidence Score')\n",
        "plt.plot(accuracy_list,'ro-')\n",
        "plt.xlabel('Confidence Score Cutoff')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.plot(precision_list,'b.-')\n",
        "\n",
        "plt.plot(recall_list,'g*-')\n",
        "plt.xticks(ticks = [0,1,2,3,4,5,6,7,8,9,0], \n",
        "           labels=['0.0','0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9',])\n",
        "plt.grid()\n",
        "plt.legend(['Accuracy', 'Precision','Recall'])\n",
        "\n",
        "\n",
        "#\n",
        "# TP/FP/TN/FN metrics\n",
        "#\n",
        "plt.figure()\n",
        "plt.title('Prediction Metrics Per Confidence Score')\n",
        "valtp=[] #temp holder\n",
        "valtn=[]\n",
        "valfp=[]\n",
        "valfn=[]\n",
        "for ii in range(0,len(TP)):\n",
        "    valtp.append(np.sum(TP[ii]))\n",
        "    valfp.append(np.sum(FP[ii]))\n",
        "    valtn.append(np.sum(TN[ii]))\n",
        "    valfn.append(np.sum(FN[ii]))\n",
        "\n",
        "plt.plot(valtp,'ro-')\n",
        "plt.plot(valtn,'b.-')\n",
        "plt.plot(valfn,'ko-')\n",
        "plt.plot(valfp,'g*-')\n",
        "plt.xticks(ticks = [0,1,2,3,4,5,6,7,8,9,0], \n",
        "           labels=['0.0','0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9',])\n",
        "plt.xlabel('Confidence Score Cutoff')\n",
        "plt.ylabel('Total Occurences For Test Set')\n",
        "plt.grid()\n",
        "plt.legend(['TP','TN','FN','FP'])\n",
        "\n",
        "\n",
        "#\n",
        "# IOU plot\n",
        "#\n",
        "plt.figure()\n",
        "plt.title('Average IOU (FPs=0 IOU) Per Confidence Score')\n",
        "valiou=[] #temp holder\n",
        "\n",
        "for ii in range(0,len(IOU)):\n",
        "    valiou.append(np.sum(IOU[ii])/len(IOU[ii]))\n",
        "plt.plot(valiou,'ro-')\n",
        "\n",
        "plt.xticks(ticks = [0,1,2,3,4,5,6,7,8,9,0], \n",
        "           labels=['0.0','0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9',])\n",
        "plt.xlabel('Confidence Score Cutoff')\n",
        "plt.ylabel('Data/Prediction IOU Value')\n",
        "plt.grid()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez5aDUS3vGV0"
      },
      "outputs": [],
      "source": [
        "print('Raw Final Metrics: TP/FP/TN/FN ', np.sum(metric_TP),\n",
        "      np.sum(metric_FP),\n",
        "      np.sum(metric_TN),\n",
        "      np.sum(metric_FN))\n",
        "precision = np.sum(metric_TP) / (np.sum(metric_FP) + np.sum(metric_TP))\n",
        "recall = np.sum(metric_TP) / (np.sum(metric_FN) + np.sum(metric_TP))\n",
        "accuracy= (np.sum(metric_TP)  + (np.sum(metric_TN)) ) / ((np.sum(metric_FN) + np.sum(metric_TP) + np.sum(metric_TN) + np.sum(metric_FP)))\n",
        "\n",
        "\n",
        "print('Precision = ', precision)\n",
        "print('Recall = ', recall)\n",
        "print('Accuracy = ', accuracy)\n",
        "\n",
        "np.sum(metric_TP)\n",
        "print('counter = ', counter)\n",
        "print(np.sum(metric_FP)/counter)\n",
        "print(np.sum(metric_TP),np.sum(metric_FP),np.sum(metric_TN),np.sum(metric_FN))\n",
        "print('             ABNORMAL     NORMAL')\n",
        "print('ABNORMAL')\n",
        "print('NORMAL  ')\n",
        "\n",
        "print(len(metric_IOU))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t0oRmQ7TiAX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.is_tensor(1)\n",
        "\n",
        "avg_iou = np.sum(iou_val)/len(iou_val)\n",
        "total = 0\n",
        "counter = 0\n",
        "for num,ii in enumerate(iou_val):\n",
        "    if (torch.is_tensor(ii)):\n",
        "        temp = ii.cpu().numpy()\n",
        "        print(temp)\n",
        "        #total = total + temp\n",
        "        #counter +=1\n",
        "        if (pred_label[num]==0 ) and (truth_box_present[num]==0):\n",
        "            #TN, no annotations present\n",
        "            pass\n",
        "        elif(pred_label[num]==1 ) and (truth_box_present[num]==0):\n",
        "            #FN, penalize this\n",
        "            counter +=1\n",
        "        elif(pred_label[num]==1 ) and (truth_box_present[num]==0):\n",
        "            #FP\n",
        "            counter +=1 #penalize\n",
        "        elif(pred_label[num]==1 ) and (truth_box_present[num]==1):\n",
        "            #TP  count this\n",
        "            total = total + temp\n",
        "            counter +=1\n",
        "        else:\n",
        "            stop #should not enter this\n",
        "    else:\n",
        "        if (pred_label[num]==0 ) and (truth_box_present[num]==0):\n",
        "            #TN, no annotations present\n",
        "            pass\n",
        "        elif(pred_label[num]==1 ) and (truth_box_present[num]==0):\n",
        "            #FN, penalize this\n",
        "            counter +=1\n",
        "        elif(pred_label[num]==1 ) and (truth_box_present[num]==0):\n",
        "            #FP\n",
        "            counter +=1 #penalize\n",
        "        elif(pred_label[num]==1 ) and (truth_box_present[num]==1):\n",
        "            #TP  count this\n",
        "            total = total + ii\n",
        "            counter +=1\n",
        "        else:\n",
        "            stop #should not enter this\n",
        "\n",
        "\n",
        "avg_iou = total/(counter +eps)\n",
        "\n",
        "avg_score = np.sum(pred_score)/len(pred_score)\n",
        "avg_truth_box = np.sum(truth_box_present)/len(truth_box_present)\n",
        "avg_pred_box = np.sum(pred_box_present)/len(pred_box_present)\n",
        "print(avg_iou, avg_score, avg_truth_box, avg_pred_box)\n",
        "print(iou_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo1LrvqFcHCX"
      },
      "outputs": [],
      "source": [
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ve0uT4ZTrqy"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_name = train_list[0]\n",
        "\n",
        "img = pickle.load( open( file_name, \"rb\" ) )\n",
        "\n",
        "print(np.shape(img))\n",
        "print('image type is ', type(img[0,0,0]))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img[1,:,:], cmap='gray')\n",
        "plt.colorbar()\n",
        "\n",
        "#torchvision.transforms.ToTensor(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSD6PjUhsIj1"
      },
      "source": [
        "### -------------------DEBUG NEW MODEL TYPES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_Zc70YmRZl3"
      },
      "outputs": [],
      "source": [
        "%pdb off\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "#el model\n",
        "\n",
        "#del backbone\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load a pre-trained model for classification and return\n",
        "# only the features\n",
        "#backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "#backbone.out_channels = 1280\n",
        "%pdb off\n",
        "backbone = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
        "backbone.out_channels = 512\n",
        "\n",
        "#backbone = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "#backbone.out_channels = 1280\n",
        "#anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "anchor_generator = AnchorGenerator(sizes=((8, 16, 32, 64, 128),),\n",
        "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "# let's define what are the feature maps that we will\n",
        "# use to perform the region of interest cropping, as well as\n",
        "# the size of the crop after rescaling.\n",
        "# if your backbone returns a Tensor, featmap_names is expected to\n",
        "# be [0]. More generally, the backbone should return an\n",
        "# OrderedDict[Tensor], and in featmap_names you can choose which\n",
        "# feature maps to use.\n",
        "''' mobilenet\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                output_size=7,\n",
        "                                                sampling_ratio=2)\n",
        "'''\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(['feat1', 'feat3'], 3, 2)\n",
        "from collections import OrderedDict\n",
        "i = OrderedDict()\n",
        "i['feat1'] = torch.rand(1, 5, 64, 64)\n",
        "i['feat2'] = torch.rand(1, 5, 32, 32)  # this feature won't be used in the pooling\n",
        "i['feat3'] = torch.rand(1, 5, 16, 16)\n",
        "# create some random bounding boxes\n",
        "boxes = torch.rand(6, 4) * 256; boxes[:, 2:] += boxes[:, :2]\n",
        "# original image size, before computing the feature maps\n",
        "image_sizes = [(512, 512)]\n",
        "output = roi_pooler(i, [boxes], image_sizes)\n",
        "print(output.shape)\n",
        "\n",
        "\n",
        "\n",
        "# put the pieces together inside a FasterRCNN model\n",
        "model = FasterRCNN(backbone,\n",
        "                   num_classes=2,\n",
        "                   rpn_anchor_generator=anchor_generator,\n",
        "                   box_roi_pool=roi_pooler)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if (train_on_gpu ==1):\n",
        "    model=model.to(dev)\n",
        "else:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "# For training\n",
        "images= torch.rand(1, 3, 600, 1200) \n",
        "boxes= torch.Tensor([[[10,10,100,100]]])  #torch.rand(1, 11,4)*100 #11, 4)\n",
        "\n",
        "labels = torch.randint(1, 91, (4, 11))\n",
        "#images = list(image for image in images)\n",
        "\n",
        "### Moving image data to the device\n",
        "imagelist=[]\n",
        "for ii in range(0,len(images)):\n",
        "    #imagelist.append(images[ii])\n",
        "    if (train_on_gpu):\n",
        "        imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32).to(dev))\n",
        "    else:\n",
        "        imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "targets = []\n",
        "for i in range(len(images)):\n",
        "    d = {}\n",
        "    d['boxes'] = boxes[i]\n",
        "    d['labels'] = labels[i]\n",
        "    targets.append(d)\n",
        "\n",
        "output = model(imagelist) #, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QX330WaZBLg"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,\n",
        "                                       step_size=7,\n",
        "                                       gamma=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#training_data set above by calling Custom Dataset\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(training_data,\n",
        "                                            batch_size=10,\n",
        "                                            shuffle=False, #True,\n",
        "                                            num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "images,targets = next(iter(data_loader))\n",
        "#images = list(image for image in images)\n",
        "\n",
        "imagelist=[]\n",
        "for ii in range(0,len(images)):\n",
        "    #imagelist.append(images[ii])\n",
        "    if (train_on_gpu):\n",
        "        imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32).to(dev))\n",
        "    else:\n",
        "        imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32))\n",
        "print(np.shape(images), len(images))\n",
        "print(np.shape(imagelist[0]))\n",
        "\n",
        "tdata=[]\n",
        "ddata={}\n",
        "\n",
        "import tensorflow as tf\n",
        "for ii in range(0,len(targets['boxes'])):\n",
        "    if (train_on_gpu):\n",
        "        ddata['boxes'] = targets['boxes'][ii].to(dev) #torch.DoubleTensor(targets['boxes'][ii])\n",
        "\n",
        "        ddata['labels']=targets['labels'][ii].to(dev)\n",
        "        ddata['area'] = targets['area'][ii].to(dev)\n",
        "        tdata.append(ddata)\n",
        "    else:\n",
        "        ddata['boxes'] = targets['boxes'][ii] #torch.DoubleTensor(targets['boxes'][ii])\n",
        "\n",
        "        ddata['labels']=targets['labels'][ii]\n",
        "        ddata['area'] = targets['area'][ii]\n",
        "        tdata.append(ddata)\n",
        "\n",
        "\n",
        "if (train_on_gpu ==1):\n",
        "    imagelist = [ t.to(dev) for t in imagelist ]\n",
        "#target_list = [ {'boxes':d['boxes'].to(device), 'labels':d['labels']} for d in target_list ]\n",
        "\n",
        "model.eval()  # Set model to training mode\n",
        "\n",
        "print('!!! FORWARD PASS !!!!')\n",
        "out=model(imagelist,tdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44H7SaIHtRDi"
      },
      "outputs": [],
      "source": [
        "model_children = list(model.children())\n",
        "print(model_children)\n",
        "no_of_layers=0\n",
        "conv_layers=[]\n",
        "\n",
        "rpn = model_children[2]\n",
        "#print(model_children[2])\n",
        "\n",
        "\n",
        "img = np.zeros((10,3,600,600))\n",
        "\n",
        "img= np.float32(img)\n",
        "result = model(torch.tensor(img).to(dev))\n",
        "\n",
        "'''\n",
        "    print('--  ',type(child))\n",
        "    if type(child)==nn.Conv2d:\n",
        "        no_of_layers+=1\n",
        "        conv_layers.append(child)\n",
        "    elif type(child)==nn.Sequential:\n",
        "        for layer in child.children():\n",
        "            if type(layer)==nn.Conv2d:\n",
        "                no_of_layers+=1\n",
        "                conv_layers.append(layer)\n",
        "print(no_of_layers)\n",
        "\n",
        "\n",
        "results = [conv_layers[0](img)]\n",
        "for i in range(1, len(conv_layers)):\n",
        "    results.append(conv_layers[i](results[-1]))\n",
        "outputs = results\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG5KgWUumXQD"
      },
      "outputs": [],
      "source": [
        "model.roi_heads.box_predictor.cls_score(torch.tensor(img).to(dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VaveGUssEz1"
      },
      "source": [
        "### RUN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcRYVBE5TrgV"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "# load a pre-trained model for classification and return\n",
        "# only the features\n",
        "backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "# FasterRCNN needs to know the number of\n",
        "# output channels in a backbone. For mobilenet_v2, it's 1280\n",
        "# so we need to add it here\n",
        "backbone.out_channels = 1280\n",
        "\n",
        "# let's make the RPN generate 5 x 3 anchors per spatial\n",
        "# location, with 5 different sizes and 3 different aspect\n",
        "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
        "# map could potentially have different sizes and\n",
        "# aspect ratios\n",
        "#anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "anchor_generator = AnchorGenerator(sizes=((8, 16, 32, 64, 128),),\n",
        "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "# let's define what are the feature maps that we will\n",
        "# use to perform the region of interest cropping, as well as\n",
        "# the size of the crop after rescaling.\n",
        "# if your backbone returns a Tensor, featmap_names is expected to\n",
        "# be [0]. More generally, the backbone should return an\n",
        "# OrderedDict[Tensor], and in featmap_names you can choose which\n",
        "# feature maps to use.\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                output_size=7,\n",
        "                                                sampling_ratio=2)\n",
        "\n",
        "# put the pieces together inside a FasterRCNN model\n",
        "model = FasterRCNN(backbone,\n",
        "                   num_classes=2,\n",
        "                   rpn_anchor_generator=anchor_generator,\n",
        "                   box_roi_pool=roi_pooler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLWa6D72_kQB"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "#Show summary of model setup and move model to the GPU\n",
        " #train_on_gpu = torch.cuda.is_available()\n",
        "from torchsummary import summary\n",
        "\n",
        "if (train_on_gpu == 1):\n",
        "    #dev=torch.device(\"cuda\") \n",
        "    model.to(dev)\n",
        "    model.eval()\n",
        "    summary(model,(3,600,800), batch_size = 300, device='cuda')\n",
        "elif ( (train_on_tpu == 1) and (train_on_gpu == 0)):\n",
        "    ### TPU with pytorch has some issues\n",
        "    model_vgg16.to(dev)\n",
        "    summary(model_vgg16,(3,244,244), batch_size = bsize, device=dev)\n",
        "else:\n",
        "    summary(model,(3,600,800), batch_size = bsize)\n",
        "'''\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWURd5-GuUAJ"
      },
      "source": [
        "#MODEL RUN\n",
        "These are the assertions for the pretrained model\n",
        "'''\n",
        "    739                 floating_point_types = (torch.float, torch.double, torch.half)\n",
        "    740                 assert t[\"boxes\"].dtype in floating_point_types, 'target boxes must of float type'\n",
        "--> 741                 assert t[\"labels\"].dtype == torch.int64, 'target labels must of int64 type'\n",
        "    742                 if self.has_keypoint():\n",
        "    743                     assert t[\"keypoints\"].dtype == torch.float32, 'target keypoints must of float type'\n",
        "'''\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaO7Cn-VT4z2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "\n",
        "#model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "#dataset = PennFudanDataset('PennFudanPed', get_transform(train=True))\n",
        "\n",
        "# replace the classifier with a new one, that has\n",
        "# num_classes which is user-defined\n",
        "num_classes = 2  # 1 class (person) + background\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "\n",
        "#from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "train_on_gpu = 0\n",
        "if (train_on_gpu):\n",
        "    model.to(dev)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,\n",
        "                                       step_size=7,\n",
        "                                       gamma=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#training_data set above by calling Custom Dataset\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(training_data,\n",
        "                                            batch_size=10,\n",
        "                                            shuffle=False, #True,\n",
        "                                            num_workers=2)\n",
        "\n",
        "##dataloader_training = DataLoader(train_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "# For Training\n",
        "\n",
        "\n",
        "images,targets = next(iter(data_loader))\n",
        "#images = list(image for image in images)\n",
        "\n",
        "imagelist=[]\n",
        "for ii in range(0,len(images)):\n",
        "    #imagelist.append(images[ii])\n",
        "    if (train_on_gpu):\n",
        "        imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32).to(dev))\n",
        "    else:\n",
        "        imagelist.append(torch.as_tensor(images[ii], dtype=torch.float32))\n",
        "print(np.shape(images), len(images))\n",
        "print(np.shape(imagelist[0]))\n",
        "\n",
        "tdata=[]\n",
        "ddata={}\n",
        "\n",
        "import tensorflow as tf\n",
        "for ii in range(0,len(targets['boxes'])):\n",
        "    if (train_on_gpu):\n",
        "        ddata['boxes'] = targets['boxes'][ii].to(dev) #torch.DoubleTensor(targets['boxes'][ii])\n",
        "\n",
        "        ddata['labels']=targets['labels'][ii].to(dev)\n",
        "        ddata['area'] = targets['area'][ii].to(dev)\n",
        "        tdata.append(ddata)\n",
        "    else:\n",
        "        ddata['boxes'] = targets['boxes'][ii] #torch.DoubleTensor(targets['boxes'][ii])\n",
        "\n",
        "        ddata['labels']=targets['labels'][ii]\n",
        "        ddata['area'] = targets['area'][ii]\n",
        "        tdata.append(ddata)\n",
        "\n",
        "\n",
        "if (train_on_gpu ==1):\n",
        "    imagelist = [ t.to(dev) for t in imagelist ]\n",
        "#target_list = [ {'boxes':d['boxes'].to(device), 'labels':d['labels']} for d in target_list ]\n",
        "\n",
        "model.eval()  # Set model to training mode\n",
        "\n",
        "print('!!! FORWARD PASS !!!!')\n",
        "out=model(imagelist,tdata)\n",
        "#out = model(images, tdata)\n",
        "\n",
        "losses = sum(loss for loss in out.values())\n",
        "\n",
        "\n",
        "#targets_formatted = [{'boxes', targets['boxes'],\n",
        "#            'labels',targets['labels']}]\n",
        "#output = model(images,targets)   # Returns losses and detections\n",
        "# For inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)           # Returns predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfjUvHjXyl-4"
      },
      "source": [
        "#PLOT ANCHORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYOXySHubZ9R"
      },
      "outputs": [],
      "source": [
        "out[0]\n",
        "\n",
        "\n",
        "for fcount,numfiles in enumerate(range(0,len(out),1)):\n",
        "    idata = imagelist[fcount]\n",
        "    plt.figure(figsize=(8, 6), dpi=30)\n",
        "    plt.imshow(idata[0,:,:].cpu(),cmap='gray')\n",
        "    plt.title(str(fcount))\n",
        "\n",
        "\n",
        "    for counter,blist in enumerate(range(0,len(out[fcount]['boxes']))): #out['boxes']):\n",
        "        for ii in range(0,blist):\n",
        "            points = out[fcount]['boxes'][ii]\n",
        "\n",
        "            #ii = out[counter]['boxes'][0]\n",
        "            newbox = [torch.detach(points[0]),torch.detach(points[1]),torch.detach(points[2]),torch.detach(points[3])]\n",
        "            #idata = imagelist[counter]\n",
        "\n",
        "            rect = patches.Rectangle((np.uint(newbox[0].cpu()),\n",
        "                                    np.uint(newbox[1].cpu())),\n",
        "                                    np.uint(newbox[2].cpu())-(np.uint(newbox[0].cpu())),\n",
        "                                    np.uint(newbox[3].cpu())-(np.uint(newbox[1].cpu())),\n",
        "                                    linewidth=0.8,\n",
        "                                    edgecolor='r',\n",
        "                                    facecolor='none')\n",
        "\n",
        "\n",
        "\n",
        "                # Get the current reference\n",
        "            ax = plt.gca()\n",
        "                # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "print('counter is ',counter)\n",
        "    \n",
        "#x = torchvision.conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(out) #(base_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RQc79uabOjo"
      },
      "outputs": [],
      "source": [
        "idata = imagelist[5]\n",
        "plt.figure(figsize=(8, 6), dpi=80)\n",
        "plt.imshow(idata[0,:,:].cpu(),cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASlpLcLS3wJr"
      },
      "outputs": [],
      "source": [
        "print(len(targets[\"boxes\"]))\n",
        "#print(targets['boxes'][\n",
        "\n",
        "fdata = []\n",
        "box_data={}\n",
        "label_data={}\n",
        "ddata={}\n",
        "\n",
        "for ii in range(0,3):\n",
        "    ddata['boxes']=targets['boxes'][ii]\n",
        "    ddata['labels']=targets['labels'][ii]\n",
        "    fdata.append(ddata)\n",
        "\n",
        "  \n",
        "\n",
        "print(fdata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR9duulEKD8C"
      },
      "outputs": [],
      "source": [
        "targets.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcxPKk2lfQLl"
      },
      "outputs": [],
      "source": [
        "x = [torch.rand(3, 300, 400), torch.rand(3, 300, 400)]\n",
        "a = torch.tensor([[100,100,200,200],[110,110,350,400]], dtype=torch.float64)\n",
        "b = torch.tensor([1,2],dtype=torch.int64)\n",
        "targets2 = [{'boxes': a, 'labels':  b},\n",
        "            {'boxes': a, 'labels':  b}]\n",
        "#print(targets2)\n",
        "for target in targets2:\n",
        "    #print(target)\n",
        "    boxes = target[\"boxes\"]\n",
        "\n",
        "\n",
        "\n",
        "print('\\n')\n",
        "targets_formatted = [{k: v for k, v in t.items()} for t in targets2]\n",
        "targets_formatted\n",
        "#imagesx = images[0:1]\n",
        "#output = model(imagesx,targets)   # Returns losses and detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQpUW1ZwZDgt"
      },
      "outputs": [],
      "source": [
        "print(type(targets['boxes']))\n",
        "a={}\n",
        "a[\"t1\"]=4\n",
        "a[\"t2\"] = [1,2]\n",
        "a=list(a)\n",
        "for counter,aa in enumerate(a):\n",
        "    print('aa = ',aa)\n",
        "    for bb in aa.items():\n",
        "        print(bb,counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zO96z47PRis"
      },
      "outputs": [],
      "source": [
        "#a = [{k: v for k, v in t.items()} for t in targets]\n",
        "a=targets[\"boxes\"]\n",
        "if isinstance(a,torch.Tensor):\n",
        "    print('is instance')\n",
        "for t in targets:\n",
        "    print(t)\n",
        "    for k,v in t.items():\n",
        "        print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJJh5XVWgPmG"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "#model = torchvision.models.vgg16(pretrained=True)\n",
        "model=torchvision.models.resnet50(pretrained=True)\n",
        "#fe = list(model.features)\n",
        "\n",
        "model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXMzB_4zGlAc"
      },
      "outputs": [],
      "source": [
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "# and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                step_size=3,\n",
        "                                                gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc-2gzhSHesm"
      },
      "outputs": [],
      "source": [
        "    num_epochs = 10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train for one epoch, printing every 10 iterations\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        # evaluate on the test dataset\n",
        "        evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "    print(\"That's it!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KDkNEYNt5Fi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "#x = box_info\n",
        "#json.loads(x)\n",
        "#type(box_info)\n",
        "\n",
        "from ast import literal_eval #as make_tuple\n",
        "a=literal_eval(box_info)\n",
        "print(a[0])\n",
        "type(a[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WJ5mZROnju7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgzzBJKxPUtV"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "full_file = os.path.join(label_data_dir, label_files[0])\n",
        "with ZipFile(full_file, 'r') as zipObj:\n",
        "   # Get a list of all archived file names from the zip\n",
        "   listOfFileNames = zipObj.namelist()\n",
        "   for fnames in listOfFileNames:\n",
        "       print(fnames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQxlbtgCRovN"
      },
      "source": [
        "#SCRATCH -- PRESENTATION PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZIOIkPGR1H8"
      },
      "outputs": [],
      "source": [
        "mdir = os.listdir(busi_main_dir)\n",
        "print(mdir[0])\n",
        "for ii in mdir:\n",
        "    print(ii)\n",
        "    fdir = os.path.join(busi_main_dir,ii)\n",
        "    flist = os.listdir(fdir)\n",
        "\n",
        "    if ('malignant' in ii):\n",
        "        for jj in flist:\n",
        "            if (('(54)' in jj) and ('580' in jj)):\n",
        "                print(jj)\n",
        "                fname = os.path.join(busi_main_dir, ii, jj)\n",
        "                img = pickle.load( open( fname, \"rb\" ) )\n",
        "                plt.figure()\n",
        "                plt.imshow(img[0,:,:], cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.figure()\n",
        "                plt.imshow(img[1,:,:], cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.figure()\n",
        "                plt.imshow(img[2,:,:], cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                \n",
        "## GET UCLA IMAGES FOR PRESENTATION\n",
        "udir = '/content/gdrive/Shareddrives/BreastUS/Annotated data/unzipped_updated'\n",
        "mdir = os.listdir('/content/gdrive/Shareddrives/BreastUS/Annotated data/unzipped_updated')\n",
        "print(mdir)\n",
        "\n",
        "for ii in mdir:\n",
        "    test_dir = os.path.join(udir,ii, 'default')\n",
        "    flist = os.listdir(test_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_IWU6wKJfh3"
      },
      "source": [
        "#SCRATCH -- SHOW PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8j0sH8iKldR"
      },
      "outputs": [],
      "source": [
        "ucla_pickle_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XgA5JtWJbFs"
      },
      "outputs": [],
      "source": [
        "if(1):\n",
        "    import imageio\n",
        "    from matplotlib import image\n",
        "\n",
        "\n",
        "    fname = ucla_pickle_list[100]\n",
        "    print(fname)\n",
        "    img = pickle.load( open( fname, \"rb\" ) )\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img[1,:,:], cmap = 'gray')\n",
        "    plt.xlabel('Column Pixels')\n",
        "    plt.ylabel('Row Pixels')\n",
        "    plt.title('Normalized & Cropped Image')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(img[1,:,:])\n",
        "    plt.title('Normalized & Cropped Histogram')\n",
        "\n",
        "\n",
        "    fname2 = os.path.join(annotated_dir,'unzipped_updated','1_076up782_a_dcc4675o_1.mp4-2021_09_03_16_36_25-labelme 3.0.zip/default/frame_000051.PNG')\n",
        "\n",
        "    img2 = image.imread(fname2)\n",
        "\n",
        "\n",
        "\n",
        "    ## Convert the RGB input into grayscale\n",
        "    R, G, B = img2[:,:,0], img2[:,:,1], img2[:,:,2]\n",
        "    imgGray = 0.2989 * R + 0.5870 * G + 0.1140 * B\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(imgGray,cmap='gray')\n",
        "    plt.xlabel('Column Pixels')\n",
        "    plt.ylabel('Row Pixels')\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(imgGray)\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    #\n",
        "    # Show 3 channels of cropped image\n",
        "    #\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img[0,:,:], cmap = 'gray')\n",
        "    plt.xlabel('Column Pixels')\n",
        "    plt.ylabel('Row Pixels')\n",
        "    plt.title('Normalized & Cropped Image. CH0')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img[1,:,:], cmap = 'gray')\n",
        "    plt.xlabel('Column Pixels')\n",
        "    plt.ylabel('Row Pixels')\n",
        "    plt.title('Normalized & Cropped Image. CH1')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img[2,:,:], cmap = 'gray')\n",
        "    plt.xlabel('Column Pixels')\n",
        "    plt.ylabel('Row Pixels')\n",
        "    plt.title('Normalized & Cropped Image. CH2')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "    stop\n",
        "    num_mrn = set(mrn)\n",
        "    num_mrn\n",
        "    image_path[0:3]\n",
        "\n",
        "    print(image_path[0])\n",
        "    filename = os.path.basename(image_path[0]) \n",
        "    [_,fpath] =image_path[0].split('drive/MyDrive/Annotated data/')\n",
        "    full_file = os.path.join(annotated_dir,fpath)\n",
        "    print(full_file)\n",
        "\n",
        "    print('filename exists: ',os.path.exists(full_file))\n",
        "    import imageio\n",
        "\n",
        "    #import PIL\n",
        "    #from PIL import Image\n",
        "    # Open the image form working directory\n",
        "    #image = Image.open(full_file)\n",
        "\n",
        "    #from matplotlib import image\n",
        "    #from matplotlib import pyplot\n",
        "    img = image.imread(full_file)\n",
        "\n",
        "\n",
        "\n",
        "    ## Convert the RGB input into grayscale\n",
        "    R, G, B = img[:,:,0], img[:,:,1], img[:,:,2]\n",
        "    imgGray = 0.2989 * R + 0.5870 * G + 0.1140 * B\n",
        "\n",
        "    plt.figure(figsize=(8, 6), dpi=80)\n",
        "    plt.imshow(imgGray, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    cropped_image,skip_points,case_status = crop_us_image(imgGray,0)\n",
        "    plt.figure(figsize=(8, 6), dpi=80)\n",
        "    plt.imshow(cropped_image, cmap='gray')\n",
        "    plt.title('cropped image')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_VaveGUssEz1",
        "vfjUvHjXyl-4"
      ],
      "machine_shape": "hm",
      "name": "Read_Ultrasound_images",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM17ujm2PeP2Y3NN/KkVRah",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}